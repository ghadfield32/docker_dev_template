{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. EDA module\n",
        "\n",
        "Exploratory data analysis module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/eda.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/eda.py\n",
        "\"\"\"\n",
        "NFL Kicker Fieldâ€‘Goal EDA Utilities (v0.2)\n",
        "========================================\n",
        "A *functionâ€‘first* rewrite of the original exploratory notebook used for the\n",
        "Denver Broncos technical assessment **with 100â€¯% feature parity**.  Every cell\n",
        "in the notebook is now represented by a callable that:\n",
        "\n",
        "* replicates textual/visual output produced in the exploratory notebook,\n",
        "* accepts keyword args for easy tweaking, and\n",
        "* returns the underlying DataFrame(s)/Figure objects for downstream use or\n",
        "  testing.\n",
        "\n",
        "Major fixes in **v0.2**\n",
        "----------------------\n",
        "* **Age calculation** now computed whenever possible instead of relying on an\n",
        "  existing column.\n",
        "* **Fâ€‘strings** added where literals previously swallowed variables.\n",
        "* **Sanityâ€‘check monotonicity test** relaxed to tolerate small numerical noise.\n",
        "* **Plot titles & palettes** corrected to match the original style exactly.\n",
        "* **Explicit returns** on all helpers for easier chaining.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Sequence, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s â”‚ %(levelname)s â”‚ %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        ")\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"figure.figsize\": (12, 7),\n",
        "    \"axes.spines.top\": False,\n",
        "    \"axes.spines.right\": False,\n",
        "})\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "_FIELD_GOAL_RESULT_SUCCESS = \"Made\"\n",
        "_PRESEASON_FLAG = \"Pre\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ core helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def load_and_merge(\n",
        "    kickers_path: Path | str,\n",
        "    attempts_path: Path | str,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load raw CSVs and merge on player_id.\n",
        "\n",
        "    - Parses 'birthdate' in kickers.csv.\n",
        "    - Parses 'game_date' in field_goal_attempts.csv.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Combined DataFrame with parsed dates.\n",
        "    \"\"\"\n",
        "    # 1. Inspect columns for debugging\n",
        "    logger.info(\"Inspecting kickers file columns: %s\", pd.read_csv(kickers_path, nrows=0).columns.tolist())\n",
        "    logger.info(\"Inspecting attempts file columns: %s\", pd.read_csv(attempts_path, nrows=0).columns.tolist())\n",
        "\n",
        "    # 2. Read with correct parse_dates per file\n",
        "    logger.info(\"Reading kickers.csv with parse_dates=['birthdate']\")\n",
        "    kickers = pd.read_csv(kickers_path, parse_dates=[\"birthdate\"])\n",
        "\n",
        "    logger.info(\"Reading field_goal_attempts.csv with parse_dates=['game_date']\")\n",
        "    attempts = pd.read_csv(attempts_path, parse_dates=[\"game_date\"])\n",
        "\n",
        "    # 3. Merge\n",
        "    df = attempts.merge(kickers, on=\"player_id\", how=\"left\", validate=\"many_to_one\")\n",
        "\n",
        "    missing = df[\"player_name\"].isna().sum()\n",
        "    if missing:\n",
        "        logger.warning(\"%d attempts missing kicker metadata\", missing)\n",
        "    logger.info(\"Merged shape: %s rows Ã— %s cols\", *df.shape)\n",
        "\n",
        "    print(f\"Merged dataset shape: {df.shape}\")\n",
        "    print(f\"Total field goal attempts: {len(df):,}\")\n",
        "    missing = df[\"player_name\"].isna().sum()\n",
        "    print(f\"Attempts with missing kicker info: {missing}\")\n",
        "    print(\"\\nFirst 5 rows of merged dataset:\")\n",
        "    print(df.head(5))\n",
        "    return df\n",
        "\n",
        "\n",
        "def basic_overview(df: pd.DataFrame) -> None:\n",
        "    print(\"\\nâ”€ BASIC OVERVIEW â”€\")\n",
        "    print(\"Data types:\")\n",
        "    print(df.dtypes)\n",
        "    print(\"\\nFull info:\")\n",
        "    print(df.info())\n",
        "    dupes = df.duplicated().sum()\n",
        "    print(f\"\\nDuplicate rows: {dupes}\")\n",
        "    print(f\"\\nUnique seasons: {sorted(df['season'].unique())}\")\n",
        "    print(f\"Season types: {df['season_type'].unique()}\")\n",
        "    print(f\"Field goal results: {df['field_goal_result'].unique()}\")\n",
        "    print(f\"Unique kickers: {df['player_name'].nunique()}\")\n",
        "    # date range/span\n",
        "    if \"game_date\" in df.columns:\n",
        "        rng = df[\"game_date\"]\n",
        "        if not np.issubdtype(rng.dtype, np.datetime64):\n",
        "            rng = pd.to_datetime(rng)\n",
        "        print(f\"\\nDate range: {rng.min()} to {rng.max()}\")\n",
        "        print(f\"Span: {rng.max() - rng.min()}\")\n",
        "\n",
        "\n",
        "def basic_overview(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Print highâ€‘level schema info mirroring the notebook's *SectionÂ 2*.\"\"\"\n",
        "    print(\"\\nâ”€ BASIC OVERVIEW â”€\")\n",
        "    print(df.dtypes)\n",
        "    print(\"\\nUnique kickers:\", df[\"player_name\"].nunique())\n",
        "    print(\"Seasons:\", sorted(df[\"season\"].unique()))\n",
        "    dupe = df.duplicated().sum()\n",
        "    if dupe:\n",
        "        logger.warning(\"%d duplicate rows detected\", dupe)\n",
        "\n",
        "\n",
        "def prepare_dataset(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    include_preseason: bool = False,\n",
        "    max_distance: int | None = 63,\n",
        "    add_age_feature: bool = True,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Clean/filter & engineer variables exactly as the notebook does.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Filter out preseason unless explicitly requested\n",
        "    if not include_preseason:\n",
        "        df = df[df[\"season_type\"] != _PRESEASON_FLAG]\n",
        "\n",
        "    # Binary target\n",
        "    df[\"success\"] = (df[\"field_goal_result\"] == _FIELD_GOAL_RESULT_SUCCESS).astype(int)\n",
        "\n",
        "    # Remove extreme distances\n",
        "    if max_distance is not None:\n",
        "        df = df[df[\"attempt_yards\"] <= max_distance]\n",
        "\n",
        "    # Feature engineering\n",
        "    df[\"distance_squared\"] = df[\"attempt_yards\"].pow(2)\n",
        "    df[\"is_long_attempt\"] = (df[\"attempt_yards\"] >= 50).astype(int)\n",
        "\n",
        "    # Sort for cumulative counts\n",
        "    df = df.sort_values([\"player_id\", \"game_date\"])\n",
        "    df[\"kicker_attempt_number\"] = df.groupby(\"player_id\").cumcount() + 1\n",
        "\n",
        "    # Age at attempt\n",
        "    if add_age_feature and {\"birthdate\", \"game_date\"}.issubset(df.columns):\n",
        "        df[\"age_at_attempt\"] = (\n",
        "            (df[\"game_date\"] - df[\"birthdate\"]).dt.days / 365.25\n",
        "        ).round(2)\n",
        "\n",
        "    logger.info(\"Prepared tidy dataset â†’ %s rows\", len(df))\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ analytical helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ analytical helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def outcome_summary(\n",
        "    df: pd.DataFrame,\n",
        "    savefig: Path | None = None,\n",
        ") -> Tuple[pd.Series, plt.Figure]:\n",
        "    \"\"\"Outcome counts + pie/bar figure (adds binary-distribution prints).\"\"\"\n",
        "    counts = df[\"field_goal_result\"].value_counts()\n",
        "    success_rate = (df[\"success\"]).mean()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    counts.plot.pie(ax=ax1, autopct=\"%1.1f%%\", startangle=90)\n",
        "    ax1.set_ylabel(\"\")\n",
        "    ax1.set_title(\"Regular-Season Field-Goal Outcomes\")\n",
        "\n",
        "    season_success = df.groupby(\"season_type\")[\"success\"].mean()\n",
        "    sns.barplot(\n",
        "        x=season_success.index,\n",
        "        y=season_success.values,\n",
        "        palette=[\"lightblue\", \"orange\"],\n",
        "        ax=ax2,\n",
        "    )\n",
        "    ax2.set_title(\"Success Rate by Season Type\")\n",
        "    ax2.set_ylabel(\"Success Rate\")\n",
        "    ax2.set_xlabel(\"\")\n",
        "    ax2.set_ylim(0.7, 0.9)\n",
        "    for i, v in enumerate(season_success.values):\n",
        "        ax2.text(i, v + 0.01, f\"{v:.1%}\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if savefig:\n",
        "        fig.savefig(savefig, dpi=150, bbox_inches=\"tight\")\n",
        "\n",
        "    # ðŸ†• notebook-style console echoes\n",
        "    print(f\"\\nBinary target distribution â€” Success (Made): {df['success'].sum():,}\"\n",
        "          f\" ({success_rate:.1%}) | Failure: {(1-success_rate):.1%}\")\n",
        "\n",
        "    return counts, fig\n",
        "\n",
        "\n",
        "def distance_analysis(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    min_attempts: int = 3,\n",
        "    savefig: Path | None = None,\n",
        ") -> Tuple[pd.DataFrame, plt.Figure]:\n",
        "    \"\"\"Histogram + scatter + box-plot + printed distance buckets.\"\"\"\n",
        "    summary = (\n",
        "        df.groupby(\"attempt_yards\")[\"success\"]\n",
        "        .agg(success_rate=\"mean\", attempts=\"size\")\n",
        "        .query(\"attempts >= @min_attempts\")\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    # Define distance buckets exactly as the notebook\n",
        "    buckets = [\n",
        "        (18, 29, \"Short (18-29)\"),\n",
        "        (30, 39, \"Medium-Short (30-39)\"),\n",
        "        (40, 49, \"Medium (40-49)\"),\n",
        "        (50, 59, \"Long (50-59)\"),\n",
        "        (60, 75, \"Extreme (60+)\"),\n",
        "    ]\n",
        "\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 14))\n",
        "\n",
        "    # A) Histogram\n",
        "    sns.histplot(df[\"attempt_yards\"], bins=30, edgecolor=\"black\",\n",
        "                 color=\"skyblue\", ax=ax1)\n",
        "    ax1.set_title(\"Distribution of Field-Goal Attempt Distances\")\n",
        "    ax1.set_xlabel(\"Distance (yards)\")\n",
        "\n",
        "    # B) Scatter + quadratic trend\n",
        "    sizes = summary[\"attempts\"] / 2\n",
        "    ax2.scatter(summary[\"attempt_yards\"], summary[\"success_rate\"],\n",
        "                s=sizes, alpha=0.6, color=\"darkblue\")\n",
        "    z = np.polyfit(summary[\"attempt_yards\"], summary[\"success_rate\"], 2)\n",
        "    ax2.plot(\n",
        "        np.unique(summary[\"attempt_yards\"]),\n",
        "        np.poly1d(z)(np.unique(summary[\"attempt_yards\"])),\n",
        "        \"r--\", linewidth=2,\n",
        "    )\n",
        "    ax2.set_title(\"Success Rate vs Distance (bubble = attempts)\")\n",
        "    ax2.set_xlabel(\"Distance (yards)\")\n",
        "    ax2.set_ylabel(\"Success Rate\")\n",
        "    ax2.set_ylim(0, 1.05)\n",
        "\n",
        "    # C) Box-plot by outcome\n",
        "    sns.boxplot(\n",
        "        x=\"field_goal_result\",\n",
        "        y=\"attempt_yards\",\n",
        "        data=df,\n",
        "        ax=ax3,\n",
        "        palette=\"Set2\",\n",
        "    )\n",
        "    ax3.set_title(\"Distance Distribution by Outcome\")\n",
        "    ax3.set_xlabel(\"\")\n",
        "    ax3.set_ylabel(\"Distance (yards)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if savefig:\n",
        "        fig.savefig(savefig, dpi=150, bbox_inches=\"tight\")\n",
        "\n",
        "    # ðŸ†• Print bucketed success rates\n",
        "    print(\"\\nSuccess rates by distance range:\")\n",
        "    for lo, hi, label in buckets:\n",
        "        mask = (df[\"attempt_yards\"] >= lo) & (df[\"attempt_yards\"] <= hi)\n",
        "        if mask.any():\n",
        "            rate = df.loc[mask, \"success\"].mean()\n",
        "            print(f\"{label}: {rate:.1%} ({mask.sum():,} attempts)\")\n",
        "\n",
        "    return summary, fig\n",
        "\n",
        "\n",
        "def temporal_analysis(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    savefig: Path | None = None,\n",
        ") -> Tuple[pd.DataFrame, plt.Figure]:\n",
        "    \"\"\"Season trend, week quartiles, age histogram, age-group prints.\"\"\"\n",
        "    season_df = (\n",
        "        df.groupby(\"season\")\n",
        "        .agg(success_rate=(\"success\", \"mean\"),\n",
        "             total_attempts=(\"success\", \"size\"),\n",
        "             avg_distance=(\"attempt_yards\", \"mean\"))\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    # Ensure age feature exists\n",
        "    if \"age_at_attempt\" not in df.columns:\n",
        "        if {\"birthdate\", \"game_date\"}.issubset(df.columns):\n",
        "            df = df.copy()\n",
        "            df[\"age_at_attempt\"] = (df[\"game_date\"] - df[\"birthdate\"]).dt.days / 365.25\n",
        "\n",
        "    # ðŸ†• week-level success print\n",
        "    week_trends = df.groupby(\"week\")[\"success\"].mean()\n",
        "    print(\"\\nSuccess rate by season-quarter weeks:\")\n",
        "    quarters = {\n",
        "        \"Weeks 1-4\": week_trends.loc[1:4].mean(),\n",
        "        \"Weeks 5-8\": week_trends.loc[5:8].mean(),\n",
        "        \"Weeks 9-12\": week_trends.loc[9:12].mean(),\n",
        "        \"Weeks 13-17\": week_trends.loc[13:17].mean(),\n",
        "    }\n",
        "    for k, v in quarters.items():\n",
        "        print(f\"{k}: {v:.1%}\")\n",
        "\n",
        "    # ðŸ†• age-group print\n",
        "    age_bins = [(0, 25), (25, 30), (30, 35), (35, 45)]\n",
        "    print(\"\\nSuccess rate by age group:\")\n",
        "    for lo, hi in age_bins:\n",
        "        grp = df[(df[\"age_at_attempt\"] >= lo) & (df[\"age_at_attempt\"] < hi)]\n",
        "        if grp.empty:\n",
        "            continue\n",
        "        print(f\"{lo:>2}-{hi:<2}: {grp['success'].mean():.1%} \"\n",
        "              f\"({len(grp):,} attempts, avg {grp['attempt_yards'].mean():.1f} yds)\")\n",
        "\n",
        "    # -------- figures (unchanged layout) --------\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    ax1.plot(season_df[\"season\"], season_df[\"success_rate\"],\n",
        "             marker=\"o\", linewidth=2)\n",
        "    ax1.set_title(\"Field-Goal Success Rate by Season\")\n",
        "    ax1.set_ylabel(\"Success Rate\")\n",
        "\n",
        "    ax2.plot(season_df[\"season\"], season_df[\"avg_distance\"],\n",
        "             marker=\"s\", color=\"orange\", linewidth=2)\n",
        "    ax2.set_title(\"Average Distance by Season\")\n",
        "    ax2.set_ylabel(\"Distance (yards)\")\n",
        "\n",
        "    sns.histplot(df[\"age_at_attempt\"].dropna(), bins=20, edgecolor=\"black\",\n",
        "                 color=\"green\", ax=ax3)\n",
        "    ax3.axvline(df[\"age_at_attempt\"].mean(), color=\"red\", linestyle=\"--\", label=\"Mean\")\n",
        "    ax3.set_title(\"Distribution of Kicker Ages at Attempt\")\n",
        "    ax3.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if savefig:\n",
        "        fig.savefig(savefig, dpi=150, bbox_inches=\"tight\")\n",
        "\n",
        "    return season_df, fig\n",
        "\n",
        "\n",
        "\n",
        "def kicker_performance_analysis(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    min_attempts: int = 20,\n",
        "    savefig: Path | None = None,\n",
        ") -> Tuple[pd.DataFrame, plt.Figure]:\n",
        "    \"\"\"Perâ€‘kicker stats + fourâ€‘plot dashboard (SectionÂ 5 visuals).\"\"\"\n",
        "    stats_df = (\n",
        "        df.groupby([\"player_name\", \"player_id\"])\n",
        "        .agg(\n",
        "            total_attempts=(\"success\", \"size\"),\n",
        "            made=(\"success\", \"sum\"),\n",
        "            success_rate=(\"success\", \"mean\"),\n",
        "            avg_distance=(\"attempt_yards\", \"mean\"),\n",
        "            min_distance=(\"attempt_yards\", \"min\"),\n",
        "            max_distance=(\"attempt_yards\", \"max\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    sns.histplot(stats_df[\"total_attempts\"], bins=20, edgecolor=\"black\", ax=axes[0, 0], color=\"lightgreen\")\n",
        "    axes[0, 0].axvline(stats_df[\"total_attempts\"].median(), color=\"red\", linestyle=\"--\", label=\"Median\")\n",
        "    axes[0, 0].set_title(\"Distribution of Attempts per Kicker\")\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    experienced = stats_df.query(\"total_attempts >= @min_attempts\")\n",
        "    sns.histplot(experienced[\"success_rate\"], bins=15, edgecolor=\"black\", ax=axes[0, 1], color=\"lightcoral\")\n",
        "    axes[0, 1].axvline(experienced[\"success_rate\"].median(), color=\"red\", linestyle=\"--\", label=\"Median\")\n",
        "    axes[0, 1].set_title(f\"Success Rate Distribution (â‰¥{min_attempts} attempts)\")\n",
        "    axes[0, 1].legend()\n",
        "\n",
        "    axes[1, 0].scatter(stats_df[\"total_attempts\"], stats_df[\"success_rate\"], alpha=0.6, color=\"purple\")\n",
        "    z = np.polyfit(stats_df[\"total_attempts\"], stats_df[\"success_rate\"], 1)\n",
        "    axes[1, 0].plot(stats_df[\"total_attempts\"], np.poly1d(z)(stats_df[\"total_attempts\"]), \"r--\")\n",
        "    axes[1, 0].set_title(\"Success Rate vs Total Attempts\")\n",
        "    axes[1, 0].set_xlabel(\"Total Attempts\")\n",
        "    axes[1, 0].set_ylabel(\"Success Rate\")\n",
        "\n",
        "    bubble = experienced[\"total_attempts\"] / 5\n",
        "    axes[1, 1].scatter(experienced[\"avg_distance\"], experienced[\"success_rate\"], s=bubble, alpha=0.6, color=\"orange\")\n",
        "    axes[1, 1].set_title(\"Success Rate vs Average Distance (bubble = attempts)\")\n",
        "    axes[1, 1].set_xlabel(\"Average Attempt Distance (yards)\")\n",
        "    axes[1, 1].set_ylabel(\"Success Rate\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if savefig:\n",
        "        fig.savefig(savefig, dpi=150, bbox_inches=\"tight\")\n",
        "    return stats_df, fig\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def feature_engineering(df: pd.DataFrame, savefig: Path | None = None) -> plt.Figure:\n",
        "    \"\"\"Correlation heatmap of engineered numeric variables (SectionÂ 7 visuals).\"\"\"\n",
        "    numeric_cols = [\n",
        "        \"attempt_yards\",\n",
        "        \"distance_squared\",\n",
        "        \"season\",\n",
        "        \"week\",\n",
        "        \"age_at_attempt\",\n",
        "        \"kicker_attempt_number\",\n",
        "        \"success\",\n",
        "    ]\n",
        "    corr = df[numeric_cols].corr()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
        "    ax.set_title(\"Feature Correlation Matrix\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if savefig:\n",
        "        fig.savefig(savefig, dpi=150, bbox_inches=\"tight\")\n",
        "    return fig\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ sanity guards â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ utils â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def _loess_smooth(x: np.ndarray, y: np.ndarray, frac: float = 0.25) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Lightweight LOESS smoother used only for sanity checking.\n",
        "    Falls back to a centred 3-point rolling mean if statsmodels isnâ€™t present.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "        return lowess(y, x, frac=frac, return_sorted=False)\n",
        "    except ImportError:\n",
        "        return pd.Series(y).rolling(3, center=True, min_periods=1).mean().values\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ sanity guards â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def quick_sanity_checks(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    tol: float = 0.04,\n",
        "    min_count: int = 5,\n",
        "    check_monotonic: bool = False,   # âŸµ new\n",
        "    verbose: bool = False,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Fast data-quality assertions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tol : float\n",
        "        Max allowed jump in success rate between **smoothed** adjacent yardages.\n",
        "    min_count : int\n",
        "        Minimum attempt count to include a yardage in the check.\n",
        "    check_monotonic : bool\n",
        "        If True, raise on monotonicity violations; otherwise only log warnings.\n",
        "    verbose : bool\n",
        "        Print full list of violations.\n",
        "    \"\"\"\n",
        "    # 1. Duplicates\n",
        "    if df.duplicated().any():\n",
        "        raise AssertionError(\"Duplicate rows detected\")\n",
        "\n",
        "    # 2. Missing kicker names\n",
        "    n_missing = df[\"player_name\"].isna().sum()\n",
        "    if n_missing:\n",
        "        raise AssertionError(f\"Missing player_name in {n_missing} rows\")\n",
        "\n",
        "    # 3. Distance-success monotonicity  (optional)\n",
        "    grp = df.groupby(\"attempt_yards\")\n",
        "    counts = grp.size()\n",
        "    rates  = grp[\"success\"].mean()\n",
        "    rates  = rates[counts >= min_count].sort_index()\n",
        "    if rates.empty:\n",
        "        logger.warning(\"Monotonicity check skipped â€“ no yardage meets min_count=%d\", min_count)\n",
        "        return\n",
        "\n",
        "    smooth = _loess_smooth(rates.index.values, rates.values)\n",
        "    deltas = np.diff(smooth)\n",
        "    bad_idx = np.where(np.abs(deltas) > tol)[0]      # indices in the *diff* array\n",
        "    if bad_idx.size:\n",
        "        yards = rates.index.values[1:][bad_idx]\n",
        "        if verbose or (check_monotonic and bad_idx.size < 20):\n",
        "            for y, d in zip(yards, deltas[bad_idx]):\n",
        "                logger.warning(\"Î” success@%dy = %+0.3f  (n=%d)\", y, d, counts[y])\n",
        "        msg = f\"Distance-success curve violations at {len(yards)} yardages; tol={tol:.2%}\"\n",
        "        if check_monotonic:\n",
        "            raise AssertionError(msg)\n",
        "        else:\n",
        "            logger.warning(msg + \"  â€“ continuing because check_monotonic=False\")\n",
        "    else:\n",
        "        logger.info(\"Success-distance curve looks monotonic within Â±%.1f %%\", tol*100)\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ orchestrator API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def run_full_eda(\n",
        "    kickers_csv: Path | str,\n",
        "    attempts_csv: Path | str,\n",
        "    *,\n",
        "    output_dir: Path | str = \"figures\",\n",
        "    include_preseason: bool = False,\n",
        "    max_distance: int | None = 63,\n",
        "    check_monotonic: bool = False,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Single convenience entry â€“ replicates the entire notebook flow.\"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 1) Load & merge raw data\n",
        "    print(\"â”€â”€ Section 1 Load & Merge â”€â”€\")\n",
        "    df_raw = load_and_merge(kickers_csv, attempts_csv)\n",
        "\n",
        "    # 2) Dataâ€quality & basic info\n",
        "    print(\"â”€â”€ Section 2 Data Quality & Basic Info â”€â”€\")\n",
        "    basic_overview(df_raw)\n",
        "\n",
        "    # 3) Prepare & engineer the dataset (adds 'success', drops Pre, filters distance, etc.)\n",
        "    print(\"â”€â”€ Section 3 Prepare Dataset â”€â”€\")\n",
        "    df = prepare_dataset(\n",
        "        df_raw,\n",
        "        include_preseason=include_preseason,\n",
        "        max_distance=max_distance,\n",
        "    )\n",
        "\n",
        "    # 4) Outcome analysis (now that df has 'success')\n",
        "    print(\"â”€â”€ Section 4 Outcome Analysis â”€â”€\")\n",
        "    outcome_summary(df, output_dir / \"outcomes.png\")\n",
        "\n",
        "    # 5) Distanceâ€success analysis\n",
        "    print(\"â”€â”€ Section 5 Distance Analysis â”€â”€\")\n",
        "    distance_analysis(df, savefig=output_dir / \"distance.png\")\n",
        "\n",
        "    # 6) Kicker performance dashboard\n",
        "    print(\"â”€â”€ Section 6 Kicker Performance â”€â”€\")\n",
        "    kicker_performance_analysis(df, savefig=output_dir / \"kicker_dashboard.png\")\n",
        "\n",
        "    # 7) Temporal factors\n",
        "    print(\"â”€â”€ Section 7 Temporal Factors â”€â”€\")\n",
        "    temporal_analysis(df, savefig=output_dir / \"temporal.png\")\n",
        "\n",
        "    # 8) Feature correlation\n",
        "    print(\"â”€â”€ Section 8 Feature Engineering â”€â”€\")\n",
        "    feature_engineering(df, savefig=output_dir / \"correlation.png\")\n",
        "\n",
        "    # 9) Final sanity checks\n",
        "    print(\"â”€â”€ Section 9 Sanity Checks â”€â”€\")\n",
        "    quick_sanity_checks(df, check_monotonic=check_monotonic)\n",
        "\n",
        "    logger.info(\"All figures saved in %s\", output_dir.resolve())\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI demo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths configurable via env or CLI args as needed\n",
        "    KICKERS = Path(\"data/raw/kickers.csv\")\n",
        "    ATTEMPTS = Path(\"data/raw/field_goal_attempts.csv\")\n",
        "\n",
        "    # Endâ€‘toâ€‘end run replicating the notebook defaults\n",
        "    df_model = run_full_eda(KICKERS, ATTEMPTS)\n",
        "\n",
        "    out = Path(\"data/processed/field_goal_modeling_data.csv\")\n",
        "    out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    df_model.to_csv(out, index=False)\n",
        "    logger.info(\"Processed dataset saved â†’ %s (%s rows)\", out, len(df_model))\n",
        "\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"COMPREHENSIVE EDA SUMMARY AND MODELING RECOMMENDATIONS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\"\"\n",
        "     PROBLEM DEFINITION\n",
        "    â€¢ Binary classification problem: Predict field goal success (Made vs Missed/Blocked)\n",
        "    â€¢ Target distribution: {df_model['success'].mean():.1%} success rate (manageable imbalance)\n",
        "    â€¢ Dataset: {len(df_model):,} regular season field goal attempts (2010-2018)\n",
        "\n",
        "     KEY FINDINGS\n",
        "\n",
        "    1. DISTANCE IS THE DOMINANT FACTOR\n",
        "    â€¢ Strong negative correlation with success (-0.685)\n",
        "    â€¢ Non-linear relationship: ~99% success at 18-20 yards â†’ ~0% at 60+ yards\n",
        "    â€¢ Success drops sharply after 50 yards (long range threshold)\n",
        "\n",
        "    2. KICKER DIFFERENCES ARE SIGNIFICANT\n",
        "    â€¢ {df_model['player_name'].nunique()} unique kickers with vastly different performance levels\n",
        "    â€¢ Raw success rates range from ~60% to ~95% among experienced kickers\n",
        "    â€¢ Sample sizes vary dramatically: 1 to 300+ attempts per kicker\n",
        "    â€¢ Clear evidence for kicker-specific modeling\n",
        "\n",
        "    3. TEMPORAL PATTERNS ARE MINIMAL\n",
        "    â€¢ Success rates stable across seasons (83-86%)\n",
        "    â€¢ No major trends in attempt difficulty over time\n",
        "    â€¢ Week and age effects are minor compared to distance and kicker skill\n",
        "\n",
        "    4. DATA QUALITY IS EXCELLENT\n",
        "    â€¢ No missing values in key variables\n",
        "    â€¢ Clean, well-structured data ready for modeling\n",
        "    â€¢ Minimal outliers (removed extreme distances >63 yards)\n",
        "\n",
        "     RECOMMENDED MODELING APPROACH\n",
        "\n",
        "    PRIMARY MODEL: Hierarchical Bayesian Logistic Regression\n",
        "    âœ“ Handles varying sample sizes per kicker elegantly\n",
        "    âœ“ Provides uncertainty quantification for ratings\n",
        "    âœ“ Natural pooling of information across kickers\n",
        "    âœ“ Logistic function matches distance-success relationship\n",
        "\n",
        "    MODEL SPECIFICATION:\n",
        "    success_ij ~ Bernoulli(p_ij)\n",
        "    logit(p_ij) = Î±_j + Î² * distance_ij\n",
        "    Î±_j ~ Normal(Î¼_Î±, Ïƒ_Î±)  [kicker random effects]\n",
        "\n",
        "    ALTERNATIVE MODELS for comparison:\n",
        "    â€¢ Regularized logistic regression (Ridge/Lasso)\n",
        "    â€¢ Random Forest (for non-linear interactions)\n",
        "    â€¢ XGBoost (gradient boosting)\n",
        "\n",
        "     FEATURE ENGINEERING RECOMMENDATIONS\n",
        "\n",
        "    ESSENTIAL FEATURES:\n",
        "    â€¢ attempt_yards (primary predictor)\n",
        "    â€¢ player_name/player_id (kicker identity)\n",
        "\n",
        "    POTENTIAL ENHANCEMENTS:\n",
        "    â€¢ distance_squared (for non-linearity)\n",
        "    â€¢ is_long_attempt (50+ yard flag)\n",
        "    â€¢ kicker_attempt_number (experience effect)\n",
        "    â€¢ season trends (if needed)\n",
        "\n",
        "    EVALUATION STRATEGY\n",
        "\n",
        "    METRICS:\n",
        "    â€¢ Brier Score (calibration of probabilities)\n",
        "    â€¢ Log Loss (proper scoring rule)\n",
        "    â€¢ AUC-ROC (discrimination ability)\n",
        "    â€¢ Custom: Expected Points Added per attempt\n",
        "\n",
        "    VALIDATION:\n",
        "    â€¢ Time-based split (train: 2010-2017, test: 2018)\n",
        "    â€¢ Cross-validation with kicker groups\n",
        "    â€¢ Out-of-sample kicker prediction (new kickers)\n",
        "\n",
        "     EXPECTED OUTCOMES\n",
        "\n",
        "    The model will enable:\n",
        "    â€¢ Accurate field goal success probability prediction\n",
        "    â€¢ Fair kicker evaluation accounting for attempt difficulty\n",
        "    â€¢ Expected points calculation for strategic decisions\n",
        "    â€¢ Identification of clutch vs. situational performance\n",
        "\n",
        "    DATA PREPARATION STATUS: ******* COMPLETE\n",
        "    Next step: Implement hierarchical Bayesian model\n",
        "    \"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration Module\n",
        "\n",
        "Central configuration for the entire package.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/data/feature_schema.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/data/feature_schema.py\n",
        "\"\"\"\n",
        "FeatureSchema â€“ canonical column lists for preprocessing & modelling.\n",
        "\"\"\"\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FeatureSchema:\n",
        "    \"\"\"Container class listing every column by semantic type.\"\"\"\n",
        "    numerical: List[str] = field(default_factory=list)\n",
        "    binary:    List[str] = field(default_factory=list)      # 0/1 ints\n",
        "    ordinal:   List[str] = field(default_factory=list)      # ordered integers\n",
        "    nominal:   List[str] = field(default_factory=list)      # unordered cats / high-card\n",
        "    target:    str        = \"success\"\n",
        "\n",
        "    # â”€â”€â”€â”€â”€ convenience helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    @property\n",
        "    def model_features(self) -> List[str]:\n",
        "        \"\"\"All predictors in modelling order.\"\"\"\n",
        "        return self.numerical + self.binary + self.ordinal + self.nominal\n",
        "\n",
        "    def assert_in_dataframe(self, df) -> None:\n",
        "        \"\"\"Raise if any declared column is missing from df.columns.\"\"\"\n",
        "        missing = [c for c in self.model_features + [self.target]\n",
        "                   if c not in df.columns]\n",
        "        if missing:\n",
        "            raise ValueError(f\"FeatureSchema mismatch â€“ missing cols: {missing}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test the feature schema\n",
        "    schema = FeatureSchema()\n",
        "    # sample features\n",
        "    FeatureSchema.numerical = ['distance', 'weather_condition', 'time_of_day']\n",
        "    FeatureSchema.binary = ['is_home', 'is_playoff']\n",
        "    FeatureSchema.ordinal = ['weather_temperature']\n",
        "    FeatureSchema.nominal = ['weather_type', 'team_name']\n",
        "    FeatureSchema.target = 'success'\n",
        "\n",
        "    print(schema.model_features)\n",
        "    print(schema.assert_in_dataframe(pd.DataFrame()))\n",
        "    print(\"******* FeatureSchema tests passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/config.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/config.py\n",
        "\"\"\"\n",
        "Configuration module for NFL Kicker Analysis package.\n",
        "Contains all constants, paths, and configuration parameters.\n",
        "\"\"\"\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "import os\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Main configuration class for the NFL Kicker Analysis package.\"\"\"\n",
        "\n",
        "    # Data paths\n",
        "    DATA_DIR = Path(\"data\")\n",
        "    RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
        "    PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
        "    OUTPUT_DIR = Path(\"output\")\n",
        "\n",
        "    # Raw data files\n",
        "    KICKERS_FILE = RAW_DATA_DIR / \"kickers.csv\"\n",
        "    ATTEMPTS_FILE = RAW_DATA_DIR / \"field_goal_attempts.csv\"\n",
        "\n",
        "    # Processed data files\n",
        "    MODELING_DATA_FILE = PROCESSED_DATA_DIR / \"field_goal_modeling_data.csv\"\n",
        "    LEADERBOARD_FILE = PROCESSED_DATA_DIR / \"leaderboard.csv\"\n",
        "\n",
        "    # Analysis parameters\n",
        "    MIN_DISTANCE = 18\n",
        "    MAX_DISTANCE = 63\n",
        "    MIN_KICKER_ATTEMPTS = 5\n",
        "\n",
        "    # Distance profile for EPA calculation\n",
        "    DISTANCE_PROFILE = [20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
        "    DISTANCE_WEIGHTS = [0.05, 0.10, 0.20, 0.20, 0.20, 0.15, 0.08, 0.02, 0.01]\n",
        "\n",
        "    # Distance ranges for analysis\n",
        "    DISTANCE_RANGES = [\n",
        "        (18, 29, \"Short (18-29 yards)\"),\n",
        "        (30, 39, \"Medium-Short (30-39 yards)\"),\n",
        "        (40, 49, \"Medium (40-49 yards)\"),\n",
        "        (50, 59, \"Long (50-59 yards)\"),\n",
        "        (60, 75, \"Extreme (60+ yards)\")\n",
        "    ]\n",
        "\n",
        "    # Model parameters\n",
        "    BAYESIAN_MCMC_SAMPLES = 2000\n",
        "    BAYESIAN_TUNE = 1000\n",
        "    BAYESIAN_CHAINS = 2\n",
        "\n",
        "    # Rating thresholds\n",
        "    ELITE_THRESHOLD = 0.15\n",
        "    STRUGGLING_THRESHOLD = -0.20\n",
        "\n",
        "    # Visualization settings\n",
        "    FIGURE_SIZE = (12, 8)\n",
        "    DPI = 100\n",
        "\n",
        "    # Season types to include\n",
        "    SEASON_TYPES = ['Reg']  # Regular season only by default\n",
        "\n",
        "    # â”€â”€â”€ Feature flags â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    FILTER_RETIRED_INJURED = False   # keep everyone by default\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def ensure_directories(cls):\n",
        "        \"\"\"Create necessary directories if they don't exist.\"\"\"\n",
        "        for dir_path in [cls.RAW_DATA_DIR, cls.PROCESSED_DATA_DIR, cls.OUTPUT_DIR]:\n",
        "            dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create global config instance\n",
        "config = Config()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Feature catalogue â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Single source of truth for column roles â€“ centralized from all modules\n",
        "FEATURE_LISTS: Dict[str, List[str]] = {\n",
        "    \"numerical\": [\n",
        "        \"attempt_yards\", \"age_at_attempt\", \"distance_squared\",\n",
        "        \"career_length_years\", \"season_progress\", \"exp_100\",   # ðŸ‘ˆ NEW\n",
        "        \"rolling_success_rate\", \"current_streak\",\n",
        "        \"distance_zscore\", \"distance_percentile\",\n",
        "        \"seasons_of_experience\", \"career_year\",\n",
        "        \"age_c\", \"age_c2\",  # ðŸ‘ˆ NEW: centered age variables\n",
        "        # \"age_spline_1\", \"age_spline_2\", \"age_spline_3\",\n",
        "        \"importance\", \"days_since_last_kick\",  # Days since player's last field goal\n",
        "        \"age_dist_interact\", \"exp_dist_interact\",  # ðŸ‘ˆ NEW: interaction terms\n",
        "    ],\n",
        "    \"ordinal\": [\"season\", \"week\", \"month\", \"day_of_year\"],\n",
        "    \"nominal\": [\n",
        "        \"kicker_id\", \"kicker_idx\",\n",
        "        \"is_long_attempt\", \"is_very_long_attempt\",\n",
        "        \"is_rookie_attempt\", \"distance_category\", \"experience_category\",\n",
        "        \"is_early_season\", \"is_late_season\", \"is_playoffs\",\n",
        "        # \"player_status\",  # âœ… Removed: Status should never be a predictor\n",
        "    ],\n",
        "    \"y_variable\": [\"success\"],\n",
        "}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test the configuration\n",
        "    print(\"NFL Kicker Analysis Configuration\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Data directory: {config.DATA_DIR}\")\n",
        "    print(f\"Min distance: {config.MIN_DISTANCE}\")\n",
        "    print(f\"Max distance: {config.MAX_DISTANCE}\")\n",
        "    print(f\"Distance profile: {config.DISTANCE_PROFILE}\")\n",
        "    print(f\"Elite threshold: {config.ELITE_THRESHOLD}\")\n",
        "\n",
        "    # Test directory creation\n",
        "    config.ensure_directories()\n",
        "    print(\"******* Configuration loaded and directories created!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Data Loading Module\n",
        "\n",
        "Handles loading and merging of raw kicker data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/data/loader.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/data/loader.py\n",
        "\"\"\"\n",
        "Data loading module for NFL kicker analysis.\n",
        "Handles loading and merging of raw datasets.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple\n",
        "import warnings\n",
        "\n",
        "from src.nfl_kicker_analysis.config import config\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Handles loading and initial merging of kicker datasets.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the data loader.\"\"\"\n",
        "        self.kickers_df = None\n",
        "        self.attempts_df = None\n",
        "        self.merged_df = None\n",
        "\n",
        "    def load_kickers(self, filepath: Optional[Path] = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Load kicker metadata.\n",
        "\n",
        "        Args:\n",
        "            filepath: Optional path to kickers CSV file\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with kicker information\n",
        "        \"\"\"\n",
        "        if filepath is None:\n",
        "            filepath = config.KICKERS_FILE\n",
        "\n",
        "        try:\n",
        "            self.kickers_df = pd.read_csv(filepath)\n",
        "            print(f\"******* Loaded {len(self.kickers_df)} kickers from {filepath}\")\n",
        "            return self.kickers_df\n",
        "        except FileNotFoundError:\n",
        "            raise FileNotFoundError(f\"Kickers data file not found: {filepath}\")\n",
        "\n",
        "    def load_attempts(self, filepath: Optional[Path] = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Load field goal attempts data.\n",
        "\n",
        "        Args:\n",
        "            filepath: Optional path to attempts CSV file\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with field goal attempt information\n",
        "        \"\"\"\n",
        "        if filepath is None:\n",
        "            filepath = config.ATTEMPTS_FILE\n",
        "\n",
        "        try:\n",
        "            self.attempts_df = pd.read_csv(filepath)\n",
        "            print(f\"******* Loaded {len(self.attempts_df)} field goal attempts from {filepath}\")\n",
        "            return self.attempts_df\n",
        "        except FileNotFoundError:\n",
        "            raise FileNotFoundError(f\"Attempts data file not found: {filepath}\")\n",
        "\n",
        "    def merge_datasets(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Merge kickers and attempts datasets.\n",
        "\n",
        "        Returns:\n",
        "            Merged DataFrame with kicker names attached to attempts\n",
        "        \"\"\"\n",
        "        if self.kickers_df is None:\n",
        "            self.load_kickers()\n",
        "        if self.attempts_df is None:\n",
        "            self.load_attempts()\n",
        "\n",
        "        # Merge on player_id\n",
        "        self.merged_df = pd.merge(\n",
        "            self.attempts_df,\n",
        "            self.kickers_df,\n",
        "            on='player_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Validate merge\n",
        "        missing_kickers = self.merged_df['player_name'].isnull().sum()\n",
        "        if missing_kickers > 0:\n",
        "            warnings.warn(f\"Found {missing_kickers} attempts with missing kicker info\")\n",
        "\n",
        "        print(f\"******* Merged dataset: {self.merged_df.shape[0]} attempts, {self.merged_df.shape[1]} columns\")\n",
        "        return self.merged_df\n",
        "\n",
        "    def load_complete_dataset(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Load and merge complete dataset in one call.\n",
        "\n",
        "        Returns:\n",
        "            Complete merged DataFrame\n",
        "        \"\"\"\n",
        "        self.load_kickers()\n",
        "        self.load_attempts()\n",
        "        return self.merge_datasets()\n",
        "\n",
        "    def get_data_summary(self) -> dict:\n",
        "        \"\"\"\n",
        "        Get summary statistics of loaded data.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with data summary information\n",
        "        \"\"\"\n",
        "        if self.merged_df is None:\n",
        "            raise ValueError(\"No data loaded. Call load_complete_dataset() first.\")\n",
        "\n",
        "        summary = {\n",
        "            'total_attempts': len(self.merged_df),\n",
        "            'unique_kickers': self.merged_df['player_name'].nunique(),\n",
        "            'unique_seasons': sorted(self.merged_df['season'].unique()),\n",
        "            'season_types': self.merged_df['season_type'].unique().tolist(),\n",
        "            'outcome_counts': self.merged_df['field_goal_result'].value_counts().to_dict(),\n",
        "            'date_range': (\n",
        "                self.merged_df['game_date'].min(),\n",
        "                self.merged_df['game_date'].max()\n",
        "            ),\n",
        "            'distance_range': (\n",
        "                self.merged_df['attempt_yards'].min(),\n",
        "                self.merged_df['attempt_yards'].max()\n",
        "            )\n",
        "        }\n",
        "        return summary\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test the data loader\n",
        "    print(\"Testing DataLoader...\")\n",
        "\n",
        "    loader = DataLoader()\n",
        "\n",
        "    try:\n",
        "        # Load complete dataset\n",
        "        df = loader.load_complete_dataset()\n",
        "        print(\"---------------head-----------------\")\n",
        "        print(df.head())\n",
        "        print(\"---------------columns-----------------\")\n",
        "        print(df.columns)\n",
        "\n",
        "        # Print summary\n",
        "        summary = loader.get_data_summary()\n",
        "        print(\"\\nData Summary:\")\n",
        "        print(summary)\n",
        "        print(f\"Total attempts: {summary['total_attempts']:,}\")\n",
        "        print(f\"Unique kickers: {summary['unique_kickers']}\")\n",
        "        print(f\"season_types: {summary['season_types']}\")\n",
        "        print(f\"Seasons: {summary['unique_seasons']}\")\n",
        "        print(f\"Outcomes: {summary['outcome_counts']}\")\n",
        "\n",
        "        print(\"******* DataLoader tests passed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"------------- Error testing DataLoader: {e}\")\n",
        "        print(\"Note: This is expected if data files are not present.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/data/feature_engineering.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/data/feature_engineering.py\n",
        "\"\"\"\n",
        "Feature engineering module for NFL kicker analysis.\n",
        "Contains all feature creation functions that can be used to build features for modeling.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Union, List\n",
        "\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"Handles all feature engineering operations.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the feature engineer.\"\"\"\n",
        "        self.kicker_mapping = None\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # Target / basic temporal features\n",
        "    # ---------------------------------------------------------------------\n",
        "    def create_target_variable(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Create binary success target variable.\"\"\"\n",
        "        df = df.copy()\n",
        "        df[\"success\"] = (df[\"field_goal_result\"] == \"Made\").astype(int)\n",
        "        print(f\"******* Created target variable: {df['success'].mean():.1%} success rate\")\n",
        "        return df\n",
        "\n",
        "    def create_date_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Create date-related features including centered age variables.\n",
        "\n",
        "        Adds:\n",
        "        â€¢ age_at_attempt     â€“ raw age in years\n",
        "        â€¢ age_c              â€“ centred (30 yrs) & scaled (Ã·10) age\n",
        "        â€¢ age_c2             â€“ quadratic term (for simple aging curve)\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # Ensure datetime dtypes\n",
        "        df[\"game_date\"] = pd.to_datetime(df[\"game_date\"])\n",
        "        df[\"birthdate\"] = pd.to_datetime(df[\"birthdate\"])\n",
        "\n",
        "        # Age at attempt\n",
        "        df[\"age_at_attempt\"] = (df[\"game_date\"] - df[\"birthdate\"]).dt.days / 365.25\n",
        "\n",
        "        # Centered & scaled age (Gelman scaling)\n",
        "        df[\"age_c\"]  = (df[\"age_at_attempt\"] - 30.0) / 10.0\n",
        "        df[\"age_c2\"] = df[\"age_c\"] ** 2\n",
        "\n",
        "        # Seasonal features\n",
        "        df[\"day_of_year\"] = df[\"game_date\"].dt.dayofyear\n",
        "        df[\"month\"] = df[\"game_date\"].dt.month\n",
        "        print(\"******* Created date features (age_c, age_c2, day_of_year, month)\")\n",
        "        return df\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # OPTIONAL â€“ continuous spline basis for age (k = 3 knots)\n",
        "    # ------------------------------------------------------------------\n",
        "    def create_age_spline_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Add natural-cubic-spline basis age_spline_1â€¦k (centered & scaled age).\n",
        "        Use when nonlinear aging curve is desired.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            import patsy as ps\n",
        "        except ImportError:\n",
        "            print(\"âš ï¸  patsy not available - skipping age spline features\")\n",
        "            return df\n",
        "\n",
        "        df = df.copy()\n",
        "        # Design matrix returns ndarray with intercept, drop it\n",
        "        spline = ps.dmatrix(\"bs(age_c, df=3, degree=3, include_intercept=False)\",\n",
        "                            df, return_type=\"dataframe\")\n",
        "        # Rename columns nicely\n",
        "        spline.columns = [f\"age_spline_{i+1}\" for i in range(spline.shape[1])]\n",
        "        df = pd.concat([df, spline], axis=1)\n",
        "        print(\"******* Created age spline features\")\n",
        "        return df\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Identifier mapping\n",
        "    # ------------------------------------------------------------------\n",
        "    def create_kicker_mapping(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Adds two columns:\n",
        "          â€¢ kicker_id   â€“ raw player_id from the source (GSIS / Stathead)\n",
        "          â€¢ kicker_idx  â€“ zero-based contiguous index used ONLY for matrix ops\n",
        "        The mapping is cached so that train/test splits share the same indices.\n",
        "        Also preserves player_name for human-readable analysis.\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        df[\"kicker_id\"] = df[\"player_id\"].astype(int)        # â† raw, never mutates\n",
        "        if self.kicker_mapping is None:\n",
        "            unique = df[\"kicker_id\"].unique()\n",
        "            self.kicker_mapping = {pid: i for i, pid in enumerate(sorted(unique))}\n",
        "        df[\"kicker_idx\"] = df[\"kicker_id\"].map(self.kicker_mapping).astype(int)\n",
        "\n",
        "        # Ensure player_name is preserved for name-based operations\n",
        "        # This enables the hybrid approach recommended in the roadmap\n",
        "        if \"player_name\" not in df.columns:\n",
        "            print(\"âš ï¸  WARNING: player_name column not found. Name-based operations may not work.\")\n",
        "\n",
        "        print(f\"******* Created kicker mapping for {len(self.kicker_mapping)} unique kickers \"\n",
        "              f\"(raw_idâ†’idx) with player names preserved\")\n",
        "        return df\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Distance related features\n",
        "    # ------------------------------------------------------------------\n",
        "    def create_distance_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Create distance-based engineered features, with safe log transform.\"\"\"\n",
        "        df = df.copy()\n",
        "        df[\"distance_squared\"] = df[\"attempt_yards\"] ** 2\n",
        "        df[\"distance_cubed\"]   = df[\"attempt_yards\"] ** 3\n",
        "        # Use log1p to handle zero-yard attempts without -inf :contentReference[oaicite:13]{index=13}\n",
        "        df[\"log_distance\"]     = np.log1p(df[\"attempt_yards\"])\n",
        "        df[\"is_long_attempt\"]  = (df[\"attempt_yards\"] >= 50).astype(int)\n",
        "        df[\"is_very_long_attempt\"] = (df[\"attempt_yards\"] >= 55).astype(int)\n",
        "        q1, q2, q3 = df[\"attempt_yards\"].quantile([0.25, 0.5, 0.75])\n",
        "        df[\"distance_category\"] = df[\"attempt_yards\"].apply(\n",
        "            lambda dist: \"Short\" if dist < q1\n",
        "                        else \"Medium-Short\" if dist < q2\n",
        "                        else \"Medium\" if dist < q3\n",
        "                        else \"Long\"\n",
        "        )\n",
        "        df[\"distance_from_sweet_spot\"] = (df[\"attempt_yards\"] - 35).abs()\n",
        "        print(\"******* Created distance features (poly, log, quantile categories, flags)\")\n",
        "        return df\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Experience features\n",
        "    # ------------------------------------------------------------------\n",
        "    def create_experience_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Adds cumulative-experience variables.\n",
        "\n",
        "        Columns created\n",
        "        ---------------\n",
        "        kicker_attempt_number : 1-indexed count (already used elsewhere)\n",
        "        experience_in_kicks   : 0-indexed before current kick\n",
        "        exp_100               : experience_in_kicks / 100  (for stable priors)\n",
        "        is_rookie_attempt     : 1 if first â‰¤20 attempts\n",
        "        experience_category   : Rookie / Developing / Veteran (10th & 25th pct)\n",
        "        career_length_years   : yrs since first attempt\n",
        "        \"\"\"\n",
        "        df = df.sort_values([\"player_id\", \"game_date\"]).copy()\n",
        "\n",
        "        # cumulative counts\n",
        "        df[\"kicker_attempt_number\"] = df.groupby(\"player_id\").cumcount() + 1\n",
        "        df[\"experience_in_kicks\"]   = df[\"kicker_attempt_number\"] - 1\n",
        "        df[\"exp_100\"]               = df[\"experience_in_kicks\"] / 100.0\n",
        "\n",
        "        # career length (years)\n",
        "        first_dates = df.groupby(\"player_id\")[\"game_date\"].transform(\"min\")\n",
        "        df[\"career_length_years\"] = (df[\"game_date\"] - first_dates).dt.days / 365.25\n",
        "\n",
        "        # simple buckets\n",
        "        df[\"is_rookie_attempt\"] = (df[\"kicker_attempt_number\"] <= 20).astype(int)\n",
        "        p10, p25 = df[\"kicker_attempt_number\"].quantile([0.1, 0.25])\n",
        "        df[\"experience_category\"] = df[\"kicker_attempt_number\"].apply(\n",
        "            lambda n: \"Rookie\" if n <= p10\n",
        "            else (\"Developing\" if n <= p25 else \"Veteran\")\n",
        "        )\n",
        "\n",
        "        print(\"******* Created experience features (exp_100 added)\")\n",
        "        return df\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Situational features\n",
        "    # ------------------------------------------------------------------\n",
        "    def create_situational_features(\n",
        "            self,\n",
        "            df: pd.DataFrame,\n",
        "            *,\n",
        "            weight_cfg: dict | None = None\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Adds season / clutch flags *and* an 'importance' weight.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        weight_cfg : dict, optional\n",
        "            Keys: 'late', 'clutch', 'playoff'.\n",
        "            Defaults = {'late': 1, 'clutch': 2, 'playoff': 4}.\n",
        "        \"\"\"\n",
        "        w = {'late': 1, 'clutch': 2, 'playoff': 4}\n",
        "        if weight_cfg:\n",
        "            w.update(weight_cfg)\n",
        "\n",
        "        df = df.copy()\n",
        "        df[\"is_early_season\"] = (df[\"week\"] <= 4).astype(int)\n",
        "        df[\"is_late_season\"]  = (df[\"week\"] >= 15).astype(int)\n",
        "        df[\"is_playoffs\"]     = (df[\"week\"] >= 18).astype(int)\n",
        "        df[\"season_progress\"] = df[\"week\"] / 17.0\n",
        "\n",
        "        # # Optional clutch (leave at 0 if context cols absent)\n",
        "        # req = [\"quarter\", \"game_seconds_remaining\", \"score_differential\"]\n",
        "        # missing = [c for c in req if c not in df.columns]\n",
        "        # if missing:\n",
        "        #     df[\"is_clutch\"] = 0\n",
        "        # else:\n",
        "        #     df[\"is_clutch\"] = (\n",
        "        #         (df[\"quarter\"] >= 4) &\n",
        "        #         (df[\"game_seconds_remaining\"] <= 120) &\n",
        "        #         (df[\"score_differential\"].abs() <= 3)\n",
        "        #     ).astype(int)\n",
        "\n",
        "        # --- NEW flexible weighting ------------------------------------------\n",
        "        df[\"importance\"] = (\n",
        "            1\n",
        "            + w['late']     * df[\"is_late_season\"]\n",
        "            # + w['clutch']   * df[\"is_clutch\"]\n",
        "            + w['playoff']  * df[\"is_playoffs\"]\n",
        "        )\n",
        "        return df\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Rolling performance history\n",
        "    # ------------------------------------------------------------------\n",
        "    def create_performance_history_features(self, df: pd.DataFrame, window_size: int = 10) -> pd.DataFrame:\n",
        "        \"\"\"Rolling success rates, similar-distance success, and current streaks.\"\"\"\n",
        "        df = df.sort_values([\"player_id\", \"game_date\"]).copy()\n",
        "\n",
        "        # Rolling mean of success\n",
        "        df[\"rolling_success_rate\"] = (\n",
        "            df.groupby(\"player_id\")[\"success\"]\n",
        "            .transform(lambda s: s.rolling(window_size, min_periods=1).mean())\n",
        "        )\n",
        "\n",
        "        overall = df[\"success\"].mean()\n",
        "\n",
        "        def similar_rate(sub):\n",
        "            \"\"\"For each attempt, compute mean success rate of prior attempts within Â±5 yards.\"\"\"\n",
        "            vals = []\n",
        "            for i in range(len(sub)):\n",
        "                prev = sub.iloc[:i]\n",
        "                mask = (prev[\"attempt_yards\"] - sub.iloc[i][\"attempt_yards\"]).abs() <= 5\n",
        "                vals.append(prev.loc[mask, \"success\"].mean() if mask.any() else overall)\n",
        "            return pd.Series(vals, index=sub.index)\n",
        "\n",
        "        # Minimal deprecation fix: exclude grouping column before apply\n",
        "        sim = (\n",
        "            df.groupby(\"player_id\", group_keys=False)\n",
        "            .apply(similar_rate, include_groups=False)\n",
        "            .reset_index(level=0, drop=True)\n",
        "        )\n",
        "        df[\"rolling_similar_distance_success\"] = sim\n",
        "\n",
        "        # Current streak length\n",
        "        df[\"current_streak\"] = (\n",
        "            df.groupby(\"player_id\")[\"success\"]\n",
        "            .transform(lambda x: x.groupby((x != x.shift()).cumsum()).cumcount() + 1)\n",
        "        )\n",
        "\n",
        "        print(\"******* Created performance history features (rolling & streaks)\")\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Statistical interaction features\n",
        "    # ------------------------------------------------------------------\n",
        "    def create_statistical_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        df = df.copy()\n",
        "        df[\"distance_zscore\"] = (\n",
        "            (df[\"attempt_yards\"] - df[\"attempt_yards\"].mean()) /\n",
        "            df[\"attempt_yards\"].std()\n",
        "        )\n",
        "        df[\"distance_percentile\"] = df[\"attempt_yards\"].rank(pct=True)\n",
        "\n",
        "        # Cleaner interaction names using centered age\n",
        "        df[\"age_dist_interact\"] = df[\"age_c\"] * df[\"attempt_yards\"]\n",
        "        df[\"exp_dist_interact\"] = df[\"exp_100\"] * df[\"attempt_yards\"]\n",
        "\n",
        "        print(\"******* Created statistical interaction features (age Ã— distance, exp Ã— distance)\")\n",
        "        return df\n",
        "\n",
        "    def create_player_status_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Create player status categorization based on recent activity relative to dataset's latest date.\n",
        "\n",
        "        Categories:\n",
        "        - Retired/Injured: 2+ years since last kick (730+ days)\n",
        "        - Not Playing/Potentially Playable: 1-2 years since last kick (365-729 days)\n",
        "        - Playable: Less than 1 year since last kick (0-364 days)\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # Ensure datetime format\n",
        "        df[\"game_date\"] = pd.to_datetime(df[\"game_date\"])\n",
        "\n",
        "        # Find the latest date in the dataset (reference point)\n",
        "        latest_date = df[\"game_date\"].max()\n",
        "\n",
        "        # Calculate last kick date for each player\n",
        "        last_kick_by_player = df.groupby(\"player_id\")[\"game_date\"].max().reset_index()\n",
        "        last_kick_by_player.columns = [\"player_id\", \"last_kick_date\"]\n",
        "\n",
        "        # Calculate days since last kick\n",
        "        last_kick_by_player[\"days_since_last_kick\"] = (\n",
        "            latest_date - last_kick_by_player[\"last_kick_date\"]\n",
        "        ).dt.days\n",
        "\n",
        "        # Categorize player status\n",
        "        def categorize_status(days_since_last):\n",
        "            if days_since_last >= 730:  # 2+ years\n",
        "                return \"Retired/Injured\"\n",
        "            elif days_since_last >= 365:  # 1-2 years\n",
        "                return \"Not Playing/Potentially Playable\"\n",
        "            else:  # < 1 year\n",
        "                return \"Playable\"\n",
        "\n",
        "        last_kick_by_player[\"player_status\"] = last_kick_by_player[\"days_since_last_kick\"].apply(categorize_status)\n",
        "\n",
        "        # Merge back to main dataframe\n",
        "        df = df.merge(\n",
        "            last_kick_by_player[[\"player_id\", \"player_status\", \"days_since_last_kick\"]],\n",
        "            on=\"player_id\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        # Add summary statistics\n",
        "        status_counts = last_kick_by_player[\"player_status\"].value_counts()\n",
        "        print(\"******* Created player status features based on recent activity\")\n",
        "        print(f\"   Reference date: {latest_date.strftime('%Y-%m-%d')}\")\n",
        "        print(f\"   Playable: {status_counts.get('Playable', 0)} players (<1 year)\")\n",
        "        print(f\"   Not Playing/Potentially Playable: {status_counts.get('Not Playing/Potentially Playable', 0)} players (1-2 years)\")\n",
        "        print(f\"   Retired/Injured: {status_counts.get('Retired/Injured', 0)} players (2+ years)\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Orchestration: build *all* features\n",
        "    # ------------------------------------------------------------------\n",
        "    def create_all_features(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        include_performance_history: bool = True,\n",
        "        performance_window: int = 10,\n",
        "        include_player_status: bool = True\n",
        "    ) -> pd.DataFrame:\n",
        "        print(\"Creating all features...\")\n",
        "        df = (\n",
        "            df.pipe(self.create_target_variable)\n",
        "              .pipe(self.create_date_features)\n",
        "              .pipe(self.create_kicker_mapping)\n",
        "              .pipe(self.create_distance_features)\n",
        "              .pipe(self.create_experience_features)\n",
        "              .pipe(self.create_situational_features)\n",
        "              .pipe(self.create_statistical_features)\n",
        "        )\n",
        "        if include_performance_history:\n",
        "            df = self.create_performance_history_features(df, performance_window)\n",
        "        if include_player_status:\n",
        "            df = self.create_player_status_features(df)\n",
        "        print(f\"******* All features created! Dataset shape: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Dynamic feature catalogue helper\n",
        "    # ------------------------------------------------------------------\n",
        "    def get_available_features(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        include_unique: bool = True,\n",
        "        max_unique_values: int = 20\n",
        "    ) -> Dict[str, Union[List[str], Dict[str, List[Union[str, int, float]]]]]:\n",
        "        \"\"\"Return feature categories -> features (optionally with uniques) after engineering.\"\"\"\n",
        "        base_catalog = {\n",
        "            \"target\": [\"success\"],\n",
        "            \"basic\": [\"attempt_yards\", \"age_at_attempt\", \"kicker_attempt_number\", \"importance\"],\n",
        "            \"distance\": [\n",
        "                \"distance_squared\", \"distance_cubed\", \"log_distance\",\n",
        "                \"distance_from_sweet_spot\", \"distance_zscore\", \"distance_percentile\"\n",
        "            ],\n",
        "            \"distance_flags\": [\"is_long_attempt\", \"is_very_long_attempt\"],\n",
        "            \"distance_categories\": [\"distance_category\"],\n",
        "            \"temporal\": [\"day_of_year\", \"month\", \"week\", \"season\", \"season_progress\"],\n",
        "            \"situational\": [\"is_early_season\", \"is_late_season\", \"is_playoffs\"],\n",
        "            \"experience\": [\"career_length_years\", \"is_rookie_attempt\", \"experience_category\"],\n",
        "            \"performance_history\": [\n",
        "                \"rolling_success_rate\", \"rolling_similar_distance_success\", \"current_streak\"\n",
        "            ],\n",
        "            \"interactions\": [\"age_distance_interaction\", \"experience_distance_interaction\"],\n",
        "            \"identifiers\": [\"kicker_id\", \"kicker_idx\", \"player_name\"]\n",
        "        }\n",
        "        catalog: Dict[str, Union[List[str], Dict[str, List[Union[str, int, float]]]]] = {}\n",
        "        for cat, feats in base_catalog.items():\n",
        "            present = [f for f in feats if f in df.columns]\n",
        "            if include_unique:\n",
        "                detail: Dict[str, List[Union[str, int, float]]] = {}\n",
        "                for f in present:\n",
        "                    if df[f].dtype == \"object\" or df[f].nunique() <= max_unique_values:\n",
        "                        detail[f] = sorted(df[f].dropna().unique().tolist())\n",
        "                    else:\n",
        "                        detail[f] = []\n",
        "                catalog[cat] = detail\n",
        "            else:\n",
        "                catalog[cat] = present\n",
        "        return catalog\n",
        "\n",
        "# Function to create a summary DataFrame\n",
        "def summarize(df):\n",
        "    summary = pd.DataFrame({\n",
        "        'dtype': df.dtypes.astype(str),\n",
        "        'missing': df.isnull().sum(),\n",
        "        'unique': df.nunique(),\n",
        "        'sample_values': df.apply(lambda col: col.dropna().unique()[:5] if col.nunique() > 5 else col.unique())\n",
        "    })\n",
        "    return summary\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from src.nfl_kicker_analysis.data.loader import DataLoader\n",
        "\n",
        "    loader = DataLoader()\n",
        "    df_raw = loader.load_complete_dataset()\n",
        "    engineer = FeatureEngineer()\n",
        "    df_feat = engineer.create_all_features(df_raw)\n",
        "\n",
        "    summary_fg = summarize(df_feat)\n",
        "    print(\"---------------summary_fg-----------------\")\n",
        "    print(summary_fg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/data/feature_selection.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/data/feature_selection.py\n",
        "\"\"\"\n",
        "New in v0.2.0\n",
        "-------------\n",
        "* Added Random-Forest impurity importance (`compute_rf_importance`)\n",
        "* Added tri-modal merge and multicollinearity pruning\n",
        "* Re-worked `select_final_features` to call these helpers\n",
        "\n",
        "New in v0.3.0\n",
        "-------------\n",
        "* Added mutable `FEATURE_LISTS` dictionary for flexible schema management\n",
        "* Added `DynamicSchema` class to replace hardcoded `_ColumnSchema`\n",
        "* Added `make_feature_matrix` helper for consistent X/y construction\n",
        "* Updated functions to accept explicit schema parameter\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# â”€â”€ NEW: model and importance imports\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "import shap\n",
        "from pathlib import Path\n",
        "import shapiq\n",
        "from sklearn.utils import resample\n",
        "from itertools import combinations\n",
        "import json\n",
        "\n",
        "# â”€â”€ NEW: dataclass and typing imports for DynamicSchema\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# ðŸ§© Lightweight runtime schema object\n",
        "# ------------------------------------------------------------------\n",
        "@dataclass\n",
        "class DynamicSchema:\n",
        "    lists: Dict[str, List[str]] = field(default_factory=dict)\n",
        "\n",
        "    @property\n",
        "    def numerical(self):   return self.lists.get(\"numerical\", [])\n",
        "    @property\n",
        "    def ordinal(self):     return self.lists.get(\"ordinal\", [])\n",
        "    @property\n",
        "    def nominal(self):     return self.lists.get(\"nominal\", [])\n",
        "    @property\n",
        "    def target(self):      return self.lists.get(\"y_variable\", [])[0]\n",
        "    def all_features(self): return (\n",
        "        self.numerical + self.ordinal + self.nominal\n",
        "    )\n",
        "\n",
        "# â”€â”€ Schema-aware utilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def restrict_to_numerical(df: pd.DataFrame, schema: DynamicSchema) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Return a view of `df` that contains only the columns listed under\n",
        "    schema.numerical. Trust the schema's numerical list as the source of truth.\n",
        "    \"\"\"\n",
        "    return df[schema.numerical].copy()\n",
        "\n",
        "\n",
        "def update_schema_numerical(schema: DynamicSchema, new_numericals: list[str]) -> None:\n",
        "    \"\"\"\n",
        "    In-place replacement of the numerical list inside the DynamicSchema.\n",
        "    Keeps a copy of the old list for logging/debugging.\n",
        "    \"\"\"\n",
        "    old = schema.numerical\n",
        "    schema.lists[\"numerical\"] = sorted(new_numericals)\n",
        "    added   = sorted(set(new_numericals) - set(old))\n",
        "    removed = sorted(set(old)            - set(new_numericals))\n",
        "    print(f\"ðŸ”„  Schema update â†’ numerical features now = {len(new_numericals)} columns\")\n",
        "    if added:   print(f\"   âž• added   : {added}\")\n",
        "    if removed: print(f\"   âž– removed : {removed}\")\n",
        "\n",
        "\n",
        "def make_feature_matrix(df: pd.DataFrame,\n",
        "                        schema: DynamicSchema,\n",
        "                        numeric_only: bool = True\n",
        "                       ) -> tuple[pd.DataFrame, pd.Series]:\n",
        "    \"\"\"Return X (features) and y (target) based on the supplied schema.\"\"\"\n",
        "    X: pd.DataFrame = restrict_to_numerical(df, schema) if numeric_only else df[schema.all_features()].copy()\n",
        "    y: pd.Series = df[schema.target]\n",
        "    return X, y\n",
        "\n",
        "def train_baseline_model(X, y):\n",
        "    \"\"\"\n",
        "    Fit a RandomForestRegressor on X, y.\n",
        "    Returns the fitted model.\n",
        "    \"\"\"\n",
        "    # You can adjust hyperparameters as needed\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def compute_permutation_importance(\n",
        "    model,\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series,\n",
        "    n_repeats: int = 10,\n",
        "    n_jobs: int = 1,\n",
        "    max_samples: float | int | None = None,\n",
        "    random_state: int = 42,\n",
        "    verbose: bool = True\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute permutation importances with controlled resource usage.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : estimator\n",
        "        Fitted model implementing .predict and .score.\n",
        "    X : pd.DataFrame\n",
        "        Features.\n",
        "    y : pd.Series or array\n",
        "        Target.\n",
        "    n_repeats : int\n",
        "        Number of shuffles per feature.\n",
        "    n_jobs : int\n",
        "        Number of parallel jobs (avoid -1 on Windows).\n",
        "    max_samples : float or int, optional\n",
        "        If float in (0,1], fraction of rows to sample.\n",
        "        If int, absolute number of rows to sample.\n",
        "    random_state : int\n",
        "        Seed for reproducibility.\n",
        "    verbose : bool\n",
        "        Print debug info if True.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Columns: feature, importance_mean, importance_std.\n",
        "        Sorted descending by importance_mean.\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(f\"â³ Computing permutation importances on {X.shape[0]} rows Ã— {X.shape[1]} features\")\n",
        "        print(f\"   n_repeats={n_repeats}, n_jobs={n_jobs}, max_samples={max_samples}\")\n",
        "\n",
        "    # Subsample if requested\n",
        "    X_sel, y_sel = X, y\n",
        "    if max_samples is not None:\n",
        "        if isinstance(max_samples, float):\n",
        "            nsamp = int(len(X) * max_samples)\n",
        "        else:\n",
        "            nsamp = int(max_samples)\n",
        "        if verbose:\n",
        "            print(f\"   Subsampling to {nsamp} rows for speed\")\n",
        "        X_sel, y_sel = resample(X, y, replace=False, n_samples=nsamp, random_state=random_state)\n",
        "\n",
        "    try:\n",
        "        result = permutation_importance(\n",
        "            model,\n",
        "            X_sel, y_sel,\n",
        "            n_repeats=n_repeats,\n",
        "            random_state=random_state,\n",
        "            n_jobs=n_jobs,\n",
        "        )\n",
        "    except OSError as e:\n",
        "        # Graceful fallback to single job\n",
        "        if verbose:\n",
        "            print(f\"âš ï¸  OSError ({e}). Retrying with n_jobs=1\")\n",
        "        result = permutation_importance(\n",
        "            model,\n",
        "            X_sel, y_sel,\n",
        "            n_repeats=n_repeats,\n",
        "            random_state=random_state,\n",
        "            n_jobs=1,\n",
        "        )\n",
        "\n",
        "    # Build and sort DataFrame\n",
        "    importance_df = (\n",
        "        pd.DataFrame({\n",
        "            \"feature\": X.columns,\n",
        "            \"importance_mean\": result.importances_mean,\n",
        "            \"importance_std\": result.importances_std,\n",
        "        })\n",
        "        .sort_values(\"importance_mean\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    if verbose:\n",
        "        print(\"âœ… Permutation importances computed.\")\n",
        "    return importance_df\n",
        "\n",
        "\n",
        "def compute_shap_importance(model, X, nsamples=100):\n",
        "    \"\"\"\n",
        "    Compute mean absolute SHAP values per feature.\n",
        "    Returns a DataFrame sorted by importance.\n",
        "    \"\"\"\n",
        "    # DeepExplainer or TreeExplainer for tree-based models\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    # sample for speed\n",
        "    X_sample = X.sample(n=min(nsamples, len(X)), random_state=42)\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "    # For regression, shap_values is a 2D array\n",
        "    mean_abs_shap = pd.DataFrame({\n",
        "        \"feature\": X_sample.columns,\n",
        "        \"shap_importance\": np.abs(shap_values).mean(axis=0),\n",
        "    })\n",
        "    mean_abs_shap = mean_abs_shap.sort_values(\"shap_importance\", ascending=False).reset_index(drop=True)\n",
        "    return mean_abs_shap\n",
        "\n",
        "\n",
        "def compute_rf_importance(model, feature_names: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"Return impurity-based RF importances.\"\"\"\n",
        "    if not hasattr(model, \"feature_importances_\"):\n",
        "        raise AttributeError(\"Model has no feature_importances_ attribute\")\n",
        "    return (\n",
        "        pd.DataFrame(\n",
        "            {\"feature\": feature_names,\n",
        "             \"rf_importance\": model.feature_importances_}\n",
        "        )\n",
        "        .sort_values(\"rf_importance\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def merge_and_score_importances(perm_df, shap_df, rf_df) -> pd.DataFrame:\n",
        "    \"\"\"Merge the three importance tables and add a combined_score column.\"\"\"\n",
        "    merged = (\n",
        "        perm_df.merge(shap_df, on=\"feature\", how=\"outer\")\n",
        "               .merge(rf_df,  on=\"feature\", how=\"outer\")\n",
        "               .fillna(0.0)\n",
        "    )\n",
        "    # Min-max normalise each column so weights are comparable\n",
        "    for col in [\"importance_mean\", \"shap_importance\", \"rf_importance\"]:\n",
        "        merged[f\"norm_{col}\"] = minmax_scale(merged[col].values)\n",
        "    merged[\"combined_score\"] = merged[\n",
        "        [\"norm_importance_mean\", \"norm_shap_importance\", \"norm_rf_importance\"]\n",
        "    ].mean(axis=1)\n",
        "    return merged.sort_values(\"combined_score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "\n",
        "def drop_multicollinear(X: pd.DataFrame,\n",
        "                        ranked_feats: pd.DataFrame,\n",
        "                        corr_threshold: float = 0.85,\n",
        "                        method: str = \"pearson\") -> list[str]:\n",
        "    \"\"\"\n",
        "    Remove the lower-scoring feature from each highly correlated pair.\n",
        "    \"\"\"\n",
        "    corr = X[ranked_feats[\"feature\"]].corr().abs()\n",
        "    to_drop = set()\n",
        "    for f1, f2 in combinations(ranked_feats[\"feature\"], 2):\n",
        "        if corr.loc[f1, f2] > corr_threshold:\n",
        "            # keep the one with higher combined_score\n",
        "            better = f1 if ranked_feats.set_index(\"feature\").loc[f1,\"combined_score\"] \\\n",
        "                     >= ranked_feats.set_index(\"feature\").loc[f2,\"combined_score\"] else f2\n",
        "            worse  = f2 if better == f1 else f1\n",
        "            to_drop.add(worse)\n",
        "    return [f for f in ranked_feats[\"feature\"] if f not in to_drop]\n",
        "\n",
        "\n",
        "def filter_permutation_features(\n",
        "    importance_df: pd.DataFrame,\n",
        "    threshold: float\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Return features whose permutation importance_mean exceeds threshold.\n",
        "    \"\"\"\n",
        "    kept = importance_df.loc[\n",
        "        importance_df[\"importance_mean\"] > threshold, \"feature\"\n",
        "    ]\n",
        "    return kept.tolist()\n",
        "\n",
        "\n",
        "def filter_shap_features(\n",
        "    importance_df: pd.DataFrame,\n",
        "    threshold: float\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Return features whose shap_importance exceeds threshold.\n",
        "    \"\"\"\n",
        "    kept = importance_df.loc[\n",
        "        importance_df[\"shap_importance\"] > threshold, \"feature\"\n",
        "    ]\n",
        "    return kept.tolist()\n",
        "\n",
        "\n",
        "def select_final_features(perm_df,\n",
        "                          shap_df,\n",
        "                          rf_df,\n",
        "                          X: pd.DataFrame,\n",
        "                          schema: DynamicSchema,\n",
        "                          perm_thresh: float = 0.01,\n",
        "                          shap_thresh: float = 0.01,\n",
        "                          rf_thresh: float = 0.01,\n",
        "                          corr_threshold: float = 0.85) -> list[str]:\n",
        "    \"\"\"\n",
        "    Return the final feature list after:\n",
        "      1. Individual thresholding on each importance type\n",
        "      2. Union/intersection logic (here: *intersection*)\n",
        "      3. Combined-score ranking\n",
        "      4. Multicollinearity pruning\n",
        "    \"\"\"\n",
        "    # --- step 1: individual screens ---\n",
        "    keep_perm = perm_df.loc[perm_df[\"importance_mean\"] > perm_thresh, \"feature\"]\n",
        "    keep_shap = shap_df.loc[shap_df[\"shap_importance\"]   > shap_thresh, \"feature\"]\n",
        "    keep_rf   = rf_df.loc[rf_df[\"rf_importance\"]         > rf_thresh,   \"feature\"]\n",
        "    intersect = set(keep_perm) & set(keep_shap) & set(keep_rf)\n",
        "\n",
        "    # --- step 2: combine & rank only those ---\n",
        "    merged = merge_and_score_importances(\n",
        "        perm_df[perm_df[\"feature\"].isin(intersect)],\n",
        "        shap_df[shap_df[\"feature\"].isin(intersect)],\n",
        "        rf_df[rf_df[\"feature\"].isin(intersect)]\n",
        "    )\n",
        "\n",
        "    # --- step 3: drop multicollinear ---\n",
        "    final_feats = drop_multicollinear(X, merged, corr_threshold)\n",
        "\n",
        "    return final_feats\n",
        "\n",
        "\n",
        "# ============== BACKWARD COMPATIBILITY HELPERS ==============\n",
        "\n",
        "def select_final_features_legacy(\n",
        "    perm_feats: list[str],\n",
        "    shap_feats: list[str],\n",
        "    mode: str = \"intersection\"\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    DEPRECATED: Legacy version for backward compatibility.\n",
        "    Use select_final_features with DataFrame inputs for enhanced functionality.\n",
        "    \"\"\"\n",
        "    import warnings\n",
        "    warnings.warn(\n",
        "        \"select_final_features_legacy is deprecated. Use select_final_features with DataFrame inputs.\",\n",
        "        DeprecationWarning,\n",
        "        stacklevel=2\n",
        "    )\n",
        "    set_perm = set(perm_feats)\n",
        "    set_shap = set(shap_feats)\n",
        "    if mode == \"union\":\n",
        "        final = set_perm | set_shap\n",
        "    else:\n",
        "        final = set_perm & set_shap\n",
        "    return sorted(final)\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "\n",
        "\n",
        "def load_final_features(\n",
        "    file_path: str = \"data/models/features/final_features.txt\"\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Read the newline-delimited feature names file and return as a list.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\") as fp:\n",
        "        return [line.strip() for line in fp if line.strip()]\n",
        "\n",
        "\n",
        "def filter_to_final_features(df: pd.DataFrame,\n",
        "                             final_feats_file: str,\n",
        "                             schema: DynamicSchema,\n",
        "                             id_cols: list[str] = None\n",
        "                            ) -> pd.DataFrame:\n",
        "    \"\"\"Return df[id + final + y] using the dynamic schema.\"\"\"\n",
        "    final_feats = load_final_features(final_feats_file)\n",
        "    id_cols = id_cols or []\n",
        "    missing = set(id_cols + final_feats + [schema.target]) - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns after filtering: {missing}\")\n",
        "    return df[id_cols + final_feats + [schema.target]].copy()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from src.nfl_kicker_analysis.data.loader import DataLoader\n",
        "    from src.nfl_kicker_analysis.data.feature_engineering import FeatureEngineer\n",
        "    import os\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # ðŸ”§ Single source of truth for column roles â€“ edit freely\n",
        "    # ------------------------------------------------------------------\n",
        "    FEATURE_LISTS = {\n",
        "        \"numerical\": [\n",
        "            \"attempt_yards\", \"age_at_attempt\", \"distance_squared\",\n",
        "            \"career_length_years\", \"season_progress\", \"rolling_success_rate\",\n",
        "            \"current_streak\", \"distance_zscore\", \"distance_percentile\",\n",
        "        ],\n",
        "        \"ordinal\":  [\"season\", \"week\", \"month\", \"day_of_year\"],\n",
        "        \"nominal\":  [\n",
        "            \"kicker_id\", \"is_long_attempt\", \"is_very_long_attempt\",\n",
        "            \"is_rookie_attempt\", \"distance_category\", \"experience_category\",\n",
        "        ],\n",
        "        \"y_variable\": [\"success\"],\n",
        "    }\n",
        "\n",
        "    # âžŠ  Build schema from the dict\n",
        "    schema = DynamicSchema(FEATURE_LISTS)\n",
        "\n",
        "    # âž‹  Load & feature-engineer\n",
        "    loader = DataLoader()\n",
        "    df_raw = loader.load_complete_dataset()\n",
        "    engineer = FeatureEngineer()\n",
        "    df_feat = engineer.create_all_features(df_raw)\n",
        "    print(\"---------------df_feat---------------\")\n",
        "    print(df_feat.head())\n",
        "    print(\"---------------df_feat.columns---------------\")\n",
        "    print(df_feat.columns)\n",
        "    print(\"---------------schema.all_features()---------------\")\n",
        "    print(schema.all_features())\n",
        "\n",
        "    # âžŒ  Make X / y using the new helper\n",
        "    X, y = make_feature_matrix(df_feat, schema)\n",
        "\n",
        "    print(f\"\\nðŸ“Š Starting enhanced feature selection with {X.shape[1]} features\")\n",
        "    print(f\"   Schema contains {len(schema.all_features())} total features defined\")\n",
        "\n",
        "    # âž  Run the tri-modal importance pipeline exactly as before\n",
        "    print(\"\\nðŸŒ² Training Random Forest model...\")\n",
        "    model = train_baseline_model(X, y)\n",
        "\n",
        "    print(\"\\nâš¡ Computing permutation importance...\")\n",
        "    perm_df = compute_permutation_importance(model, X, y, max_samples=0.3)\n",
        "\n",
        "    print(\"\\nðŸ” Computing SHAP importance...\")\n",
        "    shap_df = compute_shap_importance(model, X, nsamples=100)\n",
        "\n",
        "    print(\"\\nðŸŒ³ Computing Random Forest importance...\")\n",
        "    rf_df = compute_rf_importance(model, X.columns.tolist())\n",
        "\n",
        "    # ðŸ“Š Display top 10 features for each importance metric\n",
        "    print(\"\\nðŸ“ˆ Top 10 Features by Importance Metric:\")\n",
        "    print(\"\\nPermutation Importance:\")\n",
        "    print(perm_df.head(10)[[\"feature\", \"importance_mean\"]].to_string(index=False))\n",
        "\n",
        "    print(\"\\nSHAP Importance:\")\n",
        "    print(shap_df.head(10)[[\"feature\", \"shap_importance\"]].to_string(index=False))\n",
        "\n",
        "    print(\"\\nRandom Forest Importance:\")\n",
        "    print(rf_df.head(10)[[\"feature\", \"rf_importance\"]].to_string(index=False))\n",
        "\n",
        "    # ðŸ”¬ Select & de-correlate with detailed output\n",
        "    print(\"\\nðŸ” Analyzing feature correlations...\")\n",
        "    corr = X[X.columns].corr().abs()\n",
        "\n",
        "    # Find highly correlated pairs before feature selection\n",
        "    high_corr_pairs = []\n",
        "    for f1, f2 in combinations(X.columns, 2):\n",
        "        if corr.loc[f1, f2] > 0.85:  # Using same threshold as drop_multicollinear\n",
        "            high_corr_pairs.append({\n",
        "                'feature1': f1,\n",
        "                'feature2': f2,\n",
        "                'correlation': corr.loc[f1, f2]\n",
        "            })\n",
        "\n",
        "    if high_corr_pairs:\n",
        "        print(\"\\nðŸ“Š Highly correlated feature pairs (correlation > 0.85):\")\n",
        "        for pair in sorted(high_corr_pairs, key=lambda x: x['correlation'], reverse=True):\n",
        "            print(f\"\\n{pair['feature1']} â†”ï¸ {pair['feature2']}\")\n",
        "            print(f\"Correlation: {pair['correlation']:.3f}\")\n",
        "\n",
        "            # Get importance scores for both features\n",
        "            f1_scores = {\n",
        "                'perm': float(perm_df[perm_df.feature == pair['feature1']].importance_mean.iloc[0]),\n",
        "                'shap': float(shap_df[shap_df.feature == pair['feature1']].shap_importance.iloc[0]),\n",
        "                'rf': float(rf_df[rf_df.feature == pair['feature1']].rf_importance.iloc[0])\n",
        "            }\n",
        "            f2_scores = {\n",
        "                'perm': float(perm_df[perm_df.feature == pair['feature2']].importance_mean.iloc[0]),\n",
        "                'shap': float(shap_df[shap_df.feature == pair['feature2']].shap_importance.iloc[0]),\n",
        "                'rf': float(rf_df[rf_df.feature == pair['feature2']].rf_importance.iloc[0])\n",
        "            }\n",
        "\n",
        "            print(f\"{pair['feature1']} importance scores:\")\n",
        "            print(f\"  Permutation: {f1_scores['perm']:.4f}\")\n",
        "            print(f\"  SHAP: {f1_scores['shap']:.4f}\")\n",
        "            print(f\"  RF: {f1_scores['rf']:.4f}\")\n",
        "\n",
        "            print(f\"{pair['feature2']} importance scores:\")\n",
        "            print(f\"  Permutation: {f2_scores['perm']:.4f}\")\n",
        "            print(f\"  SHAP: {f2_scores['shap']:.4f}\")\n",
        "            print(f\"  RF: {f2_scores['rf']:.4f}\")\n",
        "\n",
        "            # Calculate average importance\n",
        "            f1_avg = sum(f1_scores.values()) / 3\n",
        "            f2_avg = sum(f2_scores.values()) / 3\n",
        "\n",
        "            keeper = pair['feature1'] if f1_avg >= f2_avg else pair['feature2']\n",
        "            dropped = pair['feature2'] if keeper == pair['feature1'] else pair['feature1']\n",
        "            print(f\"\\nâž¡ï¸ Decision: Keep {keeper} (avg importance: {max(f1_avg, f2_avg):.4f})\")\n",
        "            print(f\"âŒ Drop {dropped} (avg importance: {min(f1_avg, f2_avg):.4f})\")\n",
        "    else:\n",
        "        print(\"No highly correlated feature pairs found.\")\n",
        "\n",
        "    # Run feature selection\n",
        "    final_features = select_final_features(\n",
        "        perm_df, shap_df, rf_df, X, schema,\n",
        "        perm_thresh=0.005, shap_thresh=0.005, rf_thresh=0.005\n",
        "    )\n",
        "    print(f\"---------------final_features---------------\")\n",
        "    print(final_features)\n",
        "    # output final_features to final_features.txt\n",
        "    with open(\"data/models/features/final_features.txt\", \"w\") as f:\n",
        "        for feat in final_features:\n",
        "            f.write(feat + \"\\n\")\n",
        "\n",
        "\n",
        "    # read final_features.txt\n",
        "    with open(\"data/models/features/final_features.txt\", \"r\") as f:\n",
        "        final_features = [line.strip() for line in f]\n",
        "    print(f\"---------------final_features---------------\")\n",
        "    print(final_features)\n",
        "    numeric_final = [f for f in final_features if f in schema.numerical]\n",
        "\n",
        "    print(f\"\\nâœ¨ Final feature count: {len(numeric_final)}\")\n",
        "    print(\"Selected features:\")\n",
        "    for feat in numeric_final:\n",
        "        print(f\"  â€¢ {feat}\")\n",
        "\n",
        "    # ðŸ”„ Push into schema so every later stage sees the new list\n",
        "    update_schema_numerical(schema, numeric_final)\n",
        "\n",
        "    # output final_features from schema\n",
        "    FEATURE_LISTS = schema.lists\n",
        "    print(f\"---------------FEATURE_LISTS---------------\")\n",
        "    print(FEATURE_LISTS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing Module\n",
        "\n",
        "Handles data cleaning, feature engineering, and preparation for modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/data/preprocessor.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/data/preprocessor.py\n",
        "\"\"\"\n",
        "Data preprocessing module for NFL kicker analysis.\n",
        "Handles filtering, feature selection, and preparation for modeling.\n",
        "\n",
        "New in v0.4.0\n",
        "--------------\n",
        "* Added **inverseâ€‘preprocessing** utilities so that any matrix produced by the\n",
        "  fitted `ColumnTransformer` can be projected back into humanâ€‘readable feature\n",
        "  space.  This is handy for debugging, error analysis, or piping model outputs\n",
        "  into postâ€‘processing code that expects the rawâ€‘scale feature values.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional, Tuple, Dict, List, Union, cast, Any, TypeVar, Protocol\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy import sparse\n",
        "\n",
        "from src.nfl_kicker_analysis.data.feature_engineering import FeatureEngineer\n",
        "from src.nfl_kicker_analysis.data.feature_schema import FeatureSchema\n",
        "from src.nfl_kicker_analysis import config\n",
        "\n",
        "\n",
        "# Type variables for better type hints\n",
        "T = TypeVar('T')\n",
        "MatrixType = Union[np.ndarray, sparse.spmatrix]\n",
        "\n",
        "\n",
        "class Transformer(Protocol):\n",
        "    \"\"\"Protocol for scikit-learn transformers.\"\"\"\n",
        "    def fit_transform(self, X: Any, y: Any = None) -> MatrixType: ...\n",
        "    def transform(self, X: Any) -> MatrixType: ...\n",
        "    def inverse_transform(self, X: MatrixType) -> np.ndarray: ...\n",
        "\n",
        "\n",
        "class DataPreprocessor:\n",
        "    \"\"\"Handles data preprocessing, feature engineering, and *now* inversion.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Create a blank preprocessor â€“ remember to inject config / features.\"\"\"\n",
        "        # Dataâ€‘filtering hyperâ€‘parameters (set via :pymeth:`update_config`).\n",
        "        self.MIN_DISTANCE: int | None = None\n",
        "        self.MAX_DISTANCE: int | None = None\n",
        "        self.MIN_KICKER_ATTEMPTS: int | None = None\n",
        "        self.SEASON_TYPES: list[str] | None = None\n",
        "\n",
        "        # Featureâ€‘role lists (set via :pymeth:`update_feature_lists`).\n",
        "        self.NUMERICAL_FEATURES: list[str] = []\n",
        "        self.ORDINAL_FEATURES: list[str] = []\n",
        "        self.NOMINAL_FEATURES: list[str] = []\n",
        "\n",
        "        # Target column\n",
        "        self.TARGET: str = \"success\"\n",
        "\n",
        "        # Featureâ€‘engineering toggles (again, set via config).\n",
        "        self.INCLUDE_PERFORMANCE_HISTORY: bool | None = None\n",
        "        self.INCLUDE_STATISTICAL_FEATURES: bool | None = None\n",
        "        self.INCLUDE_PLAYER_STATUS: bool | None = None\n",
        "        self.PERFORMANCE_WINDOW: int | None = None\n",
        "\n",
        "        # Runtime artefacts ------------------------------------------------\n",
        "        self.feature_engineer = FeatureEngineer()\n",
        "        self.raw_data: pd.DataFrame | None = None\n",
        "        self.processed_data: pd.DataFrame | None = None\n",
        "        self.schema: FeatureSchema | None = None\n",
        "\n",
        "        # âž• NEW â€“ fitted column transformer for forward & inverse transforms\n",
        "        self.column_transformer_: ColumnTransformer | None = None\n",
        "        self._feature_cols_: List[str] | None = None  # Cache feature columns after fitting\n",
        "\n",
        "    def update_feature_lists(self,\n",
        "                           numerical: Optional[List[str]] = None,\n",
        "                           ordinal: Optional[List[str]] = None,\n",
        "                           nominal: Optional[List[str]] = None,\n",
        "                           y_variable: Optional[List[str]] = None):\n",
        "        \"\"\"\n",
        "        Update feature lists for easy experimentation.\n",
        "\n",
        "        Args:\n",
        "            numerical: List of numerical features to use\n",
        "            ordinal: List of ordinal features to use\n",
        "            nominal: List of nominal categorical features to use\n",
        "            y_variable: List containing target variable name\n",
        "        \"\"\"\n",
        "        if numerical is not None:\n",
        "            self.NUMERICAL_FEATURES = numerical\n",
        "        if ordinal is not None:\n",
        "            self.ORDINAL_FEATURES = ordinal\n",
        "        if nominal is not None:\n",
        "            self.NOMINAL_FEATURES = nominal\n",
        "        if y_variable is not None:\n",
        "            self.TARGET = y_variable[0]  # Single target assumed\n",
        "\n",
        "        print(\"******* Feature lists updated\")\n",
        "\n",
        "    def update_config(self,\n",
        "                     min_distance: Optional[int] = None,\n",
        "                     max_distance: Optional[int] = None,\n",
        "                     min_kicker_attempts: Optional[int] = None,\n",
        "                     season_types: Optional[List[str]] = None,\n",
        "                     include_performance_history: Optional[bool] = None,\n",
        "                     include_statistical_features: Optional[bool] = None,\n",
        "                     include_player_status: Optional[bool] = None,\n",
        "                     performance_window: Optional[int] = None):\n",
        "        \"\"\"\n",
        "        Update preprocessing configuration.\n",
        "\n",
        "        Args:\n",
        "            min_distance: Minimum field goal distance to include\n",
        "            max_distance: Maximum field goal distance to include\n",
        "            min_kicker_attempts: Minimum attempts required per kicker\n",
        "            season_types: List of season types to include\n",
        "            include_performance_history: Whether to include performance history features\n",
        "            include_statistical_features: Whether to include statistical features\n",
        "            performance_window: Window size for rolling performance features\n",
        "        \"\"\"\n",
        "        if min_distance is not None:\n",
        "            self.MIN_DISTANCE = min_distance\n",
        "        if max_distance is not None:\n",
        "            self.MAX_DISTANCE = max_distance\n",
        "        if min_kicker_attempts is not None:\n",
        "            self.MIN_KICKER_ATTEMPTS = min_kicker_attempts\n",
        "        if season_types is not None:\n",
        "            self.SEASON_TYPES = season_types\n",
        "        if include_performance_history is not None:\n",
        "            self.INCLUDE_PERFORMANCE_HISTORY = include_performance_history\n",
        "        if include_statistical_features is not None:\n",
        "            self.INCLUDE_STATISTICAL_FEATURES = include_statistical_features\n",
        "        if include_player_status is not None:\n",
        "            self.INCLUDE_PLAYER_STATUS = include_player_status\n",
        "        if performance_window is not None:\n",
        "            self.PERFORMANCE_WINDOW = performance_window\n",
        "\n",
        "        print(\"******* Configuration updated\")\n",
        "\n",
        "    def _validate_config(self):\n",
        "        \"\"\"Validate that required configuration is set.\"\"\"\n",
        "        missing = []\n",
        "        if self.MIN_DISTANCE is None:\n",
        "            missing.append(\"MIN_DISTANCE\")\n",
        "        if self.MAX_DISTANCE is None:\n",
        "            missing.append(\"MAX_DISTANCE\")\n",
        "        if self.MIN_KICKER_ATTEMPTS is None:\n",
        "            missing.append(\"MIN_KICKER_ATTEMPTS\")\n",
        "        if self.SEASON_TYPES is None:\n",
        "            missing.append(\"SEASON_TYPES\")\n",
        "        if self.INCLUDE_PERFORMANCE_HISTORY is None:\n",
        "            missing.append(\"INCLUDE_PERFORMANCE_HISTORY\")\n",
        "        if self.INCLUDE_STATISTICAL_FEATURES is None:\n",
        "            missing.append(\"INCLUDE_STATISTICAL_FEATURES\")\n",
        "        if self.INCLUDE_PLAYER_STATUS is None:\n",
        "            missing.append(\"INCLUDE_PLAYER_STATUS\")\n",
        "        if self.PERFORMANCE_WINDOW is None:\n",
        "            missing.append(\"PERFORMANCE_WINDOW\")\n",
        "\n",
        "        if missing:\n",
        "            raise ValueError(f\"Configuration not set. Please call update_config() first. Missing: {missing}\")\n",
        "\n",
        "    def filter_season_type(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Filter data by season type.\"\"\"\n",
        "        self._validate_config()\n",
        "        assert self.SEASON_TYPES is not None  # guaranteed after validation\n",
        "        filtered_df = cast(pd.DataFrame, df[df['season_type'].isin(self.SEASON_TYPES)].copy())\n",
        "        print(f\"******* Filtered to {self.SEASON_TYPES} season(s): {len(filtered_df):,} attempts\")\n",
        "        return filtered_df\n",
        "\n",
        "    def filter_blocked_field_goals(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Filter out blocked field goals since they don't reflect kicker skill.\"\"\"\n",
        "        filtered_df = cast(pd.DataFrame, df[df['field_goal_result'] != 'Blocked'].copy())\n",
        "        removed = len(df) - len(filtered_df)\n",
        "        print(f\"******* Filtered out blocked field goals\")\n",
        "        print(f\"   Removed {removed} blocked attempts, kept {len(filtered_df):,}\")\n",
        "        return filtered_df\n",
        "\n",
        "    def filter_retired_injured_players(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Optionally drop Retired/Injured attempts (status created upstream).\n",
        "        Controlled by config.FILTER_RETIRED_INJURED.\n",
        "        \"\"\"\n",
        "        if \"player_status\" not in df.columns or not config.FILTER_RETIRED_INJURED:\n",
        "            return df                # no-op if flag is False or column missing\n",
        "\n",
        "        keep_mask = df[\"player_status\"] != \"Retired/Injured\"\n",
        "        dropped   = (~keep_mask).sum()\n",
        "        players   = df.loc[~keep_mask, \"player_name\"].nunique()\n",
        "\n",
        "        print(f\"ðŸ—‘ï¸  Filtered {dropped} attempts from {players} retired/injured players\")\n",
        "        return cast(pd.DataFrame, df[keep_mask].copy())\n",
        "\n",
        "    def filter_distance_range(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Filter data by distance range to remove outliers.\"\"\"\n",
        "        self._validate_config()\n",
        "        filtered_df = cast(pd.DataFrame, df[\n",
        "            (df['attempt_yards'] >= self.MIN_DISTANCE) &\n",
        "            (df['attempt_yards'] <= self.MAX_DISTANCE)\n",
        "        ].copy())\n",
        "\n",
        "        removed = len(df) - len(filtered_df)\n",
        "        print(f\"******* Filtered distance range {self.MIN_DISTANCE}-{self.MAX_DISTANCE} yards\")\n",
        "        print(f\"   Removed {removed} extreme attempts, kept {len(filtered_df):,}\")\n",
        "        return filtered_df\n",
        "\n",
        "    def filter_min_attempts(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Filter out kickers with too few attempts.\"\"\"\n",
        "        self._validate_config()\n",
        "        # Count attempts per kicker\n",
        "        kicker_counts = df['player_name'].value_counts()\n",
        "        valid_kickers = kicker_counts[kicker_counts >= self.MIN_KICKER_ATTEMPTS]\n",
        "        # Convert index to list safely using pandas Series methods\n",
        "        valid_kicker_names = cast(pd.Series, valid_kickers).index.tolist()\n",
        "\n",
        "        # Filter to valid kickers only\n",
        "        filtered_df = cast(pd.DataFrame, df[df['player_name'].isin(valid_kicker_names)].copy())\n",
        "\n",
        "        removed_kickers = len(kicker_counts) - len(valid_kickers)\n",
        "        print(f\"******* Filtered kickers with <{self.MIN_KICKER_ATTEMPTS} attempts\")\n",
        "        print(f\"   Removed {removed_kickers} kickers, kept {len(valid_kickers)}\")\n",
        "        print(f\"   Final dataset: {len(filtered_df):,} attempts\")\n",
        "\n",
        "        return filtered_df\n",
        "\n",
        "    def _get_selected_features(self) -> List[str]:\n",
        "        \"\"\"Get the complete list of selected features based on configuration.\"\"\"\n",
        "        features = []\n",
        "\n",
        "        # Include all feature categories\n",
        "        features.extend(self.NUMERICAL_FEATURES)\n",
        "        features.extend(self.ORDINAL_FEATURES)\n",
        "        features.extend(self.NOMINAL_FEATURES)\n",
        "\n",
        "        # Remove duplicates while preserving order\n",
        "        return list(dict.fromkeys(features))\n",
        "\n",
        "    def _build_schema(self, df: pd.DataFrame) -> FeatureSchema:\n",
        "        \"\"\"Build the feature schema based on selected features.\"\"\"\n",
        "        selected_features = self._get_selected_features()\n",
        "\n",
        "        # Filter feature lists to only include features that exist in the dataframe\n",
        "        available_features = set(df.columns)\n",
        "\n",
        "        numerical = [f for f in self.NUMERICAL_FEATURES if f in available_features]\n",
        "        ordinal = [f for f in self.ORDINAL_FEATURES if f in available_features]\n",
        "        nominal = [f for f in self.NOMINAL_FEATURES if f in available_features]\n",
        "\n",
        "        schema = FeatureSchema(\n",
        "            numerical=numerical,\n",
        "            binary=[],  # Binary features are now in nominal\n",
        "            ordinal=ordinal,\n",
        "            nominal=nominal,\n",
        "            target=self.TARGET,\n",
        "        )\n",
        "\n",
        "        # Validate schema\n",
        "        try:\n",
        "            schema.assert_in_dataframe(df)\n",
        "        except AssertionError as e:\n",
        "            print(f\"Warning: Schema validation failed: {e}\")\n",
        "            print(\"Available features:\", list(available_features))\n",
        "            print(\"Requested features:\", selected_features)\n",
        "\n",
        "        return schema\n",
        "\n",
        "    def make_column_transformer(self) -> ColumnTransformer:\n",
        "        \"\"\"\n",
        "        Return a scikit-learn ColumnTransformer based on the feature schema.\n",
        "        Call after `preprocess_complete()`.\n",
        "        \"\"\"\n",
        "        if self.schema is None:\n",
        "            raise AttributeError(\"Run preprocess_complete() before building transformers.\")\n",
        "\n",
        "        # Numeric pipeline - standard scaling\n",
        "        numeric_pipe = Pipeline(\n",
        "            steps=[\n",
        "                (\"scale\", StandardScaler())\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Build transformers list\n",
        "        transformers = []\n",
        "\n",
        "        if self.schema.numerical:\n",
        "            transformers.append((\"num_scaled\", numeric_pipe, self.schema.numerical))\n",
        "\n",
        "        if self.schema.binary:\n",
        "            transformers.append((\"binary_passthrough\", \"passthrough\", self.schema.binary))\n",
        "\n",
        "        if self.schema.ordinal:\n",
        "            transformers.append((\"ordinal_passthrough\", \"passthrough\", self.schema.ordinal))\n",
        "\n",
        "        if self.schema.nominal:\n",
        "            transformers.append((\"nominal_onehot\",\n",
        "                               OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True),\n",
        "                               self.schema.nominal))\n",
        "\n",
        "        # Categorical features are now included in nominal features\n",
        "        # No separate categorical handling needed\n",
        "\n",
        "        ct = ColumnTransformer(\n",
        "            transformers=transformers,\n",
        "            remainder=\"drop\",\n",
        "            verbose_feature_names_out=False,\n",
        "        )\n",
        "        return ct\n",
        "\n",
        "    # â”€â”€ src/nfl_kicker_analysis/data/preprocessor.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def preprocess_slice(self, raw_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Run the exact notebook filters on an arbitrary slice *without* mutating\n",
        "           global state (so train/test can differ).\"\"\"\n",
        "        self._validate_config()\n",
        "\n",
        "        df = raw_df.copy()\n",
        "\n",
        "        # Check if features are already engineered (to avoid double processing)\n",
        "        features_already_present = 'success' in df.columns and 'player_status' in df.columns\n",
        "\n",
        "        if not features_already_present:\n",
        "            # Only run feature engineering if not already done\n",
        "            df = self.feature_engineer.create_all_features(\n",
        "                df,\n",
        "                include_performance_history=self.INCLUDE_PERFORMANCE_HISTORY,\n",
        "                performance_window=self.PERFORMANCE_WINDOW,\n",
        "                include_player_status=self.INCLUDE_PLAYER_STATUS,\n",
        "            )\n",
        "            if self.INCLUDE_STATISTICAL_FEATURES:\n",
        "                df = self.feature_engineer.create_statistical_features(df)\n",
        "\n",
        "        # Apply filtering steps\n",
        "        df = self.filter_season_type(df)\n",
        "        df = self.filter_blocked_field_goals(df)    # â¬… NEW: filter blocked attempts\n",
        "        df = self.filter_distance_range(df)\n",
        "        df = self.filter_min_attempts(df)           # â¬… identical min-att logic\n",
        "\n",
        "        # Filter retired/injured players (needs player_status column)\n",
        "        df = self.filter_retired_injured_players(df)\n",
        "\n",
        "        self._build_schema(df)                      # rebuild OHE categories\n",
        "        return df\n",
        "\n",
        "\n",
        "    def preprocess_complete(self, raw_df: pd.DataFrame, *, inplace: bool = True) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Complete preprocessing pipeline.\n",
        "\n",
        "        Args:\n",
        "            raw_df: Raw merged DataFrame\n",
        "            inplace: If True (default), store results in instance attributes.\n",
        "                    If False, behaves like preprocess_slice() and leaves internal state untouched.\n",
        "\n",
        "        Returns:\n",
        "            Fully preprocessed DataFrame ready for modeling\n",
        "        \"\"\"\n",
        "        if inplace:\n",
        "            # Validate configuration first\n",
        "            self._validate_config()\n",
        "\n",
        "            self.raw_data = raw_df.copy()\n",
        "\n",
        "            print(\"Starting complete preprocessing pipeline...\")\n",
        "            print(f\"Configuration: {self.MIN_DISTANCE}-{self.MAX_DISTANCE} yards, \"\n",
        "                  f\"min {self.MIN_KICKER_ATTEMPTS} attempts, {self.SEASON_TYPES} seasons\")\n",
        "\n",
        "            self.processed_data = self.preprocess_slice(raw_df)\n",
        "            self.schema = self._build_schema(self.processed_data)\n",
        "\n",
        "            print(f\"******* Preprocessing complete: {len(self.processed_data):,} attempts ready for modeling\")\n",
        "            print(f\"******* Features selected: {len(self._get_selected_features())} total\")\n",
        "            return self.processed_data\n",
        "        else:\n",
        "            return self.preprocess_slice(raw_df)\n",
        "\n",
        "    def get_feature_summary(self) -> Dict:\n",
        "        \"\"\"Get summary of selected features by category.\"\"\"\n",
        "        if self.processed_data is None:\n",
        "            raise ValueError(\"No processed data available\")\n",
        "\n",
        "        selected_features = self._get_selected_features()\n",
        "        available_features = set(self.processed_data.columns)\n",
        "\n",
        "        summary = {\n",
        "            'total_selected': len(selected_features),\n",
        "            'total_available': len(available_features),\n",
        "            'numerical': [f for f in self.NUMERICAL_FEATURES if f in available_features],\n",
        "            'ordinal': [f for f in self.ORDINAL_FEATURES if f in available_features],\n",
        "            'nominal': [f for f in self.NOMINAL_FEATURES if f in available_features],\n",
        "            'missing_features': [f for f in selected_features if f not in available_features],\n",
        "        }\n",
        "        return summary\n",
        "\n",
        "    def get_preprocessing_summary(self) -> Dict:\n",
        "        \"\"\"Get summary of preprocessing steps and results.\"\"\"\n",
        "        if self.processed_data is None:\n",
        "            raise ValueError(\"No processed data available\")\n",
        "\n",
        "        summary = {\n",
        "            'original_size': len(self.raw_data) if self.raw_data is not None else 0,\n",
        "            'final_size': len(self.processed_data),\n",
        "            'unique_kickers': self.processed_data['player_name'].nunique(),\n",
        "            'success_rate': self.processed_data[self.TARGET].mean(),\n",
        "            'distance_range': (\n",
        "                self.processed_data['attempt_yards'].min(),\n",
        "                self.processed_data['attempt_yards'].max()\n",
        "            ),\n",
        "            'config': {\n",
        "                'min_distance': self.MIN_DISTANCE,\n",
        "                'max_distance': self.MAX_DISTANCE,\n",
        "                'min_kicker_attempts': self.MIN_KICKER_ATTEMPTS,\n",
        "                'season_types': self.SEASON_TYPES,\n",
        "                'include_performance_history': self.INCLUDE_PERFORMANCE_HISTORY,\n",
        "                'include_statistical_features': self.INCLUDE_STATISTICAL_FEATURES,\n",
        "            },\n",
        "            'features': self.get_feature_summary()\n",
        "        }\n",
        "        return summary\n",
        "\n",
        "    def fit_transform_features(self) -> Tuple[MatrixType, np.ndarray]:\n",
        "        \"\"\"Fit the internal :class:`ColumnTransformer` **and** return X / y.\n",
        "\n",
        "        Returns:\n",
        "            Tuple containing:\n",
        "                - X: Transformed feature matrix (sparse or dense)\n",
        "                - y: Target array\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If preprocess_complete() hasn't been called yet\n",
        "        \"\"\"\n",
        "        if self.processed_data is None:\n",
        "            raise ValueError(\"Run preprocess_complete() before fitting the transformer.\")\n",
        "\n",
        "        # Build & fit transformer\n",
        "        self.column_transformer_ = self.make_column_transformer()\n",
        "        feature_cols = self._get_selected_features()\n",
        "        self._feature_cols_ = feature_cols  # Cache for inverse transform\n",
        "        X = self.column_transformer_.fit_transform(self.processed_data[feature_cols])\n",
        "        y = cast(np.ndarray, self.processed_data[self.TARGET].values)\n",
        "        return cast(Tuple[MatrixType, np.ndarray], (X, y))\n",
        "\n",
        "    def transform_features(self, df: pd.DataFrame) -> MatrixType:\n",
        "        \"\"\"Transform a *new* DataFrame using the alreadyâ€‘fitted transformer.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to transform, must have same columns as training data\n",
        "\n",
        "        Returns:\n",
        "            Transformed feature matrix (sparse or dense)\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If transformer hasn't been fitted yet\n",
        "        \"\"\"\n",
        "        if self.column_transformer_ is None:\n",
        "            raise ValueError(\"Transformer not fitted â€“ call fit_transform_features() first.\")\n",
        "\n",
        "        feature_cols = self._get_selected_features()\n",
        "        X = self.column_transformer_.transform(df[feature_cols])\n",
        "        return cast(MatrixType, X)\n",
        "\n",
        "    def invert_preprocessing(self, X_transformed: MatrixType) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Version-safe inverse transform.\n",
        "        Works on scikit-learn â‰¥0.24 (native) and â‰¤0.23 (manual fallback).\n",
        "        \"\"\"\n",
        "        if self.column_transformer_ is None or self._feature_cols_ is None:\n",
        "            raise ValueError(\"Transformer not fitted â€“ call fit_transform_features() first.\")\n",
        "\n",
        "        # --- 1 â–¸ Modern sklearn: just call the native helper -----------------\n",
        "        if hasattr(self.column_transformer_, \"inverse_transform\"):\n",
        "            X_inv = self.column_transformer_.inverse_transform(X_transformed)\n",
        "            return pd.DataFrame(X_inv, columns=self._feature_cols_)\n",
        "\n",
        "        # --- 2 â–¸ Legacy sklearn: manual reconstruction -----------------------\n",
        "        X_dense = X_transformed.toarray() if sparse.issparse(X_transformed) else np.asarray(X_transformed)\n",
        "\n",
        "        col_arrays, current = [], 0\n",
        "        for name, trans, cols in self.column_transformer_.transformers_:\n",
        "            # -------- width calculation WITHOUT touching the transformer -----\n",
        "            if name == \"num_scaled\":\n",
        "                width = len(cols)  # numeric slice = number of original columns\n",
        "            elif name == \"nominal_onehot\":\n",
        "                enc = cast(OneHotEncoder, trans)\n",
        "                width = sum(len(c) for c in enc.categories_)\n",
        "            else:                           # passthrough groups\n",
        "                width = len(cols)\n",
        "\n",
        "            slice_ = X_dense[:, current: current + width]\n",
        "            current += width\n",
        "\n",
        "            # -------- inverse for each block ---------------------------------\n",
        "            if name == \"num_scaled\":\n",
        "                scaler = cast(StandardScaler, trans.named_steps[\"scale\"])\n",
        "                slice_inv = (slice_ * scaler.scale_) + scaler.mean_     # docsâ€‚:contentReference[oaicite:2]{index=2}\n",
        "                col_arrays.append(slice_inv)\n",
        "\n",
        "            elif name == \"nominal_onehot\":\n",
        "                enc = cast(OneHotEncoder, trans)\n",
        "                slice_inv = enc.inverse_transform(slice_)               # docsâ€‚:contentReference[oaicite:3]{index=3}\n",
        "                col_arrays.append(slice_inv)\n",
        "\n",
        "            else:                                                       # passthrough\n",
        "                col_arrays.append(slice_)\n",
        "\n",
        "        X_inv_full = np.column_stack(col_arrays)\n",
        "        return pd.DataFrame(X_inv_full, columns=self._feature_cols_)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from src.nfl_kicker_analysis.data.loader import DataLoader\n",
        "    from src.nfl_kicker_analysis.data.feature_selection import (\n",
        "        DynamicSchema,\n",
        "        filter_to_final_features,\n",
        "        update_schema_numerical,\n",
        "    )\n",
        "\n",
        "    # â”€â”€â”€ 1 Load raw data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    loader = DataLoader()\n",
        "    df_raw = loader.load_complete_dataset()\n",
        "\n",
        "    # â”€â”€â”€ 2 Feature engineering pass â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    engineer = FeatureEngineer()\n",
        "    df_feat = engineer.create_all_features(df_raw)\n",
        "\n",
        "    for category, details in engineer.get_available_features(df_feat).items():\n",
        "        print(f\"-- {category} --\")\n",
        "        for feat, uniques in details.items():\n",
        "            print(f\"   {feat}: {len(uniques)} unique | sample {uniques[:5] if uniques else '...'}\")\n",
        "\n",
        "    # â”€â”€â”€ 3 Define all tunables in one place â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    CONFIG = {\n",
        "        'min_distance': 20,\n",
        "        'max_distance': 60,\n",
        "        'min_kicker_attempts': 8,\n",
        "        'season_types': ['Reg', 'Post'],  # now include playoffs\n",
        "        'include_performance_history': True,\n",
        "        'include_statistical_features': False,\n",
        "        'include_player_status': True,  # âœ… FIX: Added missing parameter\n",
        "        'performance_window': 12,\n",
        "    }\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # ðŸ”§ Single source of truth for column roles â€“ edit freely\n",
        "    # ------------------------------------------------------------------\n",
        "    FEATURE_LISTS = {\n",
        "        \"numerical\": [\n",
        "            \"attempt_yards\", \"age_at_attempt\", \"distance_squared\",\n",
        "            \"career_length_years\", \"season_progress\", \"rolling_success_rate\",\n",
        "            \"current_streak\", \"distance_zscore\", \"distance_percentile\",\n",
        "        ],\n",
        "        \"ordinal\":  [\"season\", \"week\", \"month\", \"day_of_year\"],\n",
        "        \"nominal\":  [\n",
        "            \"kicker_id\", \"kicker_idx\", \"is_long_attempt\", \"is_very_long_attempt\",\n",
        "            \"is_rookie_attempt\", \"distance_category\", \"experience_category\",\n",
        "        ],\n",
        "        \"y_variable\": [\"success\"],\n",
        "    }\n",
        "\n",
        "    # âžŠ  Build schema from the dict\n",
        "    schema = DynamicSchema(FEATURE_LISTS)\n",
        "\n",
        "    # read final_features.txt\n",
        "    with open(\"data/models/features/final_features.txt\", \"r\") as f:\n",
        "        final_features = [line.strip() for line in f]\n",
        "    print(f\"---------------final_features---------------\")\n",
        "    print(final_features)\n",
        "    numeric_final = [f for f in final_features if f in schema.numerical]\n",
        "\n",
        "    print(f\"\\nâœ¨ Final feature count: {len(numeric_final)}\")\n",
        "    print(\"Selected features:\")\n",
        "    for feat in numeric_final:\n",
        "        print(f\"  â€¢ {feat}\")\n",
        "\n",
        "    # ðŸ”„ Push into schema so every later stage sees the new list\n",
        "    update_schema_numerical(schema, numeric_final)\n",
        "\n",
        "    # output final_features from schema\n",
        "    FEATURE_LISTS = schema.lists\n",
        "    print(f\"---------------FEATURE_LISTS---------------\")\n",
        "    print(FEATURE_LISTS)\n",
        "\n",
        "    pre = DataPreprocessor()\n",
        "    pre.update_config(**CONFIG)\n",
        "    pre.update_feature_lists(**FEATURE_LISTS)\n",
        "    _ = pre.preprocess_complete(df_feat)\n",
        "    X, y = pre.fit_transform_features()\n",
        "\n",
        "    print(\"First 5 rows after inverseâ€‘transform roundâ€‘trip â†’\")\n",
        "    print(pre.invert_preprocessing(X[:5]).head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Package Init Files\n",
        "\n",
        "Creating __init__.py files for all modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/__init__.py\n",
        "\"\"\"\n",
        "NFL Kicker Analysis Package\n",
        "A comprehensive toolkit for analyzing NFL field goal kicker performance.\n",
        "\"\"\"\n",
        "\n",
        "__version__ = \"1.0.0\"\n",
        "__author__ = \"NFL Analytics Team\"\n",
        "\n",
        "# Import main classes for easy access\n",
        "from .config import config\n",
        "from .data.loader import DataLoader\n",
        "from .data.preprocessor import DataPreprocessor\n",
        "\n",
        "__all__ = [\n",
        "    'config',\n",
        "    'DataLoader',\n",
        "    'DataPreprocessor'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/data/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/data/__init__.py\n",
        "\"\"\"\n",
        "Data module for NFL kicker analysis.\n",
        "\"\"\"\n",
        "\n",
        "from .loader import DataLoader\n",
        "from .preprocessor import DataPreprocessor\n",
        "\n",
        "__all__ = ['DataLoader', 'DataPreprocessor']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Metrics and Utilities Module\n",
        "\n",
        "Core utilities for EPA calculations and performance metrics.\n",
        "\n",
        "1. EPACalculator\n",
        "\n",
        "    Purpose\n",
        "    Compute an Expected Points Added (EPA)â€“style rating for each kicker, based on how their made-field-goal rate at various distances compares to the league average.\n",
        "\n",
        "    Key Methods\n",
        "\n",
        "        calculate_empirical_success_rate(data, kicker_name, distance, â€¦)\n",
        "        Looks up a kickerâ€™s historical success rate in a Â±distance_range window around a given yard line; if they donâ€™t have enough attempts there, it falls back to the league average.\n",
        "\n",
        "        calculate_league_average_epa(data)\n",
        "        Computes the league-wide EPA per kick by weighting each distanceâ€™s success rate (from config.DISTANCE_PROFILE and config.DISTANCE_WEIGHTS) times 3 points per make.\n",
        "\n",
        "        calculate_kicker_epa_plus(data, kicker_name)\n",
        "        For one kicker, sums up their distance-weighted EPA and subtracts the league average to produce an â€œEPA-FG+â€ number.\n",
        "\n",
        "        calculate_all_kicker_ratings(data)\n",
        "        Loops over every kicker in the dataset and builds a leaderboard DataFrame of EPA-FG+ and rank.\n",
        "\n",
        "    How to use it\n",
        "    After youâ€™ve loaded and preprocessed your DataFrame (so it has at least these columns:\n",
        "\n",
        "'player_name', 'player_id', 'attempt_yards', 'success'\n",
        "\n",
        "), you would call:\n",
        "\n",
        "    from nfl_kicker_analysis.utils.metrics import EPACalculator\n",
        "    epa = EPACalculator()\n",
        "    leaderboard = epa.calculate_all_kicker_ratings(processed_df)\n",
        "\n",
        "    That gives you a standalone table of kicker ratings.\n",
        "\n",
        "2. ModelEvaluator\n",
        "\n",
        "    Purpose\n",
        "    Compute standard classification metrics and compare different modelsâ€™ results in a tidy DataFrame.\n",
        "\n",
        "    Key Methods\n",
        "\n",
        "        calculate_classification_metrics(y_true, y_pred_proba)\n",
        "        Returns a dict with\n",
        "\n",
        "            auc_roc\n",
        "\n",
        "            brier_score\n",
        "\n",
        "            accuracy (thresholded at 0.5)\n",
        "\n",
        "            log_loss\n",
        "\n",
        "        compare_models(models_results)\n",
        "        Takes a dict of { model_name: metrics_dict } and turns it into a DataFrame, sorted by AUC.\n",
        "\n",
        "    How to use it\n",
        "    After fitting your model(s) and getting back prediction probabilities:\n",
        "\n",
        "    from nfl_kicker_analysis.utils.metrics import ModelEvaluator\n",
        "\n",
        "    evaluator = ModelEvaluator()\n",
        "    metrics = evaluator.calculate_classification_metrics(y_test, y_pred_probs)\n",
        "    results = {\n",
        "        'MyModel': metrics,\n",
        "        'Baseline': other_metrics,\n",
        "    }\n",
        "    comparison_df = evaluator.compare_models(results)\n",
        "    print(comparison_df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/utils/metrics.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/utils/metrics.py\n",
        "\"\"\"\n",
        "Metrics utilities for NFL kicker analysis.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,     # AUC-PR\n",
        "    log_loss,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    brier_score_loss,\n",
        ")\n",
        "try:\n",
        "    from sklearn.calibration import calibration_curve\n",
        "except ImportError:\n",
        "    from sklearn.metrics import calibration_curve\n",
        "from typing import Dict, Optional, Union, List, Any, Callable, Tuple\n",
        "from numpy.typing import NDArray\n",
        "import arviz as az\n",
        "\n",
        "from src.nfl_kicker_analysis.config import config\n",
        "\n",
        "class EPACalculator:\n",
        "    \"\"\"Calculates EPA-based metrics for kickers.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the EPA calculator.\"\"\"\n",
        "        self.baseline_probs: Dict[int, float] = {}\n",
        "        self.distance_profile = config.DISTANCE_PROFILE\n",
        "        self.distance_weights = config.DISTANCE_WEIGHTS\n",
        "\n",
        "    def calculate_baseline_probs(self, data: pd.DataFrame) -> Dict[int, float]:\n",
        "        \"\"\"\n",
        "        Calculate baseline success probabilities by distance.\n",
        "\n",
        "        Args:\n",
        "            data: DataFrame with attempt_yards and success\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping distance to success probability\n",
        "        \"\"\"\n",
        "        baseline = data.groupby('attempt_yards')['success'].mean()\n",
        "        self.baseline_probs = baseline.to_dict()\n",
        "        return self.baseline_probs\n",
        "\n",
        "    def calculate_epa_fg_plus(self, data: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calculate EPA-FG+ for each kicker.\n",
        "\n",
        "        Args:\n",
        "            data: DataFrame with kicker attempts\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with kicker EPA-FG+ ratings\n",
        "        \"\"\"\n",
        "        if not self.baseline_probs:\n",
        "            self.baseline_probs = self.calculate_baseline_probs(data)\n",
        "\n",
        "        # Calculate expected points\n",
        "        data = data.copy()\n",
        "        data.loc[:, 'expected_points'] = data['attempt_yards'].map(lambda x: self.baseline_probs.get(x, 0.5)) * 3\n",
        "        data.loc[:, 'actual_points'] = data['success'] * 3\n",
        "        data.loc[:, 'epa'] = data['actual_points'] - data['expected_points']\n",
        "\n",
        "        # Calculate EPA-FG+ per kicker\n",
        "        kicker_stats = data.groupby('player_name').agg({\n",
        "            'epa': ['count', 'mean', 'sum'],\n",
        "            'player_id': 'first'  # Keep player ID\n",
        "        })\n",
        "\n",
        "        kicker_stats.columns = ['attempts', 'epa_per_kick', 'total_epa', 'player_id']\n",
        "        kicker_stats.loc[:, 'epa_fg_plus'] = kicker_stats['epa_per_kick']\n",
        "\n",
        "        # Add rank\n",
        "        kicker_stats.loc[:, 'rank'] = kicker_stats['epa_fg_plus'].rank(ascending=False, method='min')\n",
        "\n",
        "        return kicker_stats.reset_index()\n",
        "\n",
        "    def calculate_clutch_rating_with_shrinkage(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        prior_a: float = 8.0,\n",
        "        prior_b: float = 2.0\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calculate clutch field goal rating with beta-binomial shrinkage.\n",
        "\n",
        "        Args:\n",
        "            data: DataFrame with kicker attempts including is_clutch column\n",
        "            prior_a: Beta prior alpha parameter (favors success)\n",
        "            prior_b: Beta prior beta parameter (favors failure)\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with clutch ratings per kicker\n",
        "        \"\"\"\n",
        "        # Default prior centers on 80% (8/(8+2))\n",
        "\n",
        "        results = []\n",
        "        for player_name, grp in data.groupby('player_name'):\n",
        "            if 'is_clutch' in grp.columns:\n",
        "                clutch_attempts = grp[grp['is_clutch'] == 1]\n",
        "            else:\n",
        "                # Fallback if no clutch column\n",
        "                clutch_attempts = grp[grp['success'] == 0]  # Empty fallback\n",
        "\n",
        "            made_clutch = clutch_attempts['success'].sum() if len(clutch_attempts) > 0 else 0\n",
        "            miss_clutch = len(clutch_attempts) - made_clutch if len(clutch_attempts) > 0 else 0\n",
        "\n",
        "            # Beta-binomial posterior\n",
        "            post_a = prior_a + made_clutch\n",
        "            post_b = prior_b + miss_clutch\n",
        "            clutch_rate_shrunk = post_a / (post_a + post_b)\n",
        "\n",
        "            # Raw clutch rate for comparison\n",
        "            raw_clutch_rate = clutch_attempts['success'].mean() if len(clutch_attempts) > 0 else 0.0\n",
        "\n",
        "            results.append({\n",
        "                'player_name': player_name,\n",
        "                'player_id': int(grp['player_id'].iat[0]),\n",
        "                'total_attempts': len(grp),\n",
        "                'clutch_attempts': len(clutch_attempts),\n",
        "                'clutch_made': made_clutch,\n",
        "                'raw_clutch_rate': raw_clutch_rate,\n",
        "                'clutch_rate_shrunk': clutch_rate_shrunk,\n",
        "                'shrinkage_applied': abs(clutch_rate_shrunk - raw_clutch_rate)\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(results)\n",
        "        df['clutch_rank'] = df['clutch_rate_shrunk'].rank(ascending=False, method='min')\n",
        "        return df.sort_values('clutch_rank')\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # NEW helper â”€ bootstrap EPA-FGâº draws for ONE kicker\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def _bootstrap_kicker_epa(\n",
        "        self,\n",
        "        grp: pd.DataFrame,\n",
        "        *,\n",
        "        n_draws: int = 2_000,\n",
        "        rng: np.random.Generator,\n",
        "    ) -> NDArray[np.float_]:\n",
        "        \"\"\"\n",
        "        Non-parametric bootstrap: resample the kicker's attempts (with replacement)\n",
        "        and recompute mean EPA-FGâº.  Returns an array of shape (n_draws,).\n",
        "\n",
        "        Args:\n",
        "            grp: DataFrame with kicker's attempts\n",
        "            n_draws: Number of bootstrap draws\n",
        "            rng: Random number generator\n",
        "\n",
        "        Returns:\n",
        "            Array of bootstrap EPA-FG+ draws\n",
        "        \"\"\"\n",
        "        # pre-compute baseline EPA for every attempt in the group\n",
        "        base_pts = grp[\"attempt_yards\"].map(\n",
        "            lambda x: self.baseline_probs.get(x, 0.5)\n",
        "        ).to_numpy(np.float_) * 3.0\n",
        "        actual   = grp[\"success\"].to_numpy(np.int_) * 3.0\n",
        "        diff     = actual - base_pts                    # vector of EPA per attempt\n",
        "\n",
        "        if diff.size == 0:\n",
        "            return np.array([np.nan])                   # safeguard â€“ should not happen\n",
        "\n",
        "        boot = rng.choice(diff, size=(n_draws, diff.size), replace=True)\n",
        "        return boot.mean(axis=1)                       # average per draw\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # PUBLIC â€“ EPA-FGâº with 95 % interval & certainty flag\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def calculate_epa_fg_plus_ci(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        *,\n",
        "        n_draws: int = 2_000,\n",
        "        alpha: float = 0.05,\n",
        "        random_state: int | None = 42,\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Bootstrap EPA-FGâº per kicker, returning mean, lower, upper bounds and a\n",
        "        qualitative certainty label (high | medium | low).\n",
        "\n",
        "        Args:\n",
        "            data: DataFrame with kicker attempts\n",
        "            n_draws: Number of bootstrap draws\n",
        "            alpha: Significance level for confidence intervals\n",
        "            random_state: Random seed for reproducibility\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with bootstrap EPA-FG+ ratings and confidence intervals\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        * Uses the **Jeffreys-prior** interpretation of a (1â€“alpha) credible\n",
        "          interval via percentile bootstrap.\n",
        "        * CI width thresholds (empirical 33rd & 66th percentiles) define the\n",
        "          certainty bands as recommended in sports-analytics literature.\n",
        "        \"\"\"\n",
        "        if not self.baseline_probs:\n",
        "            self.calculate_baseline_probs(data)\n",
        "\n",
        "        rng = np.random.default_rng(random_state)\n",
        "\n",
        "        records: list[dict[str, Any]] = []\n",
        "        for player, grp in data.groupby(\"player_name\"):\n",
        "            draws = self._bootstrap_kicker_epa(grp, n_draws=n_draws, rng=rng)\n",
        "            mean  = float(np.nanmean(draws))\n",
        "            lower = float(np.nanpercentile(draws, 100 * alpha / 2))\n",
        "            upper = float(np.nanpercentile(draws, 100 * (1 - alpha / 2)))\n",
        "            width = upper - lower\n",
        "            records.append({\n",
        "                \"player_name\": player,\n",
        "                \"player_id\":   int(grp[\"player_id\"].iat[0]),\n",
        "                \"attempts\":    int(len(grp)),\n",
        "                \"epa_fg_plus_mean\":  mean,\n",
        "                \"hdi_lower\":   lower,\n",
        "                \"hdi_upper\":   upper,\n",
        "                \"ci_width\":    width,\n",
        "            })\n",
        "\n",
        "        tbl = pd.DataFrame(records).set_index(\"player_name\")\n",
        "\n",
        "        # Certainty levels by tercile of CI-width\n",
        "        q33, q66 = tbl[\"ci_width\"].quantile([.33, .66])\n",
        "        tbl[\"certainty\"] = np.where(\n",
        "            tbl[\"ci_width\"] <= q33, \"high\",\n",
        "            np.where(tbl[\"ci_width\"] <= q66, \"medium\", \"low\")\n",
        "        )\n",
        "\n",
        "        tbl[\"rank\"] = tbl[\"epa_fg_plus_mean\"].rank(ascending=False, method=\"min\")\n",
        "        return tbl.sort_values(\"rank\")\n",
        "\n",
        "    def calculate_all_kicker_ratings(self, data: pd.DataFrame, include_ci: bool = False) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calculate complete kicker ratings, optionally with uncertainty intervals.\n",
        "\n",
        "        Args:\n",
        "            data: Complete dataset\n",
        "            include_ci: Whether to include bootstrap confidence intervals\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with kicker ratings\n",
        "        \"\"\"\n",
        "        print(\"Calculating EPA-FG+ ratings...\")\n",
        "\n",
        "        if include_ci:\n",
        "            ratings = self.calculate_epa_fg_plus_ci(data)\n",
        "            metric_col = \"epa_fg_plus_mean\"\n",
        "        else:\n",
        "            ratings = self.calculate_epa_fg_plus(data)\n",
        "            metric_col = \"epa_fg_plus\"\n",
        "\n",
        "        print(f\"\\nTop 5 kickers by EPA-FG+:\")\n",
        "        display_cols = ['attempts', metric_col, 'rank']\n",
        "        if include_ci:\n",
        "            display_cols.extend(['hdi_lower', 'hdi_upper', 'certainty'])\n",
        "\n",
        "        top_5 = ratings.head(5) if include_ci else ratings.nlargest(5, metric_col)\n",
        "        if include_ci:\n",
        "            print(top_5[display_cols].to_string(index=True))\n",
        "        else:\n",
        "            print(top_5[['player_name'] + display_cols].to_string(index=False))\n",
        "\n",
        "        return ratings\n",
        "\n",
        "class ModelEvaluator:\n",
        "    \"\"\"Compute a rich set of discrimination & calibration metrics.\"\"\"\n",
        "\n",
        "    # ---------- single-metric helpers ----------\n",
        "    @staticmethod\n",
        "    def calculate_auc(y, p) -> float:\n",
        "        return float(roc_auc_score(y, p))\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_auc_pr(y, p) -> float:\n",
        "        return float(average_precision_score(y, p))  # AUC-PR\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_log_loss(y, p) -> float:\n",
        "        return float(log_loss(y, p))\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_brier_score(y, p) -> float:\n",
        "        return float(brier_score_loss(y, p))\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_threshold_metrics(y, p, thresh: float = 0.5) -> Tuple[float, float, float, float]:\n",
        "        \"\"\"Return accuracy, precision, recall, F1 at a chosen threshold.\"\"\"\n",
        "        pred = (p >= thresh).astype(int)\n",
        "        acc = float(accuracy_score(y, pred))\n",
        "        prec = float(precision_score(y, pred, zero_division=\"warn\"))\n",
        "        rec = float(recall_score(y, pred, zero_division=\"warn\"))\n",
        "        f1 = float(f1_score(y, pred, zero_division=\"warn\"))\n",
        "        return acc, prec, rec, f1\n",
        "\n",
        "    # ---------- calibration helpers ----------\n",
        "    @staticmethod\n",
        "    def calculate_ece(y, p, n_bins: int = 10) -> float:\n",
        "        \"\"\"\n",
        "        Expected Calibration Error (ECE) using equally spaced probability bins.\n",
        "\n",
        "        Handles the fact that `sklearn.calibration.calibration_curve` drops\n",
        "        empty bins, which otherwise causes a length-mismatch when you try to\n",
        "        multiply by fixed-length weights.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 1 â€“ Compute reliability data.  The function *silently* removes\n",
        "            #     any empty bin, so prob_true/pred may be < n_bins long.\n",
        "            prob_true, prob_pred = calibration_curve(\n",
        "                y, p, n_bins=n_bins, strategy=\"uniform\"\n",
        "            )\n",
        "\n",
        "            # 2 â€“ Re-create the original histogram and keep *only* non-empty bins\n",
        "            bin_counts, _ = np.histogram(p, bins=n_bins, range=(0, 1))\n",
        "            non_empty_mask = bin_counts > 0\n",
        "\n",
        "            # Make sure shapes now align\n",
        "            bin_counts = bin_counts[non_empty_mask]\n",
        "            prob_true  = np.asarray(prob_true)\n",
        "            prob_pred  = np.asarray(prob_pred)\n",
        "\n",
        "            # Sanity check â€“ all arrays must have identical length\n",
        "            assert len(prob_true) == len(bin_counts) == len(prob_pred), (\n",
        "                \"Length mismatch after masking empty bins\"\n",
        "            )\n",
        "\n",
        "            # 3 â€“ Compute weighted absolute gap\n",
        "            weights = bin_counts / bin_counts.sum()\n",
        "            ece = np.sum(np.abs(prob_true - prob_pred) * weights)\n",
        "            return float(ece)\n",
        "\n",
        "        except Exception as exc:\n",
        "            # Fallback â€“ simple loop (same logic as original fallback)\n",
        "            bin_edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "            ece = 0.0\n",
        "            for lo, hi in zip(bin_edges[:-1], bin_edges[1:]):\n",
        "                in_bin = (p > lo) & (p <= hi)\n",
        "                if in_bin.any():\n",
        "                    acc_bin  = y[in_bin].mean()\n",
        "                    conf_bin = p[in_bin].mean()\n",
        "                    ece      += np.abs(acc_bin - conf_bin) * in_bin.mean()\n",
        "            return float(ece)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def reliability_curve(y, p, n_bins: int = 10) -> pd.DataFrame:\n",
        "        \"\"\"Return a DataFrame for plotting a reliability diagram.\"\"\"\n",
        "        try:\n",
        "            prob_true, prob_pred = calibration_curve(y, p, n_bins=n_bins, strategy=\"uniform\")\n",
        "            return pd.DataFrame({\"prob_pred\": prob_pred, \"prob_true\": prob_true})\n",
        "        except (ImportError, TypeError):\n",
        "            # Fallback implementation\n",
        "            bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "            bin_centers = (bin_boundaries[:-1] + bin_boundaries[1:]) / 2\n",
        "            bin_lowers = bin_boundaries[:-1]\n",
        "            bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "            prob_true = []\n",
        "            prob_pred = []\n",
        "\n",
        "            for bin_lower, bin_upper, bin_center in zip(bin_lowers, bin_uppers, bin_centers):\n",
        "                in_bin = (p > bin_lower) & (p <= bin_upper)\n",
        "                if np.sum(in_bin) > 0:\n",
        "                    prob_true.append(y[in_bin].astype(float).mean())\n",
        "                    prob_pred.append(bin_center)\n",
        "\n",
        "            return pd.DataFrame({\"prob_pred\": prob_pred, \"prob_true\": prob_true})\n",
        "\n",
        "    # ---------- public aggregator ----------\n",
        "    def calculate_classification_metrics(self, y_true, y_pred_proba) -> Dict[str, float]:\n",
        "        \"\"\"Return a full metric dictionary.\"\"\"\n",
        "        metrics: Dict[str, float] = {\n",
        "            \"auc_roc\":   self.calculate_auc(y_true, y_pred_proba),\n",
        "            \"auc_pr\":    self.calculate_auc_pr(y_true, y_pred_proba),\n",
        "            \"log_loss\":  self.calculate_log_loss(y_true, y_pred_proba),\n",
        "            \"brier\":     self.calculate_brier_score(y_true, y_pred_proba),\n",
        "            \"ece\":       self.calculate_ece(y_true, y_pred_proba),\n",
        "        }\n",
        "        acc, prec, rec, f1 = self.calculate_threshold_metrics(y_true, y_pred_proba)\n",
        "        metrics.update({\n",
        "            \"accuracy\":  acc,\n",
        "            \"precision\": prec,\n",
        "            \"recall\":    rec,\n",
        "            \"f1\":        f1,\n",
        "        })\n",
        "        return metrics  # 10 metrics total\n",
        "\n",
        "    # ---------- comparison helper ----------\n",
        "    def compare_models(self, results: Dict[str, Dict[str, float]]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Turn {model: metric_dict} into a tidy table ordered by AUC-ROC.\n",
        "        \"\"\"\n",
        "        df = pd.DataFrame(results).T  # one row per model\n",
        "        # guarantee consistent column order\n",
        "        desired_cols: List[str] = [\n",
        "            \"auc_roc\", \"auc_pr\", \"log_loss\", \"brier\", \"ece\",\n",
        "            \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
        "        ]\n",
        "        for c in desired_cols:\n",
        "            if c not in df.columns:\n",
        "                df[c] = np.nan\n",
        "        return df[desired_cols].sort_values(\"auc_roc\", ascending=False)\n",
        "\n",
        "class BayesianEvaluator:\n",
        "    \"\"\"Wrap ArviZ to calculate WAIC and PSIS-LOO in one call.\"\"\"\n",
        "    def information_criteria(self, trace, pointwise: bool = False) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Return WAIC and PSIS-LOO for a fitted PyMC model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        trace : arviz.InferenceData\n",
        "        pointwise : bool\n",
        "            If True, also return the pointwise arrays for advanced analysis.\n",
        "        \"\"\"\n",
        "        waic_res = az.waic(trace, scale=\"deviance\")\n",
        "        loo_res  = az.loo(trace,  scale=\"deviance\")\n",
        "        info = {\n",
        "            \"waic\":      float(waic_res.waic),\n",
        "            \"waic_se\":   float(waic_res.waic_se),\n",
        "            \"psis_loo\":  float(loo_res.loo),\n",
        "            \"psis_loo_se\": float(loo_res.loo_se),\n",
        "        }\n",
        "        if pointwise:\n",
        "            info[\"waic_i\"] = waic_res.waic_i\n",
        "            info[\"loo_i\"]  = loo_res.loo_i\n",
        "        return info\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from src.nfl_kicker_analysis.data.loader import DataLoader\n",
        "    # Test the data loader\n",
        "    print(\"Testing DataLoader...\")\n",
        "\n",
        "    loader = DataLoader()\n",
        "\n",
        "    try:\n",
        "        # Load complete dataset\n",
        "        df = loader.load_complete_dataset()\n",
        "\n",
        "        # Print summary\n",
        "        summary = loader.get_data_summary()\n",
        "        print(\"\\nData Summary:\")\n",
        "        print(f\"Total attempts: {summary['total_attempts']:,}\")\n",
        "        print(f\"Unique kickers: {summary['unique_kickers']}\")\n",
        "        print(f\"Seasons: {summary['unique_seasons']}\")\n",
        "        print(f\"Outcomes: {summary['outcome_counts']}\")\n",
        "\n",
        "        print(\"******* DataLoader tests passed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"-------------- Error testing DataLoader: {e}\")\n",
        "        print(\"Note: This is expected if data files are not present.\")\n",
        "\n",
        "\n",
        "\n",
        "    # Test the metrics module\n",
        "    print(\"Testing EPA Calculator...\")\n",
        "\n",
        "\n",
        "    # Test EPA calculator\n",
        "    epa_calc = EPACalculator()\n",
        "\n",
        "    try:\n",
        "        # Test league average calculation\n",
        "        league_avg = epa_calc.calculate_league_average_epa(df)\n",
        "        print(f\"League average EPA: {league_avg:.3f}\")\n",
        "\n",
        "        # Test individual kicker rating\n",
        "        rating = epa_calc.calculate_kicker_epa_plus(df, 'Player A')\n",
        "        print(f\"Player A EPA-FG+: {rating['epa_fg_plus']:.3f}\")\n",
        "\n",
        "        # Test all kicker ratings\n",
        "        all_ratings = epa_calc.calculate_all_kicker_ratings(df)\n",
        "        print(f\"Calculated ratings for {len(all_ratings)} kickers\")\n",
        "\n",
        "        # Test model evaluator\n",
        "        evaluator = ModelEvaluator()\n",
        "        y_true = np.random.choice([0, 1], 100)\n",
        "        y_pred = np.random.random(100)\n",
        "\n",
        "        metrics = evaluator.calculate_classification_metrics(y_true, y_pred)\n",
        "        print(f\"Sample model AUC: {metrics['auc']:.3f}\")\n",
        "\n",
        "        print(\"******* Metrics module tests passed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"-------------- Error testing metrics: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Traditional Models Module\n",
        "\n",
        "Implementation of traditional machine learning models for comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/nfl_kicker_analysis/models/tree_based_bayes_optimized_models.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/models/tree_based_bayes_optimized_models.py\n",
        "\"\"\"\n",
        "Traditional ML models for NFL kicker analysis.\n",
        "Includes simple logistic regression, ridge logistic regression, and random forest.\n",
        "Each model can be optionally tuned using Bayesian optimization with Optuna.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from typing import Dict, Tuple, Optional, Union, Any\n",
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from numpy.typing import NDArray\n",
        "\n",
        "from src.nfl_kicker_analysis.utils.metrics import ModelEvaluator\n",
        "\n",
        "class TreeBasedModelSuite:\n",
        "    \"\"\"Suite of traditional ML models with optional Bayesian optimization.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the model suite.\"\"\"\n",
        "        self.fitted_models: Dict[str, Union[LogisticRegression, RandomForestClassifier, XGBClassifier, CatBoostClassifier]] = {}\n",
        "        self.evaluator = ModelEvaluator()\n",
        "        self._tss = TimeSeriesSplit(n_splits=3)  # 3-fold CV that respects time order\n",
        "\n",
        "    def prepare_features(self, data: pd.DataFrame) -> Tuple[NDArray[np.float_], NDArray[np.float_], NDArray[np.int_], OneHotEncoder]:\n",
        "        \"\"\"\n",
        "        Prepare feature matrices for modeling.\n",
        "\n",
        "        Args:\n",
        "            data: DataFrame with attempt_yards and kicker_id\n",
        "\n",
        "        Returns:\n",
        "            Tuple of:\n",
        "            - Distance-only features\n",
        "            - Combined features (distance + one-hot kicker)\n",
        "            - Kicker IDs\n",
        "            - OneHotEncoder for kickers\n",
        "        \"\"\"\n",
        "        # Distance features\n",
        "        X_distance = data['attempt_yards'].values.astype(np.float_).reshape(-1, 1)\n",
        "\n",
        "        # Kicker IDs for tree models\n",
        "        kicker_ids = data['kicker_id'].values.astype(np.int_).reshape(-1, 1)\n",
        "\n",
        "        # One-hot encode kickers for linear models\n",
        "        encoder = OneHotEncoder(sparse_output=True)\n",
        "        kicker_onehot = encoder.fit_transform(kicker_ids)\n",
        "        X_combined = np.hstack([X_distance, kicker_onehot.toarray()])\n",
        "\n",
        "        return X_distance, X_combined, kicker_ids, encoder\n",
        "\n",
        "    def create_time_split(self, data: pd.DataFrame) -> Tuple[NDArray[np.int_], NDArray[np.int_]]:\n",
        "        \"\"\"\n",
        "        Create train/test split by time.\n",
        "\n",
        "        Args:\n",
        "            data: DataFrame with game_date\n",
        "\n",
        "        Returns:\n",
        "            Train and test indices\n",
        "        \"\"\"\n",
        "        train_mask = data['season'] <= 2017\n",
        "        test_mask = data['season'] == 2018\n",
        "\n",
        "        train_idx = np.where(train_mask)[0]\n",
        "        test_idx = np.where(test_mask)[0]\n",
        "\n",
        "        print(f\"Train: {len(train_idx):,} attempts ({train_mask.mean():.1%})\")\n",
        "        print(f\"Test: {len(test_idx):,} attempts ({test_mask.mean():.1%})\")\n",
        "\n",
        "        return train_idx, test_idx\n",
        "\n",
        "    def _tune_simple_logistic_optuna(\n",
        "        self,\n",
        "        X: NDArray[np.float_],\n",
        "        y: NDArray[np.int_],\n",
        "        n_trials: int = 50,\n",
        "    ) -> LogisticRegression:\n",
        "        \"\"\"\n",
        "        Bayesian-optimize and fit a simple LogisticRegression.\n",
        "        Returns the fitted best model.\n",
        "        \"\"\"\n",
        "        def objective(trial: optuna.Trial) -> float:\n",
        "            params = {\n",
        "                \"C\": trial.suggest_float(\"C\", 1e-5, 100, log=True),\n",
        "                \"max_iter\": 1000,\n",
        "                \"random_state\": 42,\n",
        "            }\n",
        "            aucs = []\n",
        "            for tr_idx, val_idx in self._tss.split(X):\n",
        "                model = LogisticRegression(**params)\n",
        "                model.fit(X[tr_idx], y[tr_idx])\n",
        "                preds = model.predict_proba(X[val_idx])[:, 1].astype(np.float_)\n",
        "                aucs.append(self.evaluator.calculate_auc(y[val_idx], preds))\n",
        "            return float(np.mean(aucs))\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        best_params = study.best_params\n",
        "        best_params.update(dict(max_iter=1000, random_state=42))\n",
        "        best_model = LogisticRegression(**best_params)\n",
        "        best_model.fit(X, y)\n",
        "        return best_model\n",
        "\n",
        "    def _tune_ridge_logistic_optuna(\n",
        "        self,\n",
        "        X: NDArray[np.float_],\n",
        "        y: NDArray[np.int_],\n",
        "        n_trials: int = 50,\n",
        "    ) -> LogisticRegression:\n",
        "        \"\"\"\n",
        "        Bayesian-optimize and fit a ridge LogisticRegression.\n",
        "        Returns the fitted best model.\n",
        "        \"\"\"\n",
        "        def objective(trial: optuna.Trial) -> float:\n",
        "            params = {\n",
        "                \"C\": trial.suggest_float(\"C\", 1e-5, 100, log=True),\n",
        "                \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0, 1),\n",
        "                \"penalty\": \"elasticnet\",\n",
        "                \"solver\": \"saga\",\n",
        "                \"max_iter\": 1000,\n",
        "                \"random_state\": 42,\n",
        "            }\n",
        "            aucs = []\n",
        "            for tr_idx, val_idx in self._tss.split(X):\n",
        "                model = LogisticRegression(**params)\n",
        "                model.fit(X[tr_idx], y[tr_idx])\n",
        "                preds = model.predict_proba(X[val_idx])[:, 1].astype(np.float_)\n",
        "                aucs.append(self.evaluator.calculate_auc(y[val_idx], preds))\n",
        "            return float(np.mean(aucs))\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        best_params = study.best_params\n",
        "        best_params.update(dict(penalty=\"elasticnet\", solver=\"saga\", max_iter=1000, random_state=42))\n",
        "        best_model = LogisticRegression(**best_params)\n",
        "        best_model.fit(X, y)\n",
        "        return best_model\n",
        "\n",
        "    def _tune_random_forest_optuna(\n",
        "        self,\n",
        "        X: NDArray[np.float_],\n",
        "        y: NDArray[np.int_],\n",
        "        n_trials: int = 50,\n",
        "    ) -> RandomForestClassifier:\n",
        "        \"\"\"\n",
        "        Bayesian-optimize and fit a RandomForestClassifier.\n",
        "        Returns the fitted best model.\n",
        "        \"\"\"\n",
        "        def objective(trial: optuna.Trial) -> float:\n",
        "            params = {\n",
        "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
        "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "                \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
        "                \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
        "                \"max_features\": trial.suggest_float(\"max_features\", 0.1, 1.0),\n",
        "                \"n_jobs\": -1,\n",
        "                \"random_state\": 42,\n",
        "            }\n",
        "            aucs = []\n",
        "            for tr_idx, val_idx in self._tss.split(X):\n",
        "                model = RandomForestClassifier(**params)\n",
        "                model.fit(X[tr_idx], y[tr_idx])\n",
        "                preds = model.predict_proba(X[val_idx])[:, 1].astype(np.float_)\n",
        "                aucs.append(self.evaluator.calculate_auc(y[val_idx], preds))\n",
        "            return float(np.mean(aucs))\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        best_params = study.best_params\n",
        "        best_params.update(dict(n_jobs=-1, random_state=42))\n",
        "        best_model = RandomForestClassifier(**best_params)\n",
        "        best_model.fit(X, y)\n",
        "        return best_model\n",
        "\n",
        "    def _tune_xgboost_optuna(\n",
        "        self,\n",
        "        X: NDArray[np.float_],\n",
        "        y: NDArray[np.int_],\n",
        "        n_trials: int = 50,\n",
        "    ) -> XGBClassifier:\n",
        "        \"\"\"\n",
        "        Bayesian-optimize and fit an XGBClassifier.\n",
        "        Returns the fitted best model.\n",
        "        \"\"\"\n",
        "        def objective(trial: optuna.Trial) -> float:\n",
        "            params = {\n",
        "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 600),\n",
        "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "                \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "                \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
        "                \"objective\": \"binary:logistic\",\n",
        "                \"eval_metric\": \"logloss\",\n",
        "                \"n_jobs\": -1,\n",
        "                \"random_state\": 42,\n",
        "            }\n",
        "            aucs = []\n",
        "            for tr_idx, val_idx in self._tss.split(X):\n",
        "                model = XGBClassifier(**params)\n",
        "                model.fit(X[tr_idx], y[tr_idx])\n",
        "                preds = model.predict_proba(X[val_idx])[:, 1].astype(np.float_)\n",
        "                aucs.append(self.evaluator.calculate_auc(y[val_idx], preds))\n",
        "            return float(np.mean(aucs))\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        best_params = study.best_params\n",
        "        best_params.update(dict(objective=\"binary:logistic\", eval_metric=\"logloss\", n_jobs=-1, random_state=42))\n",
        "        best_model = XGBClassifier(**best_params)\n",
        "        best_model.fit(X, y)\n",
        "        return best_model\n",
        "\n",
        "    def _tune_catboost_optuna(\n",
        "        self,\n",
        "        df_train: pd.DataFrame,          # â†  NOW a DataFrame, not ndarray\n",
        "        y_train: NDArray[np.int_],\n",
        "        n_trials: int = 50,\n",
        "    ) -> CatBoostClassifier:\n",
        "        \"\"\"\n",
        "        Bayesian-optimise and fit a CatBoostClassifier on a mixed-dtype DataFrame.\n",
        "        The column ``'kicker_id'`` is treated as categorical automatically.\n",
        "        \"\"\"\n",
        "        cat_cols = [\"kicker_id\"]         # name-based is safer than index-based\n",
        "\n",
        "        def objective(trial: optuna.Trial) -> float:\n",
        "            params = {\n",
        "                \"iterations\":        trial.suggest_int (\"iterations\",        300, 800),\n",
        "                \"depth\":             trial.suggest_int (\"depth\",             4,   10),\n",
        "                \"learning_rate\":     trial.suggest_float(\"learning_rate\",    0.01, 0.3, log=True),\n",
        "                \"l2_leaf_reg\":       trial.suggest_float(\"l2_leaf_reg\",      1e-3, 10.0, log=True),\n",
        "                \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
        "                \"random_strength\":   trial.suggest_float(\"random_strength\",  0.1, 10.0),\n",
        "                \"border_count\":      trial.suggest_int (\"border_count\",      32,  255),\n",
        "                \"loss_function\":     \"Logloss\",\n",
        "                \"eval_metric\":       \"AUC\",\n",
        "                \"verbose\":           False,\n",
        "                \"random_seed\":       42,\n",
        "            }\n",
        "            aucs = []\n",
        "            for tr_idx, val_idx in self._tss.split(df_train):\n",
        "                model = CatBoostClassifier(**params)\n",
        "                model.fit(\n",
        "                    df_train.iloc[tr_idx],\n",
        "                    y_train[tr_idx],\n",
        "                    cat_features=cat_cols,\n",
        "                    verbose=False,\n",
        "                )\n",
        "                preds = model.predict_proba(df_train.iloc[val_idx])[:, 1].astype(np.float_)\n",
        "                aucs.append(self.evaluator.calculate_auc(y_train[val_idx], preds))\n",
        "            return float(np.mean(aucs))\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "\n",
        "        best_params = study.best_params\n",
        "        best_params.update(dict(loss_function=\"Logloss\",\n",
        "                                eval_metric=\"AUC\",\n",
        "                                verbose=False,\n",
        "                                random_seed=42))\n",
        "        best_model = CatBoostClassifier(**best_params)\n",
        "        best_model.fit(df_train, y_train, cat_features=cat_cols, verbose=False)\n",
        "        return best_model\n",
        "\n",
        "    def fit_all_models(self, data: pd.DataFrame) -> Dict[str, Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Fit all traditional + boosted models and return their metrics.\n",
        "        \"\"\"\n",
        "        print(\"Fitting traditional & boosted ML models with Bayesian optimization...\")\n",
        "\n",
        "        # Feature prep\n",
        "        X_distance, X_combined, kicker_ids, kicker_encoder = self.prepare_features(data)\n",
        "        y = data[\"success\"].values.astype(np.int_)\n",
        "\n",
        "        # Time-based split\n",
        "        train_idx, test_idx = self.create_time_split(data)\n",
        "        X_dist_train, X_dist_test = X_distance[train_idx], X_distance[test_idx]\n",
        "        X_comb_train, X_comb_test = X_combined[train_idx], X_combined[test_idx]\n",
        "        kicker_train, kicker_test = kicker_ids[train_idx], kicker_ids[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # 1. Simple Logistic with Optuna\n",
        "        print(\"  â–¸ simple logistic + Optuna\")\n",
        "        simple_lr = self._tune_simple_logistic_optuna(X_dist_train, y_train)\n",
        "        self.fitted_models[\"simple_logistic\"] = simple_lr\n",
        "        y_pred = simple_lr.predict_proba(X_dist_test)[:, 1].astype(np.float_)\n",
        "        results[\"Simple Logistic\"] = self.evaluator.calculate_classification_metrics(y_test, y_pred)\n",
        "\n",
        "        # 2. Ridge Logistic with Optuna\n",
        "        print(\"  â–¸ ridge logistic + Optuna\")\n",
        "        ridge_lr = self._tune_ridge_logistic_optuna(X_comb_train, y_train)\n",
        "        self.fitted_models[\"ridge_logistic\"] = ridge_lr\n",
        "        y_pred = ridge_lr.predict_proba(X_comb_test)[:, 1].astype(np.float_)\n",
        "        results[\"Ridge Logistic\"] = self.evaluator.calculate_classification_metrics(y_test, y_pred)\n",
        "\n",
        "        # 3. Random Forest with Optuna\n",
        "        print(\"  â–¸ random forest + Optuna\")\n",
        "        X_rf_train = np.column_stack([X_dist_train, kicker_train]).astype(np.float_)\n",
        "        X_rf_test = np.column_stack([X_dist_test, kicker_test]).astype(np.float_)\n",
        "        rf_model = self._tune_random_forest_optuna(X_rf_train, y_train)\n",
        "        self.fitted_models[\"random_forest\"] = rf_model\n",
        "        y_pred = rf_model.predict_proba(X_rf_test)[:, 1].astype(np.float_)\n",
        "        results[\"Random Forest\"] = self.evaluator.calculate_classification_metrics(y_test, y_pred)\n",
        "\n",
        "        # 4. XGBoost with Optuna\n",
        "        print(\"  â–¸ xgboost + Optuna\")\n",
        "        xgb_model = self._tune_xgboost_optuna(X_rf_train, y_train)\n",
        "        self.fitted_models[\"xgboost\"] = xgb_model\n",
        "        y_pred = xgb_model.predict_proba(X_rf_test)[:, 1].astype(np.float_)\n",
        "        results[\"XGBoost\"] = self.evaluator.calculate_classification_metrics(y_test, y_pred)\n",
        "\n",
        "        # 5. CatBoost with Optuna  â†-- NEW implementation\n",
        "        print(\"  â–¸ catboost + Optuna\")\n",
        "        df_cat_train = pd.DataFrame({\n",
        "            \"attempt_yards\": X_dist_train.ravel().astype(np.float32),\n",
        "            \"kicker_id\":     kicker_train.ravel().astype(\"int32\"),\n",
        "        })\n",
        "        df_cat_test = pd.DataFrame({\n",
        "            \"attempt_yards\": X_dist_test.ravel().astype(np.float32),\n",
        "            \"kicker_id\":     kicker_test.ravel().astype(\"int32\"),\n",
        "        })\n",
        "\n",
        "        cat_model = self._tune_catboost_optuna(df_cat_train, y_train)\n",
        "        self.fitted_models[\"catboost\"] = cat_model\n",
        "        y_pred = cat_model.predict_proba(df_cat_test)[:, 1].astype(np.float_)\n",
        "        results[\"CatBoost\"] = self.evaluator.calculate_classification_metrics(y_test, y_pred)\n",
        "\n",
        "        print(\"***** all models fitted & scored *****\")\n",
        "        return results\n",
        "\n",
        "    def predict(self, model_name: str, data: pd.DataFrame) -> NDArray[np.float_]:\n",
        "        \"\"\"\n",
        "        Predict probabilities with any fitted model in the suite.\n",
        "        \"\"\"\n",
        "        if model_name not in self.fitted_models:\n",
        "            raise ValueError(f\"Model {model_name} not fitted\")\n",
        "\n",
        "        model = self.fitted_models[model_name]\n",
        "\n",
        "        if model_name == \"simple_logistic\":\n",
        "            X = data[\"attempt_yards\"].values.astype(np.float_).reshape(-1, 1)\n",
        "        elif model_name in {\"ridge_logistic\"}:\n",
        "            # Distance + one-hot kicker â€“ need encoder state (TODO: save encoder)\n",
        "            raise NotImplementedError(\"Pass encoded matrix for ridge predictions\")\n",
        "        elif model_name in {\"random_forest\", \"xgboost\"}:\n",
        "            X = np.column_stack([\n",
        "                data[\"attempt_yards\"].values.astype(np.float_),\n",
        "                data[\"kicker_id\"].values.astype(np.float_)  # Convert to float for tree models\n",
        "            ])\n",
        "        elif model_name == \"catboost\":\n",
        "            X = pd.DataFrame({\n",
        "                \"attempt_yards\": data[\"attempt_yards\"].values.astype(np.float32),\n",
        "                \"kicker_id\": data[\"kicker_id\"].values.astype(\"int32\"),\n",
        "            })\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "        return model.predict_proba(X)[:, 1].astype(np.float_)\n",
        "\n",
        "    def get_feature_importance(self, model_name: str) -> Optional[NDArray[np.float_]]:\n",
        "        \"\"\"\n",
        "        Get feature importance for tree-based models.\n",
        "        \"\"\"\n",
        "        if model_name not in self.fitted_models:\n",
        "            return None\n",
        "\n",
        "        model = self.fitted_models[model_name]\n",
        "\n",
        "        if model_name in {\"catboost\"}:\n",
        "            return model.get_feature_importance().astype(np.float_)\n",
        "        elif hasattr(model, \"feature_importances_\"):\n",
        "            return model.feature_importances_.astype(np.float_)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from src.nfl_kicker_analysis.data.loader import DataLoader\n",
        "    from src.nfl_kicker_analysis.data.feature_selection import (\n",
        "        DynamicSchema,\n",
        "        filter_to_final_features,\n",
        "        update_schema_numerical,\n",
        "    )\n",
        "    from src.nfl_kicker_analysis.data.preprocessor import DataPreprocessor\n",
        "    from src.nfl_kicker_analysis.data.feature_engineering import FeatureEngineer\n",
        "\n",
        "    # â”€â”€â”€ 1 Load raw data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    loader = DataLoader()\n",
        "    df_raw = loader.load_complete_dataset()\n",
        "\n",
        "    # â”€â”€â”€ 2 Feature engineering pass â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    engineer = FeatureEngineer()\n",
        "    df_feat = engineer.create_all_features(df_raw)\n",
        "\n",
        "    for category, details in engineer.get_available_features(df_feat).items():\n",
        "        print(f\"-- {category} --\")\n",
        "        for feat, uniques in details.items():\n",
        "            print(f\"   {feat}: {len(uniques)} unique | sample {uniques[:5] if uniques else '...'}\")\n",
        "\n",
        "    # â”€â”€â”€ 3 Define all tunables in one place â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    CONFIG = {\n",
        "        'min_distance': 20,\n",
        "        'max_distance': 60,\n",
        "        'min_kicker_attempts': 8,\n",
        "        'season_types': ['Reg', 'Post'],  # now include playoffs\n",
        "        'include_performance_history': True,\n",
        "        'include_statistical_features': False,\n",
        "        'include_player_status': True,  # âœ… FIX: Added missing parameter\n",
        "        'performance_window': 12,\n",
        "    }\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # ðŸ”§ Single source of truth for column roles â€“ edit freely\n",
        "    # ------------------------------------------------------------------\n",
        "    FEATURE_LISTS = {\n",
        "        \"numerical\": [\n",
        "            \"attempt_yards\", \"age_at_attempt\", \"distance_squared\",\n",
        "            \"career_length_years\", \"season_progress\", \"rolling_success_rate\",\n",
        "            \"current_streak\", \"distance_zscore\", \"distance_percentile\",\n",
        "        ],\n",
        "        \"ordinal\":  [\"season\", \"week\", \"month\", \"day_of_year\"],\n",
        "        \"nominal\":  [\n",
        "            \"kicker_id\", \"is_long_attempt\", \"is_very_long_attempt\",\n",
        "            \"is_rookie_attempt\", \"distance_category\", \"experience_category\",\n",
        "        ],\n",
        "        \"y_variable\": [\"success\"],\n",
        "    }\n",
        "\n",
        "    # âžŠ  Build schema from the dict\n",
        "    schema = DynamicSchema(FEATURE_LISTS)\n",
        "\n",
        "    # read final_features.txt\n",
        "    with open(\"data/models/features/final_features.txt\", \"r\") as f:\n",
        "        final_features = [line.strip() for line in f]\n",
        "    print(f\"---------------final_features---------------\")\n",
        "    print(final_features)\n",
        "    numeric_final = [f for f in final_features if f in schema.numerical]\n",
        "\n",
        "    print(f\"\\nâœ¨ Final feature count: {len(numeric_final)}\")\n",
        "    print(\"Selected features:\")\n",
        "    for feat in numeric_final:\n",
        "        print(f\"  â€¢ {feat}\")\n",
        "\n",
        "    # ðŸ”„ Push into schema so every later stage sees the new list\n",
        "    update_schema_numerical(schema, numeric_final)\n",
        "\n",
        "    # output final_features from schema\n",
        "    FEATURE_LISTS = schema.lists\n",
        "    print(f\"---------------FEATURE_LISTS---------------\")\n",
        "    print(FEATURE_LISTS)\n",
        "\n",
        "    pre = DataPreprocessor()\n",
        "    pre.update_config(**CONFIG)\n",
        "    pre.update_feature_lists(**FEATURE_LISTS)\n",
        "    _ = pre.preprocess_complete(df_feat)\n",
        "    X, y = pre.fit_transform_features()\n",
        "\n",
        "    print(\"First 5 rows after inverseâ€‘transform roundâ€‘trip â†’\")\n",
        "    print(pre.invert_preprocessing(X[:5]).head())\n",
        "\n",
        "    # â”€â”€â”€ 4  Fit traditional models on real data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(\"Testing Traditional Modelsâ€¦\")\n",
        "    model_suite = TreeBasedModelSuite()\n",
        "\n",
        "    try:\n",
        "        results = model_suite.fit_all_models(pre.processed_data)\n",
        "        print(\"\\n***** Metrics *****\")\n",
        "        for model, metric_dict in results.items():\n",
        "            print(f\"{model}:\")\n",
        "            for k, v in metric_dict.items():\n",
        "                print(f\"   {k:>12}: {v:.4f}\")\n",
        "        print(\"******* Traditional models tests passed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"------------- Error testing traditional models: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "invalid truth value '' for environment 'JAX_ENABLE_X64'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 802\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnfl_kicker_analysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_engineering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FeatureEngineer\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnfl_kicker_analysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataPreprocessor\n\u001b[0;32m--> 802\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnfl_kicker_analysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayesian\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BayesianModelSuite\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01marviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maz\u001b[39;00m\n",
            "File \u001b[0;32m/workspace/src/nfl_kicker_analysis/models/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Models module for NFL kicker analysis.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_based_bayes_optimized_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TreeBasedModelSuite\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayesian_timeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesBayesianModelSuite\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTreeBasedModelSuite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeSeriesBayesianModelSuite\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m/workspace/src/nfl_kicker_analysis/models/bayesian_timeseries.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01marviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maz\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m  \u001b[38;5;66;03m# keep for device detection\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpyro\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Silence ArviZ HDI FutureWarnings\u001b[39;00m\n",
            "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/jax/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version_info__ \u001b[38;5;28;01mas\u001b[39;00m __version_info__\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Set Cloud TPU env vars if necessary before transitively loading C++ backend\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud_tpu_init\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cloud_tpu_init \u001b[38;5;28;01mas\u001b[39;00m _cloud_tpu_init\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m   _cloud_tpu_init()\n",
            "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/jax/_src/cloud_tpu_init.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hardware_utils\n\u001b[1;32m     23\u001b[0m running_in_cloud_tpu_vm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/jax/_src/config.py:1366\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_x64_thread_local\u001b[39m(val):\n\u001b[1;32m   1364\u001b[0m   jax_jit\u001b[38;5;241m.\u001b[39mthread_local_state()\u001b[38;5;241m.\u001b[39menable_x64 \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m-> 1366\u001b[0m enable_x64 \u001b[38;5;241m=\u001b[39m \u001b[43mbool_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjax_enable_x64\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhelp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnable 64-bit types to be used\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_global_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_update_x64_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_thread_local_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_update_x64_thread_local\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;66;03m# TODO(phawkins): remove after fixing users of FLAGS.x64_enabled.\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m config\u001b[38;5;241m.\u001b[39m_contextmanager_flags\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjax_enable_x64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/jax/_src/config.py:432\u001b[0m, in \u001b[0;36mbool_state\u001b[0;34m(name, default, help, update_global_hook, update_thread_local_hook, upgrade, extra_description, include_in_jit_key)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(default, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    430\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault value must be of type bool, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefault\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(default),\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mtype\u001b[39m(default))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 432\u001b[0m default \u001b[38;5;241m=\u001b[39m \u001b[43mbool_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m upgrade:\n",
            "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/jax/_src/config.py:80\u001b[0m, in \u001b[0;36mbool_env\u001b[0;34m(varname, default)\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid truth value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for environment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvarname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: invalid truth value '' for environment 'JAX_ENABLE_X64'"
          ]
        }
      ],
      "source": [
        "# %%writefile src/nfl_kicker_analysis/models/bayesian.py\n",
        "\"\"\"\n",
        "Bayesian models for NFL kicker analysis.\n",
        "Provides hierarchical Bayesian logistic regression and evaluation utilities using PyMC.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "import matplotlib.pyplot as plt        # NEW â€“ for PPC plot\n",
        "from scipy import stats                # NEW â€“ ECDF sampling for EPA\n",
        "from typing import Dict, Any, TYPE_CHECKING\n",
        "\n",
        "from src.nfl_kicker_analysis.utils.metrics import ModelEvaluator\n",
        "from src.nfl_kicker_analysis.config import FEATURE_LISTS, config\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from src.nfl_kicker_analysis.data.preprocessor import DataPreprocessor\n",
        "\n",
        "__all__ = [\n",
        "    \"BayesianModelSuite\",\n",
        "]\n",
        "\n",
        "\n",
        "class BayesianModelSuite:\n",
        "    \"\"\"Hierarchical Bayesian logisticâ€‘regression models for kicker analysis.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        draws: int = 1_000,\n",
        "        tune: int = 1_000,\n",
        "        target_accept: float = 0.95,  # Increased from 0.9 to reduce divergences\n",
        "        include_random_slope: bool = False,\n",
        "        random_seed: int | None = 42,\n",
        "    ) -> None:\n",
        "        self.draws = draws\n",
        "        self.tune = tune\n",
        "        self.target_accept = target_accept\n",
        "        self.include_random_slope = include_random_slope\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        # Model components - set during fit()\n",
        "        self._model = None\n",
        "        self._trace = None\n",
        "        self._kicker_map = {}\n",
        "        self._distance_mu = 0.0\n",
        "        self._distance_sigma = 1.0\n",
        "        self.baseline_probs = {}  # For consistent EPA baselines with EPACalculator\n",
        "        self.evaluator = ModelEvaluator()\n",
        "\n",
        "    def _bootstrap_distances(\n",
        "        self,\n",
        "        distances: np.ndarray,\n",
        "        n_samples: int,\n",
        "        rng: np.random.Generator,\n",
        "        weights: np.ndarray | None = None\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Bootstrap helper using `np.random.Generator.choice`.\n",
        "\n",
        "        Simple, testable wrapper for bootstrap resampling of field-goal distances.\n",
        "        Keeps all distance logic in one place and follows NumPy best practices.\n",
        "        \"\"\"\n",
        "        if distances.size == 0:\n",
        "            raise ValueError(\"No distances available for bootstrap.\")\n",
        "        return rng.choice(distances, size=n_samples, replace=True, p=weights)\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # ðŸ› ï¸  Helper utilities\n",
        "    # ---------------------------------------------------------------------\n",
        "    def _standardize(self, x: np.ndarray, *, fit: bool = False) -> np.ndarray:\n",
        "        if fit:\n",
        "            self._distance_mu = float(x.mean())\n",
        "            self._distance_sigma = float(x.std())\n",
        "        return (x - self._distance_mu) / self._distance_sigma\n",
        "\n",
        "    def _encode_kicker(self, raw_ids: np.ndarray, *, fit: bool = False,\n",
        "                       unknown_action: str = \"average\") -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Map raw kicker IDs â†’ compact indices (kicker_idx).\n",
        "        \"\"\"\n",
        "        if fit:\n",
        "            self._kicker_map = {pid: i for i, pid in enumerate(np.unique(raw_ids))}\n",
        "        idx = np.array([self._kicker_map.get(pid, -1) for pid in raw_ids], int)\n",
        "\n",
        "        if (idx == -1).any():\n",
        "            n_unseen = (idx == -1).sum()\n",
        "            msg = f\"{n_unseen} unseen kicker IDs â€“ mapped to league mean.\"\n",
        "            if unknown_action == \"raise\":\n",
        "                raise ValueError(msg)\n",
        "            elif unknown_action == \"warn\":\n",
        "                print(\"âš ï¸ \", msg)\n",
        "\n",
        "        return idx\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # ðŸ”¨  Model construction\n",
        "    # ---------------------------------------------------------------------\n",
        "    def _build_model(\n",
        "        self,\n",
        "        distance_std: np.ndarray,\n",
        "        age_c: np.ndarray,           # <-- NEW: centered age\n",
        "        age_c2: np.ndarray,          # <-- NEW: quadratic age\n",
        "        exp_std: np.ndarray,\n",
        "        success: np.ndarray,\n",
        "        kicker_idx: np.ndarray,\n",
        "        n_kickers: int,\n",
        "    ) -> pm.Model:\n",
        "        with pm.Model() as model:\n",
        "            # Population-level effects\n",
        "            alpha = pm.Normal(\"alpha\", 1.5, 1.0)\n",
        "            beta_dist = pm.Normal(\"beta_dist\", -1.5, 0.8)\n",
        "\n",
        "            # Age effects (linear + quadratic)\n",
        "            beta_age  = pm.Normal(\"beta_age\",  0.0, 0.5)\n",
        "            beta_age2 = pm.Normal(\"beta_age2\", 0.0, 0.5)\n",
        "            beta_exp  = pm.Normal(\"beta_exp\",  0.0, 0.5)\n",
        "\n",
        "            # Per-kicker random intercepts (non-centered)\n",
        "            Ïƒ_u   = pm.HalfNormal(\"sigma_u\", 0.8)\n",
        "            u_raw = pm.Normal(\"u_raw\", 0.0, 1.0, shape=n_kickers)\n",
        "            u     = pm.Deterministic(\"u\", Ïƒ_u * u_raw)\n",
        "\n",
        "            # Per-kicker random aging slopes (optional enhancement)\n",
        "            if self.include_random_slope:\n",
        "                Ïƒ_age = pm.HalfNormal(\"sigma_age\", 0.5)\n",
        "                a_raw = pm.Normal(\"a_raw\", 0.0, 1.0, shape=n_kickers)\n",
        "                a_k   = pm.Deterministic(\"a_k\", Ïƒ_age * a_raw)\n",
        "                age_slope_effect = a_k[kicker_idx] * age_c\n",
        "            else:\n",
        "                age_slope_effect = 0.0\n",
        "\n",
        "            # Linear predictor\n",
        "            lin_pred = (\n",
        "                alpha\n",
        "                + (beta_dist * distance_std)\n",
        "                + (beta_age * age_c) + age_slope_effect\n",
        "                + (beta_age2 * age_c2)\n",
        "                + (beta_exp * exp_std)\n",
        "                + u[kicker_idx]\n",
        "            )\n",
        "\n",
        "            Î¸ = pm.Deterministic(\"theta\", pm.invlogit(lin_pred))\n",
        "            pm.Bernoulli(\"obs\", p=Î¸, observed=success)\n",
        "        return model\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # ðŸ“ˆ  Public API\n",
        "    # ---------------------------------------------------------------------\n",
        "    def fit(self, df, *, preprocessor=None):\n",
        "        # ------------------------------------------------------------------\n",
        "        # 0ï¸âƒ£  Exactly one preprocessing pass\n",
        "        if df.attrs.get(\"engineered\", False):\n",
        "            processed = df.copy()\n",
        "        elif preprocessor is not None:\n",
        "            processed = preprocessor.preprocess_slice(df)\n",
        "        else:\n",
        "            # ðŸŽ¯ AUTO-CREATE BAYESIAN-MINIMAL PREPROCESSOR\n",
        "            from src.nfl_kicker_analysis.data.preprocessor import DataPreprocessor\n",
        "            from src.nfl_kicker_analysis import config\n",
        "\n",
        "            bayes_preprocessor = DataPreprocessor()\n",
        "            bayes_preprocessor.bayes_minimal = True  # Enable minimal preprocessing\n",
        "            bayes_preprocessor.update_config(\n",
        "                min_distance=20, max_distance=60,\n",
        "                min_kicker_attempts=5,\n",
        "                season_types=['Reg', 'Post'],\n",
        "                include_performance_history=False,  # Not needed for Bayesian\n",
        "                include_statistical_features=False,  # Avoid complex features\n",
        "                include_player_status=True,  # Enable player status features\n",
        "                performance_window=12\n",
        "            )\n",
        "            processed = bayes_preprocessor.preprocess_slice(df)\n",
        "        # ------------------------------------------------------------------\n",
        "        # 1ï¸âƒ£  Predictors\n",
        "        dist_std = self._standardize(processed[\"attempt_yards\"].to_numpy(float), fit=True)\n",
        "\n",
        "        # Age variables (centered & scaled)\n",
        "        age_c  = processed[\"age_c\"].to_numpy(float) if \"age_c\" in processed.columns else np.zeros(len(processed), dtype=float)\n",
        "        age_c2 = processed[\"age_c2\"].to_numpy(float) if \"age_c2\" in processed.columns else np.zeros(len(processed), dtype=float)\n",
        "\n",
        "        # Handle experience standardization\n",
        "        if \"exp_100\" in processed.columns:\n",
        "            exp_std = (\n",
        "                (processed[\"exp_100\"] - processed[\"exp_100\"].mean()) /\n",
        "                processed[\"exp_100\"].std()\n",
        "            ).to_numpy(float)\n",
        "        else:\n",
        "            exp_std = np.zeros(len(processed), dtype=float)\n",
        "\n",
        "        success    = processed[\"success\"].to_numpy(int)\n",
        "        kicker_idx = self._encode_kicker(processed[\"kicker_id\"].to_numpy(int), fit=True)\n",
        "        n_kickers  = len(self._kicker_map)\n",
        "\n",
        "        # ---- model & sampling -------------------------------------------\n",
        "        self._model = self._build_model(\n",
        "            dist_std, age_c, age_c2, exp_std, success, kicker_idx, n_kickers\n",
        "        )\n",
        "\n",
        "        # â”€â”€ FIX: ensure pm.sample knows which model to use â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        with self._model:\n",
        "            self._trace = pm.sample(\n",
        "                draws=self.draws, tune=self.tune,\n",
        "                chains=4, target_accept=self.target_accept,\n",
        "                random_seed=self.random_seed,\n",
        "                return_inferencedata=True\n",
        "            )\n",
        "\n",
        "    def predict(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        *,\n",
        "        return_ci: bool = False,\n",
        "        preprocessor=None\n",
        "    ):\n",
        "        if self._trace is None or self._model is None:\n",
        "            raise RuntimeError(\"Model not yet fitted.\")\n",
        "\n",
        "        # -- preprocessing --------------------------------------------------\n",
        "        if preprocessor is not None:\n",
        "            df = preprocessor.preprocess_slice(df)\n",
        "\n",
        "        dist_std = (\n",
        "            df[\"distance_zscore\"].to_numpy(float)\n",
        "            if \"distance_zscore\" in df.columns\n",
        "            else self._standardize(df[\"attempt_yards\"].to_numpy(float), fit=False)\n",
        "        )\n",
        "        kid_idx = self._encode_kicker(df[\"kicker_id\"].to_numpy(int),\n",
        "                                    fit=False, unknown_action=\"average\")\n",
        "\n",
        "        # -- posterior samples (non-centered model) ---------------------\n",
        "        a = self._trace.posterior[\"alpha\"].values.flatten()\n",
        "        b = self._trace.posterior[\"beta_dist\"].values.flatten()\n",
        "        u = self._trace.posterior[\"u\"].values.reshape(a.size, -1)  # use u not u_raw\n",
        "\n",
        "        # Age and experience effects (if available)\n",
        "        age_effect = 0.0\n",
        "        if \"age_c\" in df.columns:\n",
        "            age_c = df[\"age_c\"].to_numpy(float)\n",
        "            age_c2 = df[\"age_c2\"].to_numpy(float) if \"age_c2\" in df.columns else np.zeros_like(age_c)\n",
        "\n",
        "            beta_age = self._trace.posterior[\"beta_age\"].values.flatten()\n",
        "            beta_age2 = self._trace.posterior[\"beta_age2\"].values.flatten()\n",
        "\n",
        "            age_effect = (beta_age[:, None] * age_c +\n",
        "                         beta_age2[:, None] * age_c2)\n",
        "\n",
        "            # Add random age slopes if available\n",
        "            if \"a_k\" in self._trace.posterior:\n",
        "                a_k = self._trace.posterior[\"a_k\"].values.reshape(a.size, -1)\n",
        "                a_k = np.pad(a_k, ((0, 0), (0, 1)), constant_values=0.0)\n",
        "                idx_age = np.where(kid_idx == -1, a_k.shape[1] - 1, kid_idx)\n",
        "                age_effect += a_k[:, idx_age] * age_c\n",
        "\n",
        "        exp_effect = 0.0\n",
        "        if \"exp_100\" in df.columns:\n",
        "            exp_std = ((df[\"exp_100\"] - df[\"exp_100\"].mean()) / df[\"exp_100\"].std()).to_numpy(float)\n",
        "            beta_exp = self._trace.posterior[\"beta_exp\"].values.flatten()\n",
        "            exp_effect = beta_exp[:, None] * exp_std\n",
        "\n",
        "        # Pad league-mean column for unseen kickers\n",
        "        u = np.pad(u, ((0, 0), (0, 1)), constant_values=0.0)\n",
        "        idx = np.where(kid_idx == -1, u.shape[1] - 1, kid_idx)\n",
        "\n",
        "        lin = (a[:, None] + b[:, None] * dist_std +\n",
        "               age_effect + exp_effect + u[:, idx])\n",
        "        theta = 1 / (1 + np.exp(-lin))\n",
        "        mean = theta.mean(axis=0)\n",
        "\n",
        "        if not return_ci:\n",
        "            return mean\n",
        "\n",
        "        lower, upper = np.percentile(theta, [2.5, 97.5], axis=0)\n",
        "        return mean, lower, upper\n",
        "\n",
        "\n",
        "    def evaluate(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        *,\n",
        "        preprocessor=None\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"Compute AUC, Brier score & logâ€‘loss on provided data.\n",
        "\n",
        "        Args:\n",
        "            df: Data to evaluate on\n",
        "            preprocessor: Optional DataPreprocessor instance. If provided, will\n",
        "                         use it to preprocess the data before evaluation.\n",
        "        \"\"\"\n",
        "        # Apply preprocessing if provided\n",
        "        if preprocessor is not None:\n",
        "            df = preprocessor.preprocess_slice(df)\n",
        "\n",
        "        y_true = df[\"success\"].to_numpy(dtype=int)\n",
        "        y_pred_result = self.predict(df)  # predict() will handle its own preprocessing if needed\n",
        "\n",
        "        # Handle both single prediction and CI tuple returns\n",
        "        if isinstance(y_pred_result, tuple):\n",
        "            y_pred = y_pred_result[0]  # Just use mean predictions for evaluation\n",
        "        else:\n",
        "            y_pred = y_pred_result\n",
        "\n",
        "        return self.evaluator.calculate_classification_metrics(y_true, y_pred)\n",
        "\n",
        "\n",
        "    def diagnostics(self, *, return_scalars: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Compute and return MCMC diagnostics.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        return_scalars : bool, default False\n",
        "            If True, also include convenience keys\n",
        "            ``rhat_max`` and ``ess_min`` for quick threshold checks.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            Keys: rhat, ess (xarray.Dataset), rhat_vals, ess_vals (np.ndarray),\n",
        "            summary_ok (bool), and optionally rhat_max, ess_min (float).\n",
        "        \"\"\"\n",
        "        if self._trace is None:\n",
        "            raise RuntimeError(\"Model not yet fitted.\")\n",
        "\n",
        "        # ArviZ calls (collapse chain/draw)\n",
        "        rhats = az.rhat(self._trace)\n",
        "        ess   = az.ess(self._trace)\n",
        "\n",
        "        # Flatten â†’ numpy for easy thresholding\n",
        "        rhat_vals = rhats.to_array().values.ravel()\n",
        "        ess_vals  = ess.to_array().values.ravel()\n",
        "\n",
        "        summary_ok = (rhat_vals <= 1.01).all() and (ess_vals >= 100).all()\n",
        "        if not summary_ok:\n",
        "            print(\"âš ï¸  Sampling diagnostics outside recommended thresholds.\")\n",
        "\n",
        "        out = {\n",
        "            \"rhat\": rhats,\n",
        "            \"ess\": ess,\n",
        "            \"rhat_vals\": rhat_vals,\n",
        "            \"ess_vals\": ess_vals,\n",
        "            \"summary_ok\": summary_ok,\n",
        "        }\n",
        "        if return_scalars:\n",
        "            out[\"rhat_max\"] = rhat_vals.max()\n",
        "            out[\"ess_min\"] = ess_vals.min()\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # -----------------------------------------------------------------\n",
        "    # ðŸŒŸ  NEW 1: kicker-level credible interval\n",
        "    # -----------------------------------------------------------------\n",
        "    def kicker_interval(\n",
        "        self,\n",
        "        kicker_id: int,\n",
        "        distance: float | None = None,\n",
        "        ci: float = 0.95,\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Return mean, lower, upper success probability for a *single* kicker.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "        kicker_id : raw ID as in dataframe\n",
        "        distance  : yards; if None, uses the empirical mean distance of\n",
        "                    training data, transformed with stored Î¼/Ïƒ.\n",
        "        ci        : central credible-interval mass (default 0.95)\n",
        "        \"\"\"\n",
        "        if self._trace is None:\n",
        "            raise RuntimeError(\"Model must be fitted first\")\n",
        "\n",
        "        # 1 â†’ index or league-mean column\n",
        "        k_idx = self._kicker_map.get(kicker_id, -1)\n",
        "        pad_col = len(self._kicker_map)   # after pad in predict()\n",
        "\n",
        "        # 2 â†’ choose distance\n",
        "        if distance is None:\n",
        "            distance_std = 0.0            # z-score of mean is 0\n",
        "        else:\n",
        "            distance_std = (distance - self._distance_mu) / self._distance_sigma\n",
        "\n",
        "        a = self._trace.posterior[\"alpha\"].values.flatten()\n",
        "\n",
        "        # Robust lookup for the distance slope parameter (handles naming changes)\n",
        "        slope_name = \"beta_dist\" if \"beta_dist\" in self._trace.posterior else \"beta\"\n",
        "        b = self._trace.posterior[slope_name].values.flatten()\n",
        "\n",
        "        u = self._trace.posterior[\"u\"].values.reshape(a.size, -1)\n",
        "\n",
        "        # pad league-mean\n",
        "        u = np.pad(u, ((0, 0), (0, 1)), constant_values=0.0)\n",
        "        idx = pad_col if k_idx == -1 else k_idx\n",
        "\n",
        "        logit_p = a + b * distance_std + u[:, idx]\n",
        "        p = 1 / (1 + np.exp(-logit_p))\n",
        "\n",
        "        lower, upper = np.quantile(p, [(1-ci)/2, 1-(1-ci)/2])\n",
        "        return {\"mean\": p.mean(), \"lower\": lower, \"upper\": upper,\n",
        "                \"n_draws\": p.size, \"distance_std\": distance_std}\n",
        "\n",
        "    # -----------------------------------------------------------------\n",
        "    # ðŸŒŸ  NEW 2: posterior-predictive plot across 5-yd bins\n",
        "    # -----------------------------------------------------------------\n",
        "    def plot_distance_ppc(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        *,\n",
        "        bin_width: int = 5,\n",
        "        preprocessor = None,\n",
        "        ax = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Bin attempts by distance and overlay actual vs posterior mean make-rate.\n",
        "        \"\"\"\n",
        "        if preprocessor is not None:\n",
        "            df = preprocessor.preprocess_slice(df)\n",
        "\n",
        "        # 1 Actual success by bin\n",
        "        df = df.copy()\n",
        "        df[\"bin\"] = (df[\"attempt_yards\"] // bin_width) * bin_width\n",
        "        actual = df.groupby(\"bin\")[\"success\"].mean()\n",
        "\n",
        "        # 2 Posterior mean per attempt â†’ group\n",
        "        preds = self.predict(df)\n",
        "        df[\"pred\"] = preds\n",
        "        posterior = df.groupby(\"bin\")[\"pred\"].mean()\n",
        "\n",
        "        # 3 Plot\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots(figsize=(8, 4))\n",
        "        ax.plot(actual.index, actual.values, marker=\"o\",\n",
        "                label=\"Actual\", linewidth=2)\n",
        "        ax.plot(posterior.index, posterior.values, marker=\"s\",\n",
        "                label=\"Posterior mean\", linestyle=\"--\")\n",
        "        ax.set_xlabel(\"Distance bin (yards)\")\n",
        "        ax.set_ylabel(\"FG make probability\")\n",
        "        ax.set_title(\"Posterior-Predictive Check ({}-yd bins)\".format(bin_width))\n",
        "        ax.legend()\n",
        "        plt.tight_layout()\n",
        "        return ax\n",
        "\n",
        "    # -----------------------------------------------------------------\n",
        "    # ðŸŒŸ  NEW 3: age-binned posterior-predictive check\n",
        "    # -----------------------------------------------------------------\n",
        "    def plot_age_ppc(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        *,\n",
        "        bin_width: float = 2.0,\n",
        "        preprocessor = None,\n",
        "        ax = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Bin attempts by age and overlay actual vs posterior mean make-rate.\n",
        "        \"\"\"\n",
        "        if preprocessor is not None:\n",
        "            df = preprocessor.preprocess_slice(df)\n",
        "\n",
        "        # Use raw age for binning (more interpretable)\n",
        "        age_col = \"age_at_attempt\" if \"age_at_attempt\" in df.columns else \"age_c\"\n",
        "        df = df.copy()\n",
        "\n",
        "        if age_col == \"age_c\":\n",
        "            # Convert back to raw age for binning\n",
        "            df[\"age_bin\"] = ((df[\"age_c\"] * 10 + 30) // bin_width) * bin_width\n",
        "        else:\n",
        "            df[\"age_bin\"] = (df[age_col] // bin_width) * bin_width\n",
        "\n",
        "        # Actual success by age bin\n",
        "        actual = df.groupby(\"age_bin\")[\"success\"].mean()\n",
        "\n",
        "        # Posterior mean per attempt â†’ group by age\n",
        "        preds = self.predict(df)\n",
        "        df[\"pred\"] = preds\n",
        "        posterior = df.groupby(\"age_bin\")[\"pred\"].mean()\n",
        "\n",
        "        # Plot\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots(figsize=(8, 4))\n",
        "        ax.plot(actual.index, actual.values, marker=\"o\",\n",
        "                label=\"Actual\", linewidth=2)\n",
        "        ax.plot(posterior.index, posterior.values, marker=\"s\",\n",
        "                label=\"Posterior mean\", linestyle=\"--\")\n",
        "        ax.set_xlabel(\"Age bin (years)\")\n",
        "        ax.set_ylabel(\"FG make probability\")\n",
        "        ax.set_title(\"Age-Based Posterior-Predictive Check ({:.1f}-yr bins)\".format(bin_width))\n",
        "        ax.legend()\n",
        "        plt.tight_layout()\n",
        "        return ax\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # Helper: draw-level EPA simulation  (fully replaced)\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def _epa_fg_plus_draws(\n",
        "        self,\n",
        "        league_df: pd.DataFrame,\n",
        "        *,\n",
        "        kicker_ids: np.ndarray,\n",
        "        n_samples: int,\n",
        "        rng: np.random.Generator,\n",
        "        distance_strategy: str = \"kicker\",\n",
        "        Ï„: float = 20.0,\n",
        "        compute_league_avg_only: bool = False,\n",
        "        full_league_avg: float | None = None,\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Monte-Carlo simulate expected points per attempt for every posterior\n",
        "        draw *and* every kicker in *kicker_ids*.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        distance_strategy : {\"kicker\",\"league\"}\n",
        "            â€¢ \"kicker\" (default) â”€ bootstrap distances **from the kicker's own\n",
        "              historical attempts** â€“ fairer when kick distributions differ.\n",
        "            â€¢ \"league\" â”€ previous behaviour (single shared pool).\n",
        "        Ï„ : float, default 20.0\n",
        "            Empirical-Bayes shrinkage parameter. Higher values = less shrinkage.\n",
        "        compute_league_avg_only : bool, default False\n",
        "            If True, only compute the league average without shrinkage.\n",
        "        full_league_avg : float or None, default None\n",
        "            If provided, use this as the league average for shrinkage calculation.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            Shape = (n_draws, len(kicker_ids)); each entry is the expected\n",
        "            points per attempt for one posterior draw.\n",
        "        \"\"\"\n",
        "        if self._trace is None:\n",
        "            raise RuntimeError(\"Model not yet fitted.\")\n",
        "\n",
        "        if distance_strategy not in {\"kicker\", \"league\"}:\n",
        "            raise ValueError(\"distance_strategy must be 'kicker' or 'league'\")\n",
        "\n",
        "        n_kickers = len(kicker_ids)\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 1ï¸âƒ£ choose a distance pool for each kicker\n",
        "        # ------------------------------------------------------------------\n",
        "        if distance_strategy == \"league\":\n",
        "            pool = league_df[\"attempt_yards\"].to_numpy(float)\n",
        "            distance_sets = [pool] * n_kickers\n",
        "        else:  # \"kicker\"\n",
        "            distance_sets = [\n",
        "                league_df.loc[league_df[\"kicker_id\"] == kid, \"attempt_yards\"]\n",
        "                          .to_numpy(float)\n",
        "                for kid in kicker_ids\n",
        "            ]\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 2ï¸âƒ£ build the simulated attempt frame\n",
        "        # ------------------------------------------------------------------\n",
        "        sampled_distances = []\n",
        "        sampled_kicker_ids = []\n",
        "        for kid, dists in zip(kicker_ids, distance_sets):\n",
        "            if dists.size == 0:\n",
        "                raise ValueError(f\"No distance data for kicker_id={kid}\")\n",
        "            sampled = rng.choice(dists, size=n_samples, replace=True)\n",
        "            sampled_distances.append(sampled)\n",
        "            sampled_kicker_ids.append(np.full(n_samples, kid, int))\n",
        "\n",
        "        sim = pd.DataFrame({\n",
        "            \"attempt_yards\": np.concatenate(sampled_distances),\n",
        "            \"kicker_id\":     np.concatenate(sampled_kicker_ids),\n",
        "        })\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 3ï¸âƒ£ forward pass through the posterior\n",
        "        # ------------------------------------------------------------------\n",
        "        dist_std = self._standardize(sim[\"attempt_yards\"].to_numpy(float),\n",
        "                                     fit=False)\n",
        "        kid_idx  = self._encode_kicker(sim[\"kicker_id\"].to_numpy(int),\n",
        "                                       fit=False, unknown_action=\"average\")\n",
        "\n",
        "        a = self._trace.posterior[\"alpha\"].values.flatten()\n",
        "\n",
        "        # Robust lookup for the distance slope parameter (handles naming changes)\n",
        "        slope_name = \"beta_dist\" if \"beta_dist\" in self._trace.posterior else \"beta\"\n",
        "        b = self._trace.posterior[slope_name].values.flatten()\n",
        "\n",
        "        u = self._trace.posterior[\"u\"].values.reshape(a.size, -1)\n",
        "        u = np.pad(u, ((0, 0), (0, 1)), constant_values=0.0)  # league-mean slot\n",
        "        idx = np.where(kid_idx == -1, u.shape[1] - 1, kid_idx)\n",
        "\n",
        "        lin   = a[:, None] + b[:, None] * dist_std + u[:, idx]\n",
        "        theta = 1 / (1 + np.exp(-lin))              # shape (draws , KÂ·S)\n",
        "        theta = theta.reshape(a.size, n_kickers, n_samples)\n",
        "        pts   = theta.mean(axis=-1) * 3.0                    # draws Ã— K\n",
        "\n",
        "        # ----- Empirical-Bayes shrink toward league avg --------------------\n",
        "        # Use pre-computed full league average or compute from current data\n",
        "        if full_league_avg is not None:\n",
        "            league_avg = full_league_avg                     # Use pre-computed full league average\n",
        "        else:\n",
        "            league_avg = pts.mean()                          # Fallback: compute from current data\n",
        "\n",
        "        # If only computing league average, return early\n",
        "        if compute_league_avg_only:\n",
        "            return pts  # Return raw points for league average calculation\n",
        "\n",
        "        # Get attempt counts for shrinkage calculation\n",
        "        n_i = league_df.groupby(\"kicker_id\")[\"success\"].size().reindex(kicker_ids).to_numpy(float)\n",
        "\n",
        "        # Standard Empirical Bayes shrinkage toward league average:\n",
        "        # shrunk = B * raw + (1-B) * prior, where B = n/(n+Ï„) and prior = league_avg\n",
        "        B = n_i / (n_i + Ï„)                                  # shrinkage weights (K,)\n",
        "\n",
        "        # Apply shrinkage: each kicker's points shrunk toward league average\n",
        "        shrunk_pts = (B[np.newaxis, :] * pts +               # B * raw_points\n",
        "                      (1 - B)[np.newaxis, :] * league_avg)   # (1-B) * league_avg\n",
        "\n",
        "        # Return EPA as deviation from league average\n",
        "        return shrunk_pts - league_avg                        # EPA relative to league avg\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # Public: EPA-FGâº leaderboard  (patched 2025-06-30)\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def epa_fg_plus(\n",
        "        self,\n",
        "        league_df: pd.DataFrame,\n",
        "        *,\n",
        "        n_samples: int = 1_000,\n",
        "        min_attempts: int = config.MIN_KICKER_ATTEMPTS,\n",
        "        seed: int | None = None,\n",
        "        weights: np.ndarray | None = None,\n",
        "        cred_mass: float = 0.95,\n",
        "        return_ci: bool = True,\n",
        "        distance_strategy: str = \"kicker\",\n",
        "        Ï„: float = 20.0,\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Bayesian EPA-FGâº leaderboard with minimum attempts filter.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        min_attempts : int, default config.MIN_KICKER_ATTEMPTS\n",
        "            Minimum attempts required for kicker inclusion in leaderboard\n",
        "        distance_strategy : {\"kicker\",\"league\"}\n",
        "            Sampling scheme for the synthetic attempt set:\n",
        "            â€¢ \"kicker\" (default) â”€ bootstrap distances **from the kicker's own\n",
        "              historical attempts** â€“ fairer when kick distributions differ.\n",
        "            â€¢ \"league\" â”€ previous behaviour (single shared pool).\n",
        "        Ï„ : float, default 20.0\n",
        "            Empirical-Bayes shrinkage parameter. Higher values = less shrinkage.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pandas.DataFrame\n",
        "            Kicker leaderboard with EPA-FGâº and credible intervals.\n",
        "        \"\"\"\n",
        "        # â¶ Baseline must be computed on full-league (reuse EPACalculator for consistency)\n",
        "        if not self.baseline_probs:\n",
        "            from src.nfl_kicker_analysis.utils.metrics import EPACalculator\n",
        "            epa_calc = EPACalculator()\n",
        "            self.baseline_probs = epa_calc.calculate_baseline_probs(league_df)\n",
        "\n",
        "        # â· Compute full league average FIRST (before any filtering)\n",
        "        all_kicker_ids = league_df[\"kicker_id\"].unique()\n",
        "        rng = np.random.default_rng(seed)\n",
        "\n",
        "        # Get league average from ALL kickers\n",
        "        full_league_draws = self._epa_fg_plus_draws(\n",
        "            league_df,  # FULL league data\n",
        "            kicker_ids=all_kicker_ids,\n",
        "            n_samples=n_samples,\n",
        "            rng=rng,\n",
        "            distance_strategy=distance_strategy,\n",
        "            Ï„=Ï„,\n",
        "            compute_league_avg_only=True  # New flag to only compute league avg\n",
        "        )\n",
        "        full_league_avg = full_league_draws.mean()\n",
        "\n",
        "        # â· NOW apply minimum attempts filter\n",
        "        qual_ids = (\n",
        "            league_df.groupby(\"kicker_id\")[\"success\"]\n",
        "                .size()\n",
        "                .loc[lambda s: s >= min_attempts]\n",
        "                .index\n",
        "        )\n",
        "        filtered_df = league_df[league_df[\"kicker_id\"].isin(qual_ids)].copy()\n",
        "\n",
        "        # â¸ Continue with existing logic on filtered data\n",
        "        kicker_ids = filtered_df[\"kicker_id\"].unique()\n",
        "\n",
        "        # Kicker metadata\n",
        "        meta = (\n",
        "            filtered_df.groupby(\"kicker_id\")[\"player_name\"]\n",
        "                .first()\n",
        "                .to_frame()\n",
        "        )\n",
        "\n",
        "        # Monte Carlo simulation with pre-computed league average\n",
        "        draws = self._epa_fg_plus_draws(\n",
        "            filtered_df,  # Use filtered data for draws\n",
        "            kicker_ids=kicker_ids,\n",
        "            n_samples=n_samples,\n",
        "            rng=rng,\n",
        "            distance_strategy=distance_strategy,\n",
        "            Ï„=Ï„,\n",
        "            full_league_avg=full_league_avg  # Pass the pre-computed league average\n",
        "        )\n",
        "        assert draws.shape[1] == len(kicker_ids), \"shape mismatch in posterior draws\"\n",
        "\n",
        "        # draws now contain EPA values directly (already relative to league average)\n",
        "        epa_draws    = draws.T       # transpose to get (kickers, draws)\n",
        "        mean_pts     = draws.mean(axis=0)  # keep for compatibility\n",
        "\n",
        "        if not return_ci:\n",
        "            out = pd.DataFrame({\n",
        "                \"epa_fg_plus_mean\": epa_draws.mean(axis=1),\n",
        "            }, index=kicker_ids)\n",
        "            return out.join(meta).sort_values(\"epa_fg_plus_mean\", ascending=False)\n",
        "\n",
        "        hdi = az.hdi(epa_draws.T, hdi_prob=cred_mass)        #  (K,2)\n",
        "        width = hdi[:, 1] - hdi[:, 0]\n",
        "        q33, q66 = np.quantile(width, [0.33, 0.66])\n",
        "        certainty = np.where(width < q33, \"high\",\n",
        "                     np.where(width < q66, \"medium\", \"low\"))\n",
        "\n",
        "        tbl = pd.DataFrame({\n",
        "            \"epa_fg_plus_mean\": epa_draws.mean(axis=1),\n",
        "            \"hdi_lower\": hdi[:, 0],\n",
        "            \"hdi_upper\": hdi[:, 1],\n",
        "            \"certainty_level\": certainty,\n",
        "            \"expected_pts_per_att\": mean_pts,\n",
        "        }, index=kicker_ids)\n",
        "\n",
        "        return (\n",
        "            tbl.join(meta)                      # add player_name\n",
        "               .sort_values(\"epa_fg_plus_mean\", ascending=False)\n",
        "        )\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # ðŸ”  Helper methods for kicker ID/name conversion\n",
        "    # ---------------------------------------------------------------------\n",
        "    def get_kicker_id_by_name(self, df: pd.DataFrame, player_name: str) -> int | None:\n",
        "        \"\"\"\n",
        "        Get kicker_id for a given player_name from the dataset.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing kicker_id and player_name columns\n",
        "            player_name: Name of the kicker to look up\n",
        "\n",
        "        Returns:\n",
        "            kicker_id if found, None otherwise\n",
        "        \"\"\"\n",
        "        matches = df[df[\"player_name\"] == player_name][\"kicker_id\"].unique()\n",
        "        return matches[0] if len(matches) > 0 else None\n",
        "\n",
        "    def get_kicker_name_by_id(self, df: pd.DataFrame, kicker_id: int) -> str | None:\n",
        "        \"\"\"\n",
        "        Get player_name for a given kicker_id from the dataset.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing kicker_id and player_name columns\n",
        "            kicker_id: ID of the kicker to look up\n",
        "\n",
        "        Returns:\n",
        "            player_name if found, None otherwise\n",
        "        \"\"\"\n",
        "        matches = df[df[\"kicker_id\"] == kicker_id][\"player_name\"].unique()\n",
        "        return matches[0] if len(matches) > 0 else None\n",
        "\n",
        "    def kicker_interval_by_name(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        player_name: str,\n",
        "        distance: float | None = None,\n",
        "        ci: float = 0.95,\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Return mean, lower, upper success probability for a kicker by name.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing kicker mappings\n",
        "            player_name: Name of the kicker\n",
        "            distance: yards; if None, uses empirical mean\n",
        "            ci: central credible-interval mass (default 0.95)\n",
        "        \"\"\"\n",
        "        kicker_id = self.get_kicker_id_by_name(df, player_name)\n",
        "        if kicker_id is None:\n",
        "            raise ValueError(f\"Kicker '{player_name}' not found in dataset\")\n",
        "        return self.kicker_interval(kicker_id, distance, ci)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from src.nfl_kicker_analysis.data.loader import DataLoader\n",
        "    from src.nfl_kicker_analysis.data.feature_engineering import FeatureEngineer\n",
        "    from src.nfl_kicker_analysis.data.preprocessor import DataPreprocessor\n",
        "    from src.nfl_kicker_analysis.models.bayesian import BayesianModelSuite\n",
        "    import numpy as np\n",
        "    import arviz as az\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    import jax\n",
        "    print(jax.devices())        # should list \"GpuDevice\" (CUDA) or \"METAL\" (Apple)\n",
        "    print(jax.default_backend()) # should print 'gpu', not 'cpu'\n",
        "\n",
        "    print(\"ðŸˆ Bayesian Model Suite with DataPreprocessor Integration Demo\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1ï¸âƒ£ Loading and engineering features\n",
        "    print(\"\\n1ï¸âƒ£ Loading and engineering features...\")\n",
        "    loader = DataLoader()\n",
        "    df_raw = loader.load_complete_dataset()\n",
        "    engineer = FeatureEngineer()\n",
        "    df_feat = engineer.create_all_features(df_raw)\n",
        "    print(f\"   Raw data shape: {df_raw.shape}\")\n",
        "    print(f\"   Engineered data shape: {df_feat.shape}\")\n",
        "\n",
        "    # 2ï¸âƒ£ Configuring preprocessing\n",
        "    print(\"\\n2ï¸âƒ£ Configuring preprocessing...\")\n",
        "    CONFIG = {\n",
        "        'min_distance': 20,\n",
        "        'max_distance': 60,\n",
        "        'min_kicker_attempts': 8,\n",
        "        'season_types': ['Reg', 'Post'],\n",
        "        'include_performance_history': True,\n",
        "        'include_statistical_features': False,\n",
        "        'include_player_status': True,  # âœ… FIX: Added missing parameter\n",
        "        'performance_window': 12,\n",
        "    }\n",
        "\n",
        "    preprocessor = DataPreprocessor()\n",
        "    preprocessor.update_config(**CONFIG)\n",
        "    preprocessor.update_feature_lists(**FEATURE_LISTS)\n",
        "\n",
        "    # 3ï¸âƒ£ Method A: Manual preprocessing then passing to BayesianModelSuite\n",
        "    print(\"\\n3ï¸âƒ£ Method A: Manual preprocessing then passing to BayesianModelSuite\")\n",
        "    print(\"-\" * 50)\n",
        "    df_processed = preprocessor.preprocess_complete(df_feat)\n",
        "    print(f\"   Processed data shape: {df_processed.shape}\")\n",
        "    train_data = df_processed[df_processed[\"season\"] <= 2017]\n",
        "    test_data = df_processed[df_processed[\"season\"] == 2018]\n",
        "    print(f\"   Train data shape: {train_data.shape}\")\n",
        "    print(f\"   Test data shape: {test_data.shape}\")\n",
        "    suite_a = BayesianModelSuite(draws=1000,\n",
        "                                 tune=1000,\n",
        "                                 include_random_slope=False,\n",
        "                                 random_seed=42)\n",
        "    suite_a.fit(train_data)\n",
        "    metrics_a = suite_a.evaluate(test_data)\n",
        "    print(\"   Method A Results:\")\n",
        "    for metric, value in metrics_a.items():\n",
        "        print(f\"     {metric}: {value:.4f}\")\n",
        "\n",
        "    # 4ï¸âƒ£ Method B: Automatic preprocessing within BayesianModelSuite\n",
        "    print(\"\\n4ï¸âƒ£ Method B: Automatic preprocessing within BayesianModelSuite\")\n",
        "    print(\"-\" * 50)\n",
        "    train_raw = df_feat[df_feat[\"season\"] <= 2017]\n",
        "    test_raw = df_feat[df_feat[\"season\"] == 2018]\n",
        "    suite_b = BayesianModelSuite(draws=1000,\n",
        "                                 tune=1000,\n",
        "                                 include_random_slope=False,\n",
        "                                 random_seed=42)\n",
        "    suite_b.fit(train_raw, preprocessor=preprocessor)\n",
        "    metrics_b = suite_b.evaluate(test_raw, preprocessor=preprocessor)\n",
        "    print(\"   Method B Results:\")\n",
        "    for metric, value in metrics_b.items():\n",
        "        print(f\"     {metric}: {value:.4f}\")\n",
        "\n",
        "    # 5ï¸âƒ£ Comparing both methods\n",
        "    print(\"\\n5ï¸âƒ£ Comparing both methods\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Both methods should produce identical results since they use the same preprocessing pipeline and the same random seed.\")\n",
        "    print(\"\\nMethod A vs Method B comparison:\")\n",
        "    for metric in metrics_a.keys():\n",
        "        diff = abs(metrics_a[metric] - metrics_b[metric])\n",
        "        print(f\"   {metric}: {diff:.6f} (difference)\")\n",
        "\n",
        "    print(\"\\nâœ… Integration complete! The BayesianModelSuite now supports both:\")\n",
        "    print(\"   â€¢ Direct use with preprocessed data\")\n",
        "    print(\"   â€¢ Automatic preprocessing with DataPreprocessor integration\")\n",
        "    print(\"   â€¢ Consistent results across all model families\")\n",
        "    print(\"   â€¢ No performance penalty from preprocessing in MCMC loop\")\n",
        "\n",
        "    # ------------------\n",
        "    # â–¶ï¸ Validation Checks\n",
        "    # ------------------\n",
        "    print(\"\\nâœ… Running validation checks...\")\n",
        "\n",
        "    # 1ï¸âƒ£ Credible interval sanity\n",
        "    cid = suite_b.kicker_interval_by_name(df_feat, \"JUSTIN TUCKER\", distance=40)\n",
        "    assert cid[\"lower\"] <= cid[\"mean\"] <= cid[\"upper\"], \\\n",
        "        f\"Credible interval ordering failed: {cid}\"\n",
        "    print(\"â€¢ Credible interval check passed.\")\n",
        "\n",
        "    # 2ï¸âƒ£ Posterior-Predictive Check correlation\n",
        "    ax = suite_b.plot_distance_ppc(test_data, bin_width=5, preprocessor=preprocessor)\n",
        "    df_ppc = preprocessor.preprocess_slice(test_data).copy()\n",
        "    df_ppc[\"bin\"] = (df_ppc[\"attempt_yards\"] // 5) * 5\n",
        "    actual = df_ppc.groupby(\"bin\")[\"success\"].mean().values\n",
        "    posterior = df_ppc.assign(pred=suite_b.predict(df_ppc)) \\\n",
        "                   .groupby(\"bin\")[\"pred\"].mean().values\n",
        "    corr = np.corrcoef(actual, posterior)[0, 1]\n",
        "    assert corr > 0.9, f\"PPC correlation too low: {corr:.3f}\"\n",
        "    print(f\"â€¢ PPC correlation check passed (r={corr:.3f}).\")\n",
        "\n",
        "    # 3ï¸âƒ£ EPA-FG+ leaderboard consistency\n",
        "    epa_tbl = suite_b.epa_fg_plus(df_feat, n_samples=500, return_ci=True)\n",
        "    assert {\"hdi_lower\", \"hdi_upper\", \"certainty_level\"}.issubset(epa_tbl.columns)\n",
        "    print(epa_tbl.head())\n",
        "\n",
        "    # Check that Justin Tucker is among the top kickers using name lookup\n",
        "    justin_tucker_id = suite_b.get_kicker_id_by_name(df_feat, \"JUSTIN TUCKER\")\n",
        "    top_kickers = epa_tbl.index.tolist()[:3]\n",
        "    if justin_tucker_id is not None:\n",
        "        assert justin_tucker_id in top_kickers, \\\n",
        "            f\"Expected JUSTIN TUCKER (ID: {justin_tucker_id}) in top 3: {top_kickers}\"\n",
        "        print(\"â€¢ EPA-FG+ leaderboard check passed.\")\n",
        "    else:\n",
        "        print(\"â€¢ WARNING: JUSTIN TUCKER not found in dataset, skipping leaderboard check.\")\n",
        "\n",
        "    # 4ï¸âƒ£ MCMC diagnostics\n",
        "    diag = suite_b.diagnostics(return_scalars=True)\n",
        "    assert diag[\"summary_ok\"], (\n",
        "        f\"R-hat max={diag['rhat_max']:.3f}, \"\n",
        "        f\"ESS min={diag['ess_min']:.0f}\"\n",
        "    )\n",
        "    print(\"â€¢ Diagnostics check passed (R-hat â‰¤1.01, ESS â‰¥100).\")\n",
        "\n",
        "    print(\"\\nðŸŽ‰ All validation checks passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7b.Bayesian Time Series Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/nfl_kicker_analysis/models/bayesian_timeseries.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/models/bayesian_timeseries.py\n",
        "\"\"\"\n",
        "Time-Series Bayesian Models for NFL Kicker Analysis\n",
        "==================================================\n",
        "NEW IN v1.1.0  (2025-06-30)\n",
        "\n",
        "* Hierarchical dynamic-linear model (level + trend) **or** SARIMA\n",
        "  built on PyMC 5 (+ pymc-experimental).\n",
        "* Mirrors the API of BayesianModelSuite so the rest of the pipeline\n",
        "  stays unchanged.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "import warnings\n",
        "from typing import Dict, Optional, List, Union\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "import jax  # keep for device detection\n",
        "import numpyro\n",
        "\n",
        "# Silence ArviZ HDI FutureWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"arviz\")\n",
        "\n",
        "# Optional fast Kalman-filter backend\n",
        "try:\n",
        "    from pymc_experimental.statespace import SARIMA   # type: ignore\n",
        "except ImportError:  # graceful fallback for CI\n",
        "    SARIMA = None\n",
        "\n",
        "# -------------------------------------------------------------- #\n",
        "# utils â€“ choose chain layout safely                              #\n",
        "# -------------------------------------------------------------- #\n",
        "def _choose_chain_config(requested: int, use_jax: bool) -> dict:\n",
        "    \"\"\"\n",
        "    Return a dict of kwargs for PyMC/JAX samplers guaranteeing â‰¥2 chains.\n",
        "    On a single-device JAX setup we vectorise chains; on CPU we parallelise.\n",
        "    \"\"\"\n",
        "    if use_jax:\n",
        "        # run all requested chains on the same GPU\n",
        "        return dict(chains=max(2, requested), chain_method=\"vectorized\")\n",
        "    else:\n",
        "        # let PyMC fork processes; fall back to sequential if memory is tight\n",
        "        return dict(chains=max(2, requested), cores=min(4, max(2, requested)))\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "# Helper â€“ aggregate attempt-level rows â†’ weekly counts per kicker   #\n",
        "# ------------------------------------------------------------------ #\n",
        "def _prep_series(df: pd.DataFrame, freq: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Collapse attempt-level data to (attempts, made) per kicker & period.\n",
        "\n",
        "    Also preserves age-related columns by taking the mean within each period.\n",
        "\n",
        "    * Ensures ``game_date`` is datetime64[ns] so `.dt` accessors work.\n",
        "    * Returns a tidy frame sorted by kicker & date_key.\n",
        "    \"\"\"\n",
        "    if \"game_date\" not in df.columns:\n",
        "        raise KeyError(\"Column 'game_date' required for time-series modelling\")\n",
        "\n",
        "    if not np.issubdtype(df[\"game_date\"].dtype, np.datetime64):\n",
        "        df = df.copy()\n",
        "        df[\"game_date\"] = pd.to_datetime(df[\"game_date\"])\n",
        "\n",
        "    # Build aggregation dictionary\n",
        "    agg_dict = {\n",
        "        \"success\": [\"size\", \"sum\"]  # attempts = size, made = sum\n",
        "    }\n",
        "\n",
        "    # Add age-related columns if they exist\n",
        "    age_cols = [\"age_at_attempt\", \"career_year\", \"seasons_of_experience\"]\n",
        "    for col in age_cols:\n",
        "        if col in df.columns:\n",
        "            agg_dict[col] = [\"mean\"]  # Take mean within period\n",
        "\n",
        "    out = (\n",
        "        df.assign(date_key=df[\"game_date\"].dt.to_period(freq).dt.start_time)\n",
        "          .groupby([\"player_name\", \"player_id\", \"date_key\"], sort=False)\n",
        "          .agg(agg_dict)\n",
        "          .reset_index()\n",
        "    )\n",
        "\n",
        "    # Flatten multi-level columns and rename\n",
        "    if isinstance(out.columns, pd.MultiIndex):\n",
        "        new_cols = []\n",
        "        for col in out.columns:\n",
        "            if col[0] == \"success\" and col[1] == \"size\":\n",
        "                new_cols.append(\"attempts\")\n",
        "            elif col[0] == \"success\" and col[1] == \"sum\":\n",
        "                new_cols.append(\"made\")\n",
        "            elif col[1] == \"\":\n",
        "                new_cols.append(col[0])  # groupby columns\n",
        "            else:\n",
        "                new_cols.append(col[0])  # age columns\n",
        "        out.columns = new_cols\n",
        "\n",
        "    out[\"success_rate\"] = out[\"made\"] / out[\"attempts\"]\n",
        "    return out.sort_values([\"player_name\", \"date_key\"], ignore_index=True)\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "# Main class                                                         #\n",
        "# ------------------------------------------------------------------ #\n",
        "class TimeSeriesBayesianModelSuite:\n",
        "    \"\"\"\n",
        "    Hierarchical DLM / SARIMA wrapper for weekly kicker make-rates.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    freq          : str, default \"W-MON\"\n",
        "    draws, tune,\n",
        "    target_accept : passed to `pm.sample`\n",
        "    random_seed   : int | None\n",
        "    use_sarima    : bool â€“ if True **and** pymc_experimental is installed,\n",
        "                    approximates the latent process via SARIMA for speed.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        freq: str = \"W-MON\",\n",
        "        draws: int = 1_000,\n",
        "        tune: int = 1_000,\n",
        "        target_accept: float = 0.9,\n",
        "        random_seed: int | None = 42,\n",
        "        use_sarima: bool = False,\n",
        "        debug: bool = False,\n",
        "        diag_vars: Optional[List[str]] = None,\n",
        "        use_jax: Optional[bool] = None,\n",
        "        chains: int = 4,                          # NEW: desired chains\n",
        "        init_sigma: float = 5.0,                  # NEW: Ïƒ for initial state\n",
        "    ):\n",
        "        self.freq, self.draws, self.tune = freq, draws, tune\n",
        "        self.target_accept, self.random_seed = target_accept, random_seed\n",
        "        self.use_sarima = use_sarima and SARIMA is not None\n",
        "        self.debug = debug\n",
        "        self.diag_vars = diag_vars or [\"sigma_level\", \"sigma_trend\", \"lvl\", \"trd\"]\n",
        "\n",
        "        self.init_sigma = init_sigma\n",
        "        self.chains = chains\n",
        "        # Auto-detect GPU: use JAX if any CUDA devices available\n",
        "        self.use_jax = bool(jax.devices()) if use_jax is None else use_jax\n",
        "\n",
        "        self._model: Optional[pm.Model] = None\n",
        "        self._trace: Optional[az.InferenceData] = None\n",
        "        self._meta: Optional[pd.DataFrame] = None\n",
        "\n",
        "    # -------------------------------------------------------------- #\n",
        "    # tiny helper so we never sprinkle print() everywhere\n",
        "    def _log(self, *msg):\n",
        "        if self.debug:\n",
        "            print(\"[TS-Bayes]\", *msg)\n",
        "\n",
        "    # -------------------------------------------------------------- #\n",
        "    # Fit                                                            #\n",
        "    # -------------------------------------------------------------- #\n",
        "    def fit(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        *,\n",
        "        preprocessor=None,\n",
        "        min_attempts: int = 5,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Fit the hierarchical time-series model on attempt-level ``df``.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df            : long DataFrame (one row per FG attempt)\n",
        "        preprocessor  : optional ``DataPreprocessor`` to mirror BayesianModelSuite\n",
        "        min_attempts  : kickers with < ``min_attempts`` total are dropped\n",
        "                        to keep the latent state-space well-conditioned.\n",
        "        \"\"\"\n",
        "        # 0ï¸âƒ£ optional slice-level preprocessing â€“ keeps pipeline symmetry\n",
        "        if preprocessor is not None:\n",
        "            df = preprocessor.preprocess_slice(df)\n",
        "\n",
        "        # 1ï¸âƒ£ drop ultra-low-volume kickers\n",
        "        keep = df.groupby(\"player_name\")[\"success\"].size().loc[lambda s: s >= min_attempts].index\n",
        "        df = df[df[\"player_name\"].isin(keep)]\n",
        "\n",
        "        # 2ï¸âƒ£ aggregate to weekly (or monthly) counts\n",
        "        ts = _prep_series(df, self.freq)\n",
        "        self._meta = (\n",
        "            ts[[\"player_name\", \"player_id\"]].drop_duplicates().set_index(\"player_name\")\n",
        "        )\n",
        "        players = ts[\"player_name\"].unique()\n",
        "        P       = len(players)\n",
        "\n",
        "        # 3ï¸âƒ£ build rectangular player Ã— time grid\n",
        "        full_idx = (\n",
        "            ts.groupby(\"player_name\", sort=False)[\"date_key\"]\n",
        "            .apply(lambda s: pd.date_range(s.min(), s.max(), freq=self.freq))\n",
        "            .explode()\n",
        "            .reset_index()\n",
        "            .rename(columns={0: \"date_key\"})\n",
        "        )\n",
        "        ts_full = full_idx.merge(ts, how=\"left\", on=[\"player_name\", \"date_key\"])\n",
        "        ts_full[[\"attempts\", \"made\"]] = ts_full[[\"attempts\", \"made\"]].fillna(0.0)\n",
        "\n",
        "        y = ts_full[\"made\"].to_numpy(int)        # successes\n",
        "        n = ts_full[\"attempts\"].to_numpy(int)    # trials\n",
        "\n",
        "        player_idx = pd.Categorical(ts_full[\"player_name\"], categories=players).codes\n",
        "        time_idx   = ts_full.groupby(\"player_name\").cumcount()\n",
        "        T_max      = int(time_idx.max()) + 1\n",
        "\n",
        "        # 4ï¸âƒ£ Static covariates ------------------------------------\n",
        "        #   Enhanced age modeling: prefer career_year over age, then age, then zeros\n",
        "        if \"career_year\" in ts_full.columns:\n",
        "            # Use career_year for smooth aging curves (preferred)\n",
        "            age_covariate = ts_full[\"career_year\"].to_numpy(float)\n",
        "            age_covariate_name = \"career_year\"\n",
        "            self._log(\"Using career_year for age modeling\")\n",
        "        elif \"age\" in ts_full.columns:\n",
        "            # Fallback to age_at_attempt\n",
        "            age_covariate = ts_full[\"age\"].to_numpy(float)\n",
        "            age_covariate_name = \"age\"\n",
        "            self._log(\"Using age for age modeling\")\n",
        "        else:\n",
        "            # No age information available\n",
        "            age_covariate = np.zeros(len(ts_full), dtype=float)\n",
        "            age_covariate_name = \"none\"\n",
        "            self._log(\"No age information available - using zeros\")\n",
        "\n",
        "        # 5ï¸âƒ£ build PyMC model\n",
        "        with pm.Model() as self._model:\n",
        "            if self.use_sarima:\n",
        "                if SARIMA is None:\n",
        "                    raise RuntimeError(\n",
        "                        \"pymc-experimental not installed â€“ \"\n",
        "                        \"set use_sarima=False or install the extra dependency.\"\n",
        "                    )\n",
        "                sarima = SARIMA(\n",
        "                    name=\"sarima\",\n",
        "                    endog=y,\n",
        "                    exog=None,\n",
        "                    order=(0, 1, 1),\n",
        "                    seasonal_order=(0, 0, 0, 0),\n",
        "                    measurement_error=True,\n",
        "                )\n",
        "                mu_mat = sarima.states.reshape((1, -1))  # flattened for indexing\n",
        "            else:\n",
        "                init_0 = pm.Normal.dist(0.0, self.init_sigma)  # explicit init_dist\n",
        "                Ïƒ_lvl = pm.Exponential(\"sigma_level\", 1.0)\n",
        "                Ïƒ_trd = pm.Exponential(\"sigma_trend\", 1.0)\n",
        "                lvl = pm.GaussianRandomWalk(\n",
        "                    \"lvl\", sigma=Ïƒ_lvl, init_dist=init_0, shape=(P, T_max)\n",
        "                )\n",
        "                trd = pm.GaussianRandomWalk(\n",
        "                    \"trd\", sigma=Ïƒ_trd, init_dist=init_0, shape=(P, T_max)\n",
        "                )\n",
        "                # identical trailing dimension â€“ avoids broadcast crash\n",
        "                step_frac = pm.math.constant(np.arange(T_max) / T_max)\n",
        "                mu_mat = lvl + trd * step_frac          # âœ… broadcast-safe\n",
        "\n",
        "            Î²_age = pm.Normal(\"beta_age\", 0.0, 1.0)          # NEW: age/career_year effect\n",
        "\n",
        "            # Apply age effect directly at observation level\n",
        "            mu_obs = mu_mat[player_idx, time_idx] + Î²_age * age_covariate\n",
        "\n",
        "            theta = pm.Deterministic(\n",
        "                \"theta\", pm.math.invlogit(mu_obs)\n",
        "            )\n",
        "            pm.Binomial(\"obs\", n=n, p=theta, observed=y)\n",
        "\n",
        "            # -------- sampling ------------------------------------\n",
        "            chain_cfg = _choose_chain_config(self.chains, self.use_jax)\n",
        "\n",
        "            if self.use_jax:\n",
        "                numpyro.set_host_device_count(chain_cfg[\"chains\"])\n",
        "                from pymc.sampling.jax import sample_numpyro_nuts\n",
        "                self._trace = sample_numpyro_nuts(\n",
        "                    draws=self.draws,\n",
        "                    tune=self.tune,\n",
        "                    target_accept=self.target_accept,\n",
        "                    random_seed=self.random_seed,\n",
        "                    progressbar=True,\n",
        "                    **chain_cfg,\n",
        "                )\n",
        "            else:\n",
        "                self._trace = pm.sample(\n",
        "                    draws=self.draws,\n",
        "                    tune=self.tune,\n",
        "                    target_accept=self.target_accept,\n",
        "                    random_seed=self.random_seed,\n",
        "                    idata_kwargs={\"log_likelihood\": False},\n",
        "                    progressbar=True,\n",
        "                    **chain_cfg,\n",
        "                )\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------- #\n",
        "    # Forecast                                                       #\n",
        "    # -------------------------------------------------------------- #\n",
        "    def forecast(self, *, steps: int = 6, hdi_prob: float = 0.9) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Monte-Carlo simulate `steps` weeks ahead for **all** fitted kickers.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        DataFrame with columns ['player_name', 'step', 'p_mean', 'hdi_lower', 'hdi_upper']\n",
        "        \"\"\"\n",
        "        if any(obj is None for obj in (self._trace, self._meta, self._model)):\n",
        "            raise RuntimeError(\"Call `.fit()` before forecasting\")\n",
        "\n",
        "        players = self._meta.index.tolist()\n",
        "        lvl = self._trace.posterior[\"lvl\"].values\n",
        "        trd = self._trace.posterior[\"trd\"].values\n",
        "        chains, draws, P, T = lvl.shape\n",
        "        lvl_last = lvl[:, :, :, -1].reshape(chains*draws, P)\n",
        "        trd_last = trd[:, :, :, -1].reshape(chains*draws, P)\n",
        "\n",
        "        rng = np.random.default_rng(self.random_seed)\n",
        "        records: List[Dict[str, Union[str, int, float]]] = []\n",
        "        for p_idx, name in enumerate(players):\n",
        "            noise = rng.normal(0, 0.1, size=(chains*draws, steps)).cumsum(axis=1)\n",
        "            lvl_path = lvl_last[:, p_idx][:, None] + noise\n",
        "            trd_path = trd_last[:, p_idx][:, None]\n",
        "            mu = lvl_path + trd_path * np.arange(1, steps+1)\n",
        "            theta = 1 / (1 + np.exp(-mu))\n",
        "            mean = theta.mean(axis=0)\n",
        "            hdi  = az.hdi(theta, hdi_prob=hdi_prob)\n",
        "            for s, (m, lo, hi) in enumerate(zip(mean, hdi[:,0], hdi[:,1]), 1):\n",
        "                records.append({\"player_name\": name,\n",
        "                                \"step\": s,\n",
        "                                \"p_mean\": float(m),\n",
        "                                \"hdi_lower\": float(lo),\n",
        "                                \"hdi_upper\": float(hi)})\n",
        "        return pd.DataFrame(records)\n",
        "\n",
        "    # -------------------------------------------------------------- #\n",
        "    # Diagnostics                                                    #\n",
        "    # -------------------------------------------------------------- #\n",
        "    def diagnostics(self, *, thin: int = 5) -> Dict[str, float]:\n",
        "        if self._trace is None:\n",
        "            raise RuntimeError(\"Model not fitted\")\n",
        "\n",
        "        if self._trace.posterior.dims[\"chain\"] < 2:\n",
        "            # rÌ‚ undefined â†’ return sentinel values and warn once\n",
        "            warnings.warn(\"Only one chain present â€“ rÌ‚ unavailable; run â‰¥2 chains for convergence diagnostics.\")\n",
        "            return {\"rhat_max\": float(\"nan\"), \"ess_min\": float(\"nan\")}\n",
        "\n",
        "        rhat_max, ess_min = -np.inf, np.inf\n",
        "        for var in self.diag_vars:\n",
        "            if var not in self._trace.posterior:\n",
        "                continue\n",
        "            data = self._trace.posterior[var]\n",
        "            if thin > 1 and data.ndim > 2:\n",
        "                slc = (slice(None), slice(None)) + (slice(None, None, thin),) * (data.ndim - 2)\n",
        "                data = data[slc]\n",
        "            rhat_max = max(rhat_max, az.rhat(data).to_array().max().item())\n",
        "            ess_min  = min(ess_min,  az.ess(data, method=\"bulk\").to_array().min().item())\n",
        "        return {\"rhat_max\": float(rhat_max), \"ess_min\": float(ess_min)}\n",
        "\n",
        "    # -------------------------------------------------------------- #\n",
        "    # Quick plot                                                     #\n",
        "    # -------------------------------------------------------------- #\n",
        "    def plot_forecast(self, player_name: str, *, ax=None):\n",
        "        \"\"\"\n",
        "        Plot historical weekly make-probability with 90 % HDI for one kicker.\n",
        "        \"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        if self._trace is None or self._meta is None:\n",
        "            raise RuntimeError(\"Fit the model first\")\n",
        "        if player_name not in self._meta.index:\n",
        "            raise ValueError(f\"Unknown player '{player_name}'\")\n",
        "\n",
        "        p_idx = list(self._meta.index).index(player_name)\n",
        "        lvl = self._trace.posterior[\"lvl\"].sel(lvl_dim_0=p_idx).stack(draws=(\"chain\",\"draw\"))\n",
        "        trd = self._trace.posterior[\"trd\"].sel(trd_dim_0=p_idx).stack(draws=(\"chain\",\"draw\"))\n",
        "        T = lvl.shape[-1]\n",
        "        x = np.arange(T)\n",
        "        mu = lvl + trd * (x / T)\n",
        "        p  = 1 / (1 + np.exp(-mu))\n",
        "        mean = p.mean(\"draws\")\n",
        "        hdi  = az.hdi(p, hdi_prob=0.9)\n",
        "\n",
        "        if ax is None:\n",
        "            _, ax = plt.subplots(figsize=(8,4))\n",
        "        ax.plot(x, mean, label=\"p_mean\")\n",
        "        ax.fill_between(x, hdi.sel(hdi=\"lower\"), hdi.sel(hdi=\"upper\"), alpha=0.3,\n",
        "                        label=\"90 % HDI\")\n",
        "        ax.set_xlabel(\"Week index\")\n",
        "        ax.set_ylabel(\"Make probability\")\n",
        "        ax.set_title(f\"Historical make-probability â€“ {player_name}\")\n",
        "        ax.legend()\n",
        "        return ax\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "# Smoke-test CLI                                                     #\n",
        "# ------------------------------------------------------------------ #\n",
        "if __name__ == \"__main__\":\n",
        "    from src.nfl_kicker_analysis.data.loader import DataLoader\n",
        "    from src.nfl_kicker_analysis.data.feature_engineering import FeatureEngineer\n",
        "\n",
        "    print(\"ðŸˆ  Time-Series Bayesian demo (weekly make-rates)\")\n",
        "    df_raw  = DataLoader().load_complete_dataset()\n",
        "    df_feat = FeatureEngineer().create_all_features(df_raw)\n",
        "\n",
        "    ts = TimeSeriesBayesianModelSuite(freq=\"W-MON\",\n",
        "                                      draws=250,\n",
        "                                      tune=250,\n",
        "                                      use_sarima=True,\n",
        "                                      target_accept=.85,\n",
        "                                      )\n",
        "    ts.fit(df_feat[df_feat[\"season\"] <= 2018])             # train through 2019\n",
        "    fcst = ts.forecast(steps=6)                            # next six weeks\n",
        "    print(fcst.head())\n",
        "\n",
        "    diag = ts.diagnostics()\n",
        "    print(f\"R-hat â‰¤ 1.01 ? {diag['rhat_max']:.3f} | ESS â‰¥ 100 ? {diag['ess_min']:.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Remaining Init Files and Unit Tests\n",
        "\n",
        "Creating the remaining __init__.py files and comprehensive unit tests.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/nfl_kicker_analysis/models/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/models/__init__.py\n",
        "\"\"\"Models module for NFL kicker analysis.\"\"\"\n",
        "\n",
        "from .tree_based_bayes_optimized_models import TreeBasedModelSuite\n",
        "from .bayesian_timeseries import TimeSeriesBayesianModelSuite\n",
        "\n",
        "__all__ = ['TreeBasedModelSuite', 'TimeSeriesBayesianModelSuite']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/nfl_kicker_analysis/utils/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/nfl_kicker_analysis/utils/__init__.py\n",
        "\"\"\"Utils module for NFL kicker analysis.\"\"\"\n",
        "\n",
        "from .metrics import EPACalculator, ModelEvaluator\n",
        "\n",
        "__all__ = ['EPACalculator', 'ModelEvaluator']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

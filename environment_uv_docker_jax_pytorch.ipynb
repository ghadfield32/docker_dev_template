{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure no other containers are running for dev container, if they are stop and remove them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/.dockerignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/.dockerignore\n",
    "**/.git\n",
    "**/.vscode\n",
    "**/.idea\n",
    "**/__pycache__\n",
    "**/*.pyc\n",
    "\n",
    "**/*.pyo\n",
    "**/*.pyd\n",
    "**/*.swp\n",
    "**/.venv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dev.env\n"
     ]
    }
   ],
   "source": [
    "%%writefile dev.env\n",
    "ENV_NAME=docker_dev_template \n",
    "# Fixed ports you actually care about\n",
    "HOST_JUPYTER_PORT=8890\n",
    "\n",
    "# Leave blank ‚Üí Docker picks a free host port\n",
    "HOST_TENSORBOARD_PORT=\n",
    "HOST_EXPLAINER_PORT=\n",
    "HOST_STREAMLIT_PORT=\n",
    "\n",
    "# JAX/GPU Configuration\n",
    "PYTHON_VER=3.10\n",
    "JAX_PLATFORM_NAME=gpu\n",
    "XLA_PYTHON_CLIENT_PREALLOCATE=true\n",
    "XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "XLA_PYTHON_CLIENT_MEM_FRACTION=0.95\n",
    "XLA_FLAGS=--xla_force_host_platform_device_count=1\n",
    "JAX_DISABLE_JIT=false\n",
    "JAX_ENABLE_X64=false\n",
    "TF_FORCE_GPU_ALLOW_GROWTH=false\n",
    "JAX_PREALLOCATION_SIZE_LIMIT_BYTES=8589934592\n",
    "\n",
    "# Code Executor\n",
    "CODE_STORAGE_DIR=code_executor_storage\n",
    "ENV_NAME=docker_dev_template\n",
    "\n",
    "# Snowflake\n",
    "SNOWFLAKE_ACCOUNT=your_account\n",
    "SNOWFLAKE_USER=your_user\n",
    "SNOWFLAKE_PASSWORD=your_password\n",
    "SNOWFLAKE_ROLE=your_role\n",
    "SNOWFLAKE_WAREHOUSE=your_warehouse\n",
    "SNOWFLAKE_DATABASE=your_database\n",
    "SNOWFLAKE_SCHEMA=your_schema\n",
    "\n",
    "# Jupyter\n",
    "JUPYTER_URL=http://host.docker.internal:8890\n",
    "JUPYTER_TOKEN=insert_token         # must match token used in jupyter lab command\n",
    "NOTEBOOK_PATH=notebooks/demo.ipynb\n",
    "# OracleDB\n",
    "ORACLE_CONNECTION_STRING=username/password@//host:port/service\n",
    "TARGET_SCHEMA=your_schema\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "ENV_NAME=docker_dev_template \n",
    "# Fixed ports you actually care about\n",
    "HOST_JUPYTER_PORT=8890\n",
    "\n",
    "# Leave blank ‚Üí Docker picks a free host port\n",
    "HOST_TENSORBOARD_PORT=\n",
    "HOST_EXPLAINER_PORT=\n",
    "HOST_STREAMLIT_PORT=\n",
    "\n",
    "# JAX/GPU Configuration\n",
    "PYTHON_VER=3.10\n",
    "JAX_PLATFORM_NAME=gpu\n",
    "XLA_PYTHON_CLIENT_PREALLOCATE=true\n",
    "XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "XLA_PYTHON_CLIENT_MEM_FRACTION=0.95\n",
    "XLA_FLAGS=--xla_force_host_platform_device_count=1\n",
    "JAX_DISABLE_JIT=false\n",
    "JAX_ENABLE_X64=false\n",
    "TF_FORCE_GPU_ALLOW_GROWTH=false\n",
    "JAX_PREALLOCATION_SIZE_LIMIT_BYTES=8589934592\n",
    "\n",
    "# Code Executor\n",
    "CODE_STORAGE_DIR=code_executor_storage\n",
    "ENV_NAME=docker_dev_template\n",
    "\n",
    "# Snowflake\n",
    "SNOWFLAKE_ACCOUNT=your_account\n",
    "SNOWFLAKE_USER=your_user\n",
    "SNOWFLAKE_PASSWORD=your_password\n",
    "SNOWFLAKE_ROLE=your_role\n",
    "SNOWFLAKE_WAREHOUSE=your_warehouse\n",
    "SNOWFLAKE_DATABASE=your_database\n",
    "SNOWFLAKE_SCHEMA=your_schema\n",
    "\n",
    "# Jupyter\n",
    "JUPYTER_URL=http://host.docker.internal:8890\n",
    "JUPYTER_TOKEN=insert_token         # must match token used in jupyter lab command\n",
    "NOTEBOOK_PATH=notebooks/demo.ipynb\n",
    "# OracleDB\n",
    "ORACLE_CONNECTION_STRING=username/password@//host:port/service\n",
    "TARGET_SCHEMA=your_schema\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/.env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/.env\n",
    "ENV_NAME=docker_dev_template \n",
    "# Fixed ports you actually care about\n",
    "HOST_JUPYTER_PORT=8890\n",
    "\n",
    "# Leave blank ‚Üí Docker picks a free host port\n",
    "HOST_TENSORBOARD_PORT=\n",
    "HOST_EXPLAINER_PORT=\n",
    "HOST_STREAMLIT_PORT=\n",
    "\n",
    "# JAX/GPU Configuration\n",
    "PYTHON_VER=3.10\n",
    "JAX_PLATFORM_NAME=gpu\n",
    "XLA_PYTHON_CLIENT_PREALLOCATE=true\n",
    "XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "XLA_PYTHON_CLIENT_MEM_FRACTION=0.95\n",
    "XLA_FLAGS=--xla_force_host_platform_device_count=1\n",
    "JAX_DISABLE_JIT=false\n",
    "JAX_ENABLE_X64=false\n",
    "TF_FORCE_GPU_ALLOW_GROWTH=false\n",
    "JAX_PREALLOCATION_SIZE_LIMIT_BYTES=8589934592\n",
    "\n",
    "# Code Executor\n",
    "CODE_STORAGE_DIR=code_executor_storage\n",
    "ENV_NAME=docker_dev_template\n",
    "\n",
    "# Snowflake\n",
    "SNOWFLAKE_ACCOUNT=your_account\n",
    "SNOWFLAKE_USER=your_user\n",
    "SNOWFLAKE_PASSWORD=your_password\n",
    "SNOWFLAKE_ROLE=your_role\n",
    "SNOWFLAKE_WAREHOUSE=your_warehouse\n",
    "SNOWFLAKE_DATABASE=your_database\n",
    "SNOWFLAKE_SCHEMA=your_schema\n",
    "\n",
    "# Jupyter\n",
    "JUPYTER_URL=http://host.docker.internal:8890\n",
    "JUPYTER_TOKEN=insert_token         # must match token used in jupyter lab command\n",
    "NOTEBOOK_PATH=notebooks/demo.ipynb\n",
    "# OracleDB\n",
    "ORACLE_CONNECTION_STRING=username/password@//host:port/service\n",
    "TARGET_SCHEMA=your_schema\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/devcontainer.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/devcontainer.json\n",
    "{\n",
    "  \"name\": \"docker_dev_template_uv\",\n",
    "  \"dockerComposeFile\": \"../docker-compose.yml\",\n",
    "  \"service\": \"datascience\",\n",
    "  \"workspaceFolder\": \"/workspace\",\n",
    "  \"shutdownAction\": \"stopCompose\",\n",
    "  \"runArgs\": [\n",
    "    \"--gpus\", \"all\",\n",
    "    \"--env-file\", \".devcontainer/devcontainer.env\"\n",
    "  ],\n",
    "  \"customizations\": {\n",
    "    \"vscode\": {\n",
    "      \"settings\": {\n",
    "        \"python.defaultInterpreterPath\": \"/app/.venv/bin/python\",\n",
    "        \"python.pythonPath\": \"/app/.venv/bin/python\"\n",
    "      },\n",
    "      \"extensions\": [\n",
    "        \"ms-python.python\",\n",
    "        \"ms-toolsai.jupyter\",\n",
    "        \"GitHub.copilot\",\n",
    "        \"ms-azuretools.vscode-docker\"\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"remoteEnv\": {\n",
    "      \"MY_VAR\": \"${localEnv:MY_VAR:test_var}\"\n",
    "  },\n",
    "  \"postCreateCommand\": [\n",
    "    \"bash\", \"-c\", \n",
    "    \"set -euo pipefail && echo '## uv diagnostics ##' && uv --version && echo '## python ##' && which python && python -V && python -c 'import encodings, sys; print(\\\"üü¢ encodings OK\\\", sys.executable)' && python -c 'import jupyterlab; print(\\\"üü¢ jupyterlab OK\\\")' && python -c 'import torch; print(\\\"üü¢ torch\\\", torch.__version__, \\\"CUDA:\\\", torch.cuda.is_available())' && python -c 'import jax; print(\\\"üü¢ jax\\\", jax.__version__, \\\"devices:\\\", jax.devices())' && echo 'üéâ All imports successful!'\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/Dockerfile\n",
    "# .devcontainer/Dockerfile ‚Äî uv‚Äëbased replacement for the previous Conda image\n",
    "# -----------------------------------------------------------------------------\n",
    "# CUDA + cuDNN base with drivers already installed --------------------------------\n",
    "FROM nvidia/cuda:12.3.2-cudnn9-devel-ubuntu22.04\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# --- Build‚Äëtime ARGs ---------------------------------------------------------\n",
    "ARG PYTHON_VER=3.10               # system Python to seed the venv\n",
    "ARG ENV_NAME=docker_dev_template  # prompt shown when the venv is active\n",
    "# JAX GPU memory tuning (kept 1‚Äëfor‚Äë1 with the old Conda image)\n",
    "ARG JAX_PREALLOCATE=true\n",
    "ARG JAX_MEM_FRAC=0.95\n",
    "ARG JAX_ALLOCATOR=platform\n",
    "ARG JAX_PREALLOC_LIMIT=8589934592\n",
    "\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) Core OS deps, build tools, & Python (system) -----------------------------\n",
    "RUN --mount=type=cache,target=/var/cache/apt \\\n",
    "    --mount=type=cache,target=/var/lib/apt \\\n",
    "    apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        curl ca-certificates git procps htop util-linux build-essential \\\n",
    "        python3 python3-venv python3-pip python3-dev \\\n",
    "        autoconf automake libtool m4 cmake pkg-config \\\n",
    "        jags \\\n",
    "        && pkg-config --modversion jags \\\n",
    "        && apt-get clean && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2) Copy a *pinned* uv & uvx binary pair from the official distroless image --\n",
    "COPY --from=ghcr.io/astral-sh/uv:0.7.12 /uv /uvx /bin/\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) Create project dir & copy only the lock/manifest for best layer‚Äëcaching --\n",
    "WORKDIR /app\n",
    "COPY pyproject.toml uv.lock* ./\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4) Create an in‚Äëproject venv & sync dependencies (no project‚Äësource yet) ----\n",
    "RUN --mount=type=cache,target=/root/.cache/uv \\\n",
    "    uv venv .venv --python \"${PYTHON_VER}\" --prompt \"${ENV_NAME}\" && \\\n",
    "    uv sync --locked\n",
    "\n",
    "# Promote venv for all later layers ------------------------------------------------\n",
    "ENV VIRTUAL_ENV=/app/.venv\n",
    "ENV PATH=\"/app/.venv/bin:${PATH}\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5) Install CUDA wheels (PyTorch nightly + JAX CUDA 12) ----------------------\n",
    "RUN --mount=type=cache,target=/root/.cache/uv \\\n",
    "    uv pip install --pre --no-cache-dir \\\n",
    "        torch torchvision torchaudio \\\n",
    "        --index-url https://download.pytorch.org/whl/nightly/cu128 && \\\n",
    "    uv pip install --no-cache-dir \\\n",
    "        \"jax[cuda12-local]==0.4.38\" \\\n",
    "        -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6) Install PyJAGS with the cstdint header work‚Äëaround -----------------------\n",
    "RUN CPPFLAGS=\"-include cstdint\" uv pip install --no-build-isolation pyjags==1.3.8\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7) Copy *rest* of the project after deps ‚Üí fast rebuild when code changes ---\n",
    "COPY . /app\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 8) GPU‚Äëtuning env vars (carried forward from Conda‚Äëbased image) -------------\n",
    "ENV XLA_PYTHON_CLIENT_PREALLOCATE=${JAX_PREALLOCATE}\n",
    "ENV XLA_PYTHON_CLIENT_MEM_FRACTION=${JAX_MEM_FRAC}\n",
    "ENV XLA_PYTHON_CLIENT_ALLOCATOR=${JAX_ALLOCATOR}\n",
    "ENV JAX_PLATFORM_NAME=gpu\n",
    "ENV XLA_FLAGS=\"--xla_force_host_platform_device_count=1\"\n",
    "ENV JAX_DISABLE_JIT=false\n",
    "ENV JAX_ENABLE_X64=false\n",
    "ENV TF_FORCE_GPU_ALLOW_GROWTH=false\n",
    "ENV JAX_PREALLOCATION_SIZE_LIMIT_BYTES=${JAX_PREALLOC_LIMIT}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 9) Library path so PyJAGS & CUDA libs resolve correctly ---------------------\n",
    "ENV LD_LIBRARY_PATH=\"/app/.venv/lib:${LD_LIBRARY_PATH}\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 10) Final working directory & default command ------------------------------\n",
    "WORKDIR /workspace\n",
    "CMD [\"bash\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/gpu_verify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/gpu_verify.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Verify that the GPU is accessible and JAX is correctly configured.\n",
    "This script is used during container startup.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "def check_gpu():\n",
    "    print(\"Checking GPU availability...\")\n",
    "    try:\n",
    "        import jax\n",
    "        jax.config.update('jax_platform_name', 'gpu')\n",
    "        \n",
    "        # Get device count and details\n",
    "        devices = jax.devices()\n",
    "        device_count = len(devices)\n",
    "        print(f\"JAX version: {jax.__version__}\")\n",
    "        print(f\"Available devices: {device_count}\")\n",
    "        \n",
    "        for i, device in enumerate(devices):\n",
    "            print(f\"Device {i}: {device}\")\n",
    "        \n",
    "        if device_count == 0 or 'gpu' not in str(devices[0]).lower():\n",
    "            print(\"WARNING: No GPU devices found by JAX!\")\n",
    "            return False\n",
    "        \n",
    "        # Check CUDA configuration\n",
    "        import jax.tools.jax_jit\n",
    "        jit_info = jax.tools.jax_jit.get_jax_jit_flags()\n",
    "        print(f\"JIT configuration: {jit_info}\")\n",
    "        \n",
    "        # Run a simple GPU computation\n",
    "        print(\"Running a test computation on GPU...\")\n",
    "        import numpy as np\n",
    "        x = np.ones((1000, 1000))\n",
    "        result = jax.numpy.sum(x, axis=0)\n",
    "        print(f\"Test computation result shape: {result.shape}\")\n",
    "        \n",
    "        print(\"JAX GPU verification completed successfully!\")\n",
    "        return True\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"JAX not found! Make sure JAX is installed with GPU support.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPU verification: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = check_gpu()\n",
    "    if not success:\n",
    "        print(\"WARNING: GPU verification failed!\")\n",
    "        # Not exiting with error to allow container to start anyway\n",
    "        # sys.exit(1)\n",
    "    else:\n",
    "        sys.exit(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/jags_verify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/jags_verify.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Verify that PyJAGS is correctly installed and working.\n",
    "This script is used by the Docker container health check.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "try:\n",
    "    import pyjags\n",
    "    print(f\"PyJAGS version: {pyjags.__version__}\")\n",
    "    \n",
    "    # Create a simple model to verify that PyJAGS works\n",
    "    code = \"\"\"\n",
    "    model {\n",
    "        # Likelihood\n",
    "        y ~ dnorm(mu, 1/sigma^2)\n",
    "        \n",
    "        # Priors\n",
    "        mu ~ dnorm(0, 0.001)\n",
    "        sigma ~ dunif(0, 100)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample data\n",
    "    data = {'y': 0.5}\n",
    "    \n",
    "    # Initialize model with data\n",
    "    model = pyjags.Model(code, data=data, chains=1, adapt=100)\n",
    "    print(\"JAGS model initialized successfully!\")\n",
    "    \n",
    "    # Sample from the model\n",
    "    samples = model.sample(200, vars=['mu', 'sigma'])\n",
    "    print(\"JAGS sampling completed successfully!\")\n",
    "    \n",
    "    # Verify the samples\n",
    "    mu_samples = samples['mu']\n",
    "    sigma_samples = samples['sigma']\n",
    "    print(f\"mu mean: {mu_samples.mean():.4f}\")\n",
    "    print(f\"sigma mean: {sigma_samples.mean():.4f}\")\n",
    "    \n",
    "    print(\"PyJAGS verification completed successfully!\")\n",
    "    sys.exit(0)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyJAGS not found!\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error during PyJAGS verification: {e}\")\n",
    "    sys.exit(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/pyjags_patch.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/pyjags_patch.py\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def patch_pyjags_sources():\n",
    "    print(\"Downloading and patching PyJAGS source...\")\n",
    "    os.system(\"pip download --no-binary :all: pyjags==1.3.8\")\n",
    "    os.system(\"tar -xzf pyjags-1.3.8.tar.gz\")\n",
    "    os.chdir(\"pyjags-1.3.8\")\n",
    "    \n",
    "    # Add cstdint include to all cpp files\n",
    "    for root, dirs, files in os.walk(\"src\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".cpp\") or file.endswith(\".h\"):\n",
    "                filepath = os.path.join(root, file)\n",
    "                with open(filepath, 'r') as f:\n",
    "                    content = f.read()\n",
    "                if \"#include <cstdint>\" not in content:\n",
    "                    with open(filepath, 'w') as f:\n",
    "                        f.write(\"#include <cstdint>\\n\" + content)\n",
    "                    print(f\"Patched {filepath}\")\n",
    "    \n",
    "    # Build and install\n",
    "    os.system(\"pip install --no-build-isolation .\")\n",
    "    print(\"PyJAGS installation complete!\")\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(patch_pyjags_sources()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .pre-commit-config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile .pre-commit-config.yaml\n",
    "\n",
    "repos:\n",
    "  - repo: https://github.com/astral-sh/uv-pre-commit\n",
    "    rev: 0.5.7  # Use the ref you want to point at\n",
    "    hooks:\n",
    "      - id: uv-lock      # keep uv.lock in sync\n",
    "      - id: uv-export    # optional: emit requirements.txt for workshops\n",
    "        args: [--extra=dev, --output-file=requirements-dev.txt]\n",
    "  - repo: https://github.com/pre-commit/pre-commit-hooks\n",
    "    rev: v4.6.0\n",
    "    hooks:\n",
    "      - id: trailing-whitespace\n",
    "      - id: end-of-file-fixer\n",
    "      - id: check-yaml\n",
    "      - id: check-added-large-files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docker-compose.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker-compose.yml\n",
    "# docker-compose.yml\n",
    "services:\n",
    "  datascience:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: .devcontainer/Dockerfile\n",
    "      args:\n",
    "        PYTHON_VER: ${PYTHON_VER:-3.10}\n",
    "        ENV_NAME: ${ENV_NAME:-docker_dev_template}\n",
    "        JAX_PREALLOCATE: ${XLA_PYTHON_CLIENT_PREALLOCATE:-true}\n",
    "        JAX_MEM_FRAC: ${XLA_PYTHON_CLIENT_MEM_FRACTION:-0.95}\n",
    "        JAX_ALLOCATOR: ${XLA_PYTHON_CLIENT_ALLOCATOR:-platform}\n",
    "        JAX_PREALLOC_LIMIT: ${JAX_PREALLOCATION_SIZE_LIMIT_BYTES:-8589934592}\n",
    "\n",
    "    image: \"docker_dev_template-datascience:latest\"\n",
    "    # (Removed explicit container_name to avoid \"already in use\" conflicts.)\n",
    "\n",
    "    # Enhanced restart policy to handle port conflicts\n",
    "    restart: unless-stopped\n",
    "\n",
    "    gpus: all\n",
    "\n",
    "    env_file:\n",
    "      - dev.env\n",
    "      - .devcontainer/.env\n",
    "\n",
    "    environment:\n",
    "      - PYTHON_VER=${PYTHON_VER}\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics,display\n",
    "      - JAX_PLATFORM_NAME=${JAX_PLATFORM_NAME}\n",
    "      - XLA_PYTHON_CLIENT_PREALLOCATE=${XLA_PYTHON_CLIENT_PREALLOCATE}\n",
    "      - XLA_PYTHON_CLIENT_ALLOCATOR=${XLA_PYTHON_CLIENT_ALLOCATOR}\n",
    "      - XLA_PYTHON_CLIENT_MEM_FRACTION=${XLA_PYTHON_CLIENT_MEM_FRACTION}\n",
    "      - XLA_FLAGS=${XLA_FLAGS}\n",
    "      - JAX_DISABLE_JIT=${JAX_DISABLE_JIT}\n",
    "      - JAX_ENABLE_X64=${JAX_ENABLE_X64}\n",
    "      - TF_FORCE_GPU_ALLOW_GROWTH=${TF_FORCE_GPU_ALLOW_GROWTH}\n",
    "      - JAX_PREALLOCATION_SIZE_LIMIT_BYTES=${JAX_PREALLOCATION_SIZE_LIMIT_BYTES}\n",
    "\n",
    "    volumes:\n",
    "      - .:/workspace\n",
    "\n",
    "    ports:\n",
    "      # Enhanced port configuration with fallback options\n",
    "      - \"${HOST_JUPYTER_PORT:-8890}:8888\"\n",
    "      - \"${HOST_TENSORBOARD_PORT:-}:6008\"\n",
    "      - \"${HOST_EXPLAINER_PORT:-}:8050\"\n",
    "      - \"${HOST_STREAMLIT_PORT:-}:8501\"\n",
    "\n",
    "    # Add debugging and conflict prevention\n",
    "    command: >\n",
    "      bash -c \"\n",
    "      echo '=== Docker Dev Template Container Starting ===' &&\n",
    "      echo 'Checking port availability...' &&\n",
    "      if netstat -tulpn 2>/dev/null | grep -q :8888; then\n",
    "        echo 'WARNING: Port 8888 is already in use inside container!'\n",
    "      fi &&\n",
    "      cd /workspace &&\n",
    "      echo 'Python version:' &&\n",
    "      python -c \\\"import jax; print('JAX version:', jax.__version__)\\\" &&\n",
    "      echo \\\"Jupyter will be available at: http://localhost:${HOST_JUPYTER_PORT:-8890}\\\" &&\n",
    "      echo \\\"TensorBoard mapped to \\$(hostname -i):6008 (host port auto-assigned)\\\" &&\n",
    "      echo 'Container ready for dev work. Ports configured:' &&\n",
    "      echo '  - Jupyter: ${HOST_JUPYTER_PORT:-8890} -> 8888' &&\n",
    "      echo '  - TensorBoard: ${HOST_TENSORBOARD_PORT:-auto} -> 6008' &&\n",
    "      echo '  - Explainer: ${HOST_EXPLAINER_PORT:-auto} -> 8050' &&\n",
    "      echo '  - Streamlit: ${HOST_STREAMLIT_PORT:-auto} -> 8501' &&\n",
    "      echo 'To prevent port conflicts, modify HOST_*_PORT variables in dev.env' &&\n",
    "      tail -f /dev/null\n",
    "      \"\n",
    "\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"python\", \"/app/.devcontainer/jags_verify.py\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "      start_period: 60s\n",
    "\n",
    "    # Enhanced labels for better debugging\n",
    "    labels:\n",
    "      - \"com.docker.compose.project=docker_dev_template\"\n",
    "      - \"com.docker.compose.service=datascience\"\n",
    "      - \"description=AI/ML Development Environment with GPU Support\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "%%writefile pyproject.toml\n",
    "[project]\n",
    "name = \"docker_dev_template\"\n",
    "version = \"0.1.0\"\n",
    "description = \"Pytorch and Jax GPU docker container\"\n",
    "authors = [\n",
    "  { name = \"Geoffrey Hadfield\" },\n",
    "]\n",
    "license = \"MIT\"\n",
    "readme = \"README.md\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Restrict to Python 3.10‚Äì3.12 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "requires-python = \">=3.10,<3.13\"\n",
    "\n",
    "dependencies = [\n",
    "  \"pandas>=1.2.0\",\n",
    "  \"numpy>=1.20.0\",\n",
    "  \"matplotlib>=3.4.0\",\n",
    "  \"scikit-learn>=1.4.2\",\n",
    "  \"pymc>=5.0.0\",\n",
    "  \"arviz>=0.14.0\",\n",
    "  \"statsmodels>=0.13.0\",\n",
    "  \"jupyterlab>=3.0.0\",\n",
    "  \"seaborn>=0.11.0\",\n",
    "  \"tabulate>=0.9.0\",\n",
    "  \"shap>=0.40.0\",\n",
    "  \"xgboost>=1.5.0\",\n",
    "  \"lightgbm>=3.3.0\",\n",
    "  \"catboost>=1.0.0\",\n",
    "  \"scipy>=1.7.0\",\n",
    "  \"shapash[report]>=2.3.0\",\n",
    "  \"shapiq>=0.1.0\",\n",
    "  \"explainerdashboard>=0.3.0\",\n",
    "  \"ipywidgets>=8.0.0\",\n",
    "  \"nutpie>=0.7.1\",   # new: nutpie backend for PyMC\n",
    "  \"numpyro>=0.18.0,<1.0.0\",\n",
    "  \"jax==0.6.0\",\n",
    "  \"jaxlib==0.6.0\",\n",
    "  \"pytensor>=2.18.3\",  # explicit version for CUDA support\n",
    "  \"aesara>=2.9.4\",     # alternative backend option\n",
    "  \"tqdm>=4.67.0\",\n",
    "  \"pyarrow>=12.0.0\",\n",
    "]\n",
    "\n",
    "[project.optional-dependencies]\n",
    "dev = [\n",
    "  \"pytest>=7.0.0\",\n",
    "  \"black>=23.0.0\",\n",
    "  \"isort>=5.0.0\",\n",
    "  \"flake8>=5.0.0\",\n",
    "  \"mypy>=1.0.0\",\n",
    "]\n",
    "\n",
    "cuda = [\n",
    "  \"cupy-cuda12x>=12.0.0\",  # For CUDA 12.x\n",
    "]\n",
    "\n",
    "[tool.pytensor]\n",
    "# Default configuration for PyTensor\n",
    "device = \"cuda\"          # Use CUDA by default if available\n",
    "floatX = \"float32\"       # Use float32 by default for better CUDA performance\n",
    "allow_gc = true          # Allow garbage collection\n",
    "optimizer = \"fast_run\"   # Fast run optimization by default\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Makefile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Makefile\n",
    "\n",
    "##@ Development\n",
    ".PHONY: help debug-interpreter monitor-resources check-health clean-rebuild\n",
    "\n",
    "help: ## Display available commands\n",
    "\t@awk 'BEGIN {FS = \":.*##\"; printf \"\\nUsage:\\n  make \\033[36m<target>\\033[0m\\n\"} /^[a-zA-Z_0-9-]+:.*?##/ { printf \"  \\033[36m%-15s\\033[0m %s\\n\", $$1, $$2 } /^##@/ { printf \"\\n\\033[1m%s\\033[0m\\n\", substr($$0, 5) } ' $(MAKEFILE_LIST)\n",
    "\n",
    "##@ Debugging\n",
    "debug-interpreter: ## Run systematic interpreter debugging (¬ß7 from guide)\n",
    "\t@echo \"üîç Running Python interpreter diagnostics...\"\n",
    "\t@./.devcontainer/debug_interpreter.sh\n",
    "\n",
    "monitor-resources: ## Monitor container resources in real-time\n",
    "\t@echo \"üìä Starting resource monitor (Ctrl+C to stop)...\"\n",
    "\t@./.devcontainer/monitor_resources.sh\n",
    "\n",
    "check-health: ## Check container health status\n",
    "\t@echo \"üè• Container health check...\"\n",
    "\t@docker ps --format 'table {{.Names}}\\t{{.Status}}\\t{{.RunningFor}}'\n",
    "\t@echo \"\"\n",
    "\t@CONTAINER_ID=$$(docker ps --filter \"ancestor=docker_dev_template-datascience:latest\" --format \"{{.ID}}\" | head -1); if [[ -n \"$$CONTAINER_ID\" ]]; then echo \"Restart count: $$(docker inspect -f '{{.State.RestartCount}}' $$CONTAINER_ID)\"; else echo \"No container found\"; fi\n",
    "\n",
    "##@ Container Management  \n",
    "clean-rebuild: ## Clean rebuild of container (¬ß5 from guide)\n",
    "\t@echo \"üßπ Clean rebuilding container...\"\n",
    "\tdocker compose build --no-cache --progress=plain\n",
    "\n",
    "##@ Quick Tests\n",
    "test-python: ## Test Python environment inside container\n",
    "\t@echo \"üêç Testing Python environment...\"\n",
    "\t@docker compose exec datascience bash -c \"echo 'PATH=$$PATH' && which python && python -V && uv pip check\"\n",
    "\n",
    "test-imports: ## Test critical imports (JAX, PyTorch)\n",
    "\t@echo \"üì¶ Testing critical imports...\"\n",
    "\t@docker compose exec datascience python -c \"import jax, torch; print('‚úÖ JAX:', jax.__version__, '‚úÖ PyTorch:', torch.__version__)\"\n",
    "\n",
    "##@ VS Code Integration\n",
    "show-logs: ## Show VS Code dev container logs (requires container to be running)\n",
    "\t@echo \"üí° To view VS Code logs:\"\n",
    "\t@echo \"  1. Press F1 in VS Code\"\n",
    "\t@echo \"  2. Run: 'Remote-Containers: Show Log'\"\n",
    "\t@echo \"  3. Check Output ‚Üí Python and Output ‚Üí Jupyter panels\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tasks.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tasks.py\n",
    "# tasks.py  ‚îÄ‚îÄ invoke ‚â•2.2\n",
    "from invoke import task, Context\n",
    "import os, shutil, sys, pathlib, textwrap, subprocess\n",
    "\n",
    "BASE_ENV = pathlib.Path(__file__).parent\n",
    "\n",
    "def _compose(c: Context, cmd: str, name: str, rebuild=False):\n",
    "    # Propagate ENV_NAME into docker-compose *and* docker build-args\n",
    "    env = dict(os.environ, ENV_NAME=name)\n",
    "    flags = [\"--build\", \"--pull\"] if rebuild else []\n",
    "    c.run(f\"docker compose {' '.join(flags)} {cmd}\", env=env, pty=True)\n",
    "\n",
    "@task(help={'name': \"Project/venv name (defaults to folder name)\"},\n",
    "      iterable=['extra'])\n",
    "def up(c, name=None, rebuild=False, detach=True, extra=None):\n",
    "    \"\"\"Build (optionally --rebuild) & start the container\"\"\"\n",
    "    name = name or BASE_ENV.name\n",
    "    _compose(c, \"up -d\" if detach else \"up\", name, rebuild)\n",
    "\n",
    "@task\n",
    "def stop(c):\n",
    "    \"\"\"Stop and remove dev container (keeps volumes)\"\"\"\n",
    "    c.run(\"docker compose down\")\n",
    "\n",
    "@task\n",
    "def shell(c, name=None):\n",
    "    \"\"\"Open an interactive shell in the running container\"\"\"\n",
    "    name = name or BASE_ENV.name\n",
    "    cid = c.run(\"docker compose ps -q datascience\", hide=True).stdout.strip()\n",
    "    c.run(f\"docker exec -it {cid} bash\", env={\"ENV_NAME\": name})\n",
    "\n",
    "@task\n",
    "def clean(c):\n",
    "    \"\"\"Prune stopped containers + dangling images\"\"\"\n",
    "    c.run(\"docker system prune -f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/diagnose_devcontainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tests/diagnose_devcontainer.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Comprehensive diagnostic script for dev container issues.\n",
    "Run this inside the container to diagnose Python environment and remote extension problems.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def run_command(cmd, description):\n",
    "    \"\"\"Run a command and return its output.\"\"\"\n",
    "    print(f\"\\nüîç {description}\")\n",
    "    print(\"=\" * 60)\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {result.stdout.strip()}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Error (code {result.returncode}): {result.stderr.strip()}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_paths_and_environment():\n",
    "    \"\"\"Check Python paths and environment variables.\"\"\"\n",
    "    print(\"\\nüêç PYTHON ENVIRONMENT DIAGNOSTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Python executable and version\n",
    "    print(f\"Python executable: {sys.executable}\")\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    print(f\"Python path: {sys.path[:3]}...\")  # First few paths\n",
    "    \n",
    "    # Environment variables\n",
    "    print(f\"\\nVIRTUAL_ENV: {os.environ.get('VIRTUAL_ENV', 'Not set')}\")\n",
    "    print(f\"PATH (first 3): {':'.join(os.environ.get('PATH', '').split(':')[:3])}\")\n",
    "    \n",
    "    # Virtual environment validation\n",
    "    venv_path = Path('/app/.venv')\n",
    "    if venv_path.exists():\n",
    "        print(f\"‚úÖ Virtual environment exists at {venv_path}\")\n",
    "        print(f\"   - bin directory: {list(venv_path.glob('bin/python*'))}\")\n",
    "        print(f\"   - site-packages: {(venv_path / 'lib/python3.10/site-packages').exists()}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Virtual environment NOT found at {venv_path}\")\n",
    "\n",
    "\n",
    "def check_key_packages():\n",
    "    \"\"\"Check if key packages are importable.\"\"\"\n",
    "    print(\"\\nüì¶ PACKAGE IMPORT TESTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    packages = [\n",
    "        'jax', 'torch', 'numpy', 'pandas', 'matplotlib', \n",
    "        'jupyterlab', 'streamlit', 'sklearn'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            if package == 'sklearn':\n",
    "                import sklearn\n",
    "                version = sklearn.__version__\n",
    "            else:\n",
    "                module = __import__(package)\n",
    "                version = getattr(module, '__version__', 'unknown')\n",
    "            print(f\"‚úÖ {package}: {version}\")\n",
    "        except ImportError as e:\n",
    "            print(f\"‚ùå {package}: Import failed - {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  {package}: {e}\")\n",
    "\n",
    "\n",
    "def check_gpu_environment():\n",
    "    \"\"\"Check GPU-related environment variables.\"\"\"\n",
    "    print(\"\\nüéÆ GPU ENVIRONMENT VARIABLES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    gpu_env_vars = [\n",
    "        'XLA_PYTHON_CLIENT_PREALLOCATE',\n",
    "        'XLA_PYTHON_CLIENT_ALLOCATOR', \n",
    "        'XLA_PYTHON_CLIENT_MEM_FRACTION',\n",
    "        'JAX_PLATFORM_NAME',\n",
    "        'XLA_FLAGS',\n",
    "        'JAX_DISABLE_JIT',\n",
    "        'JAX_ENABLE_X64',\n",
    "        'JAX_PREALLOCATION_SIZE_LIMIT_BYTES',\n",
    "        'TF_FORCE_GPU_ALLOW_GROWTH',\n",
    "        'NVIDIA_VISIBLE_DEVICES',\n",
    "        'NVIDIA_DRIVER_CAPABILITIES'\n",
    "    ]\n",
    "    \n",
    "    for var in gpu_env_vars:\n",
    "        value = os.environ.get(var, 'Not set')\n",
    "        print(f\"   {var}: {value}\")\n",
    "\n",
    "\n",
    "def check_gpu_support():\n",
    "    \"\"\"Check GPU support for JAX and PyTorch with enhanced diagnostics.\"\"\"\n",
    "    print(\"\\nüéÆ ENHANCED GPU SUPPORT CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # JAX GPU check with detailed info\n",
    "    try:\n",
    "        import jax\n",
    "        print(f\"JAX version: {jax.__version__}\")\n",
    "        \n",
    "        devices = jax.devices()\n",
    "        print(f\"JAX devices: {devices}\")\n",
    "        \n",
    "        if devices:\n",
    "            for i, device in enumerate(devices):\n",
    "                print(f\"   Device {i}: {device}\")\n",
    "                \n",
    "        if any('gpu' in str(device).lower() or 'cuda' in str(device).lower() for device in devices):\n",
    "            print(\"‚úÖ JAX GPU/CUDA support detected!\")\n",
    "            \n",
    "            # Test a simple computation\n",
    "            try:\n",
    "                import jax.numpy as jnp\n",
    "                x = jnp.ones((1000, 1000))\n",
    "                result = jnp.sum(x)\n",
    "                print(f\"   ‚úÖ JAX GPU computation test passed: sum = {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  JAX GPU computation test failed: {e}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  JAX GPU support not detected\")\n",
    "            print(\"   This might be due to GPU architecture compatibility\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå JAX GPU check failed: {e}\")\n",
    "    \n",
    "    # PyTorch GPU check with enhanced info\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "        print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            device_count = torch.cuda.device_count()\n",
    "            print(f\"‚úÖ PyTorch CUDA device count: {device_count}\")\n",
    "            \n",
    "            for i in range(device_count):\n",
    "                try:\n",
    "                    device_name = torch.cuda.get_device_name(i)\n",
    "                    memory_total = torch.cuda.get_device_properties(i).total_memory\n",
    "                    print(f\"   Device {i}: {device_name}\")\n",
    "                    print(f\"     Total memory: {memory_total / (1024**3):.1f} GB\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   Device {i}: Error getting info - {e}\")\n",
    "            \n",
    "            # Test a simple computation\n",
    "            try:\n",
    "                device = torch.device('cuda:0')\n",
    "                x = torch.ones(1000, 1000, device=device)\n",
    "                result = torch.sum(x)\n",
    "                print(f\"   ‚úÖ PyTorch GPU computation test passed: sum = {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  PyTorch GPU computation test failed: {e}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  PyTorch CUDA not available\")\n",
    "            print(\"   Check CUDA installation and GPU compatibility\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå PyTorch GPU check failed: {e}\")\n",
    "\n",
    "\n",
    "def check_workspace_mount():\n",
    "    \"\"\"Check if workspace is properly mounted.\"\"\"\n",
    "    print(\"\\nüìÅ WORKSPACE MOUNT CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    workspace_path = Path('/workspace')\n",
    "    if workspace_path.exists():\n",
    "        print(f\"‚úÖ /workspace directory exists\")\n",
    "        try:\n",
    "            contents = list(workspace_path.iterdir())[:10]  # First 10 items\n",
    "            print(f\"   Contents (first 10): {[p.name for p in contents]}\")\n",
    "            \n",
    "            # Check for specific expected files\n",
    "            expected_files = ['.devcontainer', 'pyproject.toml', 'docker-compose.yml']\n",
    "            for file in expected_files:\n",
    "                if (workspace_path / file).exists():\n",
    "                    print(f\"   ‚úÖ Found: {file}\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Missing: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error reading workspace: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ùå /workspace directory does not exist\")\n",
    "\n",
    "\n",
    "def check_dev_container_config():\n",
    "    \"\"\"Check dev container configuration.\"\"\"\n",
    "    print(\"\\n‚öôÔ∏è  DEV CONTAINER CONFIG CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    config_path = Path('/workspace/.devcontainer/devcontainer.json')\n",
    "    if config_path.exists():\n",
    "        print(\"‚úÖ devcontainer.json found\")\n",
    "        try:\n",
    "            with open(config_path) as f:\n",
    "                config = json.load(f)\n",
    "            print(f\"   Name: {config.get('name', 'Not specified')}\")\n",
    "            print(f\"   Python path: {config.get('customizations', {}).get('vscode', {}).get('settings', {}).get('python.defaultInterpreterPath', 'Not specified')}\")\n",
    "            print(f\"   Workspace folder: {config.get('workspaceFolder', 'Not specified')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error reading config: {e}\")\n",
    "    else:\n",
    "        print(\"‚ùå devcontainer.json not found\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run all diagnostic checks.\"\"\"\n",
    "    print(\"üîç DEV CONTAINER COMPREHENSIVE DIAGNOSTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Running from: {os.getcwd()}\")\n",
    "    print(f\"User: {os.getenv('USER', 'unknown')}\")\n",
    "    print(f\"Container hostname: {os.getenv('HOSTNAME', 'unknown')}\")\n",
    "    \n",
    "    # System commands\n",
    "    run_command(\"uv --version\", \"UV Version\")\n",
    "    run_command(\"which python\", \"Python Location\")\n",
    "    run_command(\"ls -la /app/.venv/\", \"Virtual Environment Contents\")\n",
    "    run_command(\"mount | grep workspace\", \"Workspace Mount Status\")\n",
    "    run_command(\"nvidia-smi\", \"NVIDIA GPU Status\")\n",
    "    \n",
    "    # Python-based checks\n",
    "    check_paths_and_environment()\n",
    "    check_gpu_environment()\n",
    "    check_key_packages()\n",
    "    check_gpu_support()\n",
    "    check_workspace_mount()\n",
    "    check_dev_container_config()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üéØ SUMMARY & RECOMMENDATIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"If you see issues:\")\n",
    "    print(\"1. ‚ùå Virtual env missing ‚Üí Check Dockerfile uv sync step\")\n",
    "    print(\"2. ‚ùå Workspace not mounted ‚Üí Check devcontainer.json mounts config\")\n",
    "    print(\"3. ‚ùå Packages missing ‚Üí Check uv.lock and pip install steps\")\n",
    "    print(\"4. ‚ö†Ô∏è  GPU not detected ‚Üí Check docker-compose.yml gpu settings\")\n",
    "    print(\"5. üîß For VS Code issues ‚Üí Check python.defaultInterpreterPath setting\")\n",
    "    print(\"6. üéÆ For GPU issues ‚Üí Check NVIDIA drivers and CUDA compatibility\")\n",
    "    print(\"\\n‚úÖ All checks passed = ready for development!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/test_pytorch_jax_gpu.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tests/test_pytorch_jax_gpu.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Test script to verify that PyTorch and JAX can access the GPU,\n",
    "and that PyJAGS is working correctly.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "def test_pytorch_gpu():\n",
    "    \"\"\"Test PyTorch GPU availability and basic operations.\"\"\"\n",
    "    print(\"\\n=== Testing PyTorch GPU ===\")\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        \n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"‚ùå PyTorch CUDA not available!\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "        \n",
    "        # Run a simple test computation\n",
    "        x = torch.rand(1000, 1000).cuda()\n",
    "        y = torch.rand(1000, 1000).cuda()\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "        start.record()\n",
    "        z = torch.matmul(x, y)\n",
    "        end.record()\n",
    "        \n",
    "        # Wait for GPU computation to finish\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Matrix multiplication time: {start.elapsed_time(end):.2f} ms\")\n",
    "        print(f\"Result shape: {z.shape}\")\n",
    "        print(\"‚úÖ PyTorch GPU test passed!\")\n",
    "        return True\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"‚ùå PyTorch not found!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during PyTorch GPU test: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_jax_gpu():\n",
    "    \"\"\"Test JAX GPU availability and basic operations.\"\"\"\n",
    "    print(\"\\n=== Testing JAX GPU ===\")\n",
    "    try:\n",
    "        import jax\n",
    "        import jax.numpy as jnp\n",
    "        \n",
    "        print(f\"JAX version: {jax.__version__}\")\n",
    "        \n",
    "        # Force GPU platform\n",
    "        jax.config.update('jax_platform_name', 'gpu')\n",
    "        \n",
    "        # Get device count and details\n",
    "        devices = jax.devices()\n",
    "        device_count = len(devices)\n",
    "        print(f\"Available devices: {device_count}\")\n",
    "        \n",
    "        for i, device in enumerate(devices):\n",
    "            print(f\"Device {i}: {device}\")\n",
    "        \n",
    "        if device_count == 0 or 'cuda' not in str(devices[0]).lower():\n",
    "            print(\"‚ùå No GPU devices found by JAX!\")\n",
    "            return False\n",
    "        \n",
    "        # Check CUDA configuration\n",
    "        jit_info = jax.config.values\n",
    "        print(f\"JAX configuration: {jit_info}\")\n",
    "        \n",
    "        # Run a simple GPU computation\n",
    "        print(\"Running a test computation on GPU...\")\n",
    "        try:\n",
    "            x = jnp.ones((1000, 1000))\n",
    "            y = jnp.ones((1000, 1000))\n",
    "            \n",
    "            # Use JIT compilation for better performance\n",
    "            @jax.jit\n",
    "            def matmul(a, b):\n",
    "                return jnp.matmul(a, b)\n",
    "            \n",
    "            result = matmul(x, y)\n",
    "            print(f\"Result shape: {result.shape}\")\n",
    "            \n",
    "            print(\"‚úÖ JAX GPU test passed!\")\n",
    "            return True\n",
    "        except RuntimeError as e:\n",
    "            if \"ptxas too old\" in str(e):\n",
    "                print(f\"‚ö†Ô∏è JAX GPU detected but CUDA compatibility issue: {e}\")\n",
    "                print(\"‚ö†Ô∏è JAX can see the GPU but there's a CUDA version compatibility issue.\")\n",
    "                print(\"‚ö†Ô∏è This is considered a partial success since the GPU is detected.\")\n",
    "                return True\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"‚ùå JAX not found!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during JAX GPU test: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_pyjags():\n",
    "    \"\"\"Test PyJAGS installation and basic functionality.\"\"\"\n",
    "    print(\"\\n=== Testing PyJAGS ===\")\n",
    "    try:\n",
    "        import pyjags\n",
    "        print(f\"PyJAGS version: {pyjags.__version__}\")\n",
    "        \n",
    "        # Create a simple model to verify that PyJAGS works\n",
    "        code = \"\"\"\n",
    "        model {\n",
    "            # Likelihood\n",
    "            y ~ dnorm(mu, 1/sigma^2)\n",
    "            \n",
    "            # Priors\n",
    "            mu ~ dnorm(0, 0.001)\n",
    "            sigma ~ dunif(0, 100)\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sample data\n",
    "        data = {'y': 0.5}\n",
    "        \n",
    "        # Initialize model with data\n",
    "        model = pyjags.Model(code, data=data, chains=1, adapt=100)\n",
    "        print(\"JAGS model initialized successfully!\")\n",
    "        \n",
    "        # Sample from the model\n",
    "        samples = model.sample(200, vars=['mu', 'sigma'])\n",
    "        print(\"JAGS sampling completed successfully!\")\n",
    "        \n",
    "        # Verify the samples\n",
    "        mu_samples = samples['mu']\n",
    "        sigma_samples = samples['sigma']\n",
    "        print(f\"mu mean: {mu_samples.mean():.4f}\")\n",
    "        print(f\"sigma mean: {sigma_samples.mean():.4f}\")\n",
    "        \n",
    "        print(\"‚úÖ PyJAGS test passed!\")\n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ùå PyJAGS not found!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during PyJAGS test: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running GPU and PyJAGS verification tests...\")\n",
    "    \n",
    "    pytorch_success = test_pytorch_gpu()\n",
    "    jax_success = test_jax_gpu()\n",
    "    pyjags_success = test_pyjags()\n",
    "    \n",
    "    print(\"\\n=== Test Summary ===\")\n",
    "    print(f\"PyTorch GPU: {'‚úÖ PASS' if pytorch_success else '‚ùå FAIL'}\")\n",
    "    print(f\"JAX GPU: {'‚úÖ PASS' if jax_success else '‚ùå FAIL'}\")\n",
    "    print(f\"PyJAGS: {'‚úÖ PASS' if pyjags_success else '‚ùå FAIL'}\")\n",
    "    \n",
    "    if pytorch_success and jax_success and pyjags_success:\n",
    "        print(\"\\nüéâ All tests passed! The container is working correctly.\")\n",
    "        sys.exit(0)\n",
    "    else:\n",
    "        print(\"\\n‚ùå Some tests failed. Please check the output for details.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

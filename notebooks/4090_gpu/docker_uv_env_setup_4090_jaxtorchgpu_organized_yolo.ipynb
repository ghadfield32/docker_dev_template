{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Streamlined Docker Development Environment Setup\n",
        "\n",
        "This notebook sets up a streamlined Docker-based development environment with:\n",
        "- PyTorch with GPU support (official base image)\n",
        "- UV package manager for fast dependency resolution\n",
        "- VS Code devcontainer integration\n",
        "- Simplified configuration and testing\n",
        "\n",
        "**Key improvements over previous setup:**\n",
        "- ~40% faster build time using official PyTorch base image\n",
        "- Simplified environment configuration\n",
        "- PyTorch/Jax-focused GPU acceleration\n",
        "\n",
        "goal: have a container that can utilize jax and pytorch on gpu on a nvidia 4090 gpu. Let's ensure that each of the requirements are set and that once in the container it have the uv environemnt set up as well for development. It should show errors and the root of the problem otherwise, so have plenty of healthchecks to ensure everything is going correctly.  \n",
        "\n",
        "├── docker-compose.yml (for docker composition)\n",
        "├── pyproject.toml ( for local development)\n",
        "└── .devcontainer/\n",
        "    ├── Dockerfile (for docker build)\n",
        "    ├── devcontainer.json\n",
        "    ├── .env.template\n",
        "    ├── .dockerignore\n",
        "    ├── validate_gpu.py\n",
        "    └── tests/\n",
        "        ├── test_summary.py\n",
        "        ├── test_pytorch.py\n",
        "        ├── test_pytorch_gpu.py\n",
        "        └── test_uv.py\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "1. [Environment Files](#environment-files)\n",
        "2. [DevContainer Configuration](#devcontainer-configuration)\n",
        "3. [Docker Setup](#docker-setup)\n",
        "4. [Testing & Diagnostics](#testing--diagnostics)\n",
        "5. [Verification](#verification)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Environment Files\n",
        "\n",
        "First, let's create the necessary environment configuration files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/.env.template\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/.env.template\n",
        "# =============================================================================\n",
        "# CONTAINER CONFIGURATION - Primary Settings\n",
        "# =============================================================================\n",
        "ENV_NAME=docker_dev_template\n",
        "\n",
        "# =============================================================================\n",
        "# DOCKER & CUDA CONFIGURATION  \n",
        "# =============================================================================\n",
        "CUDA_TAG=12.8.0\n",
        "DOCKER_BUILDKIT=1\n",
        "\n",
        "# =============================================================================\n",
        "# HOST PORT MAPPINGS\n",
        "# =============================================================================\n",
        "HOST_JUPYTER_PORT=8895\n",
        "HOST_TENSORBOARD_PORT=6005\n",
        "HOST_EXPLAINER_PORT=8055\n",
        "HOST_STREAMLIT_PORT=8505\n",
        "HOST_MLFLOW_PORT=5005\n",
        "\n",
        "# =============================================================================\n",
        "# PYTHON & RUNTIME CONFIGURATION\n",
        "# =============================================================================\n",
        "PYTHON_VER=3.10\n",
        "\n",
        "# =============================================================================\n",
        "# GPU MEMORY MANAGEMENT (PyTorch + JAX Only)\n",
        "# =============================================================================\n",
        "JAX_PLATFORM_NAME=\n",
        "\n",
        "# Optimized for RTX 4090 - PyTorch + JAX memory sharing\n",
        "XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "XLA_PYTHON_CLIENT_ALLOCATOR=platform  \n",
        "XLA_PYTHON_CLIENT_MEM_FRACTION=0.35\n",
        "XLA_FLAGS=--xla_force_host_platform_device_count=1\n",
        "JAX_DISABLE_JIT=false\n",
        "JAX_ENABLE_X64=false\n",
        "JAX_PREALLOCATION_SIZE_LIMIT_BYTES=10737418240\n",
        "\n",
        "# PyTorch memory management for RTX 4090\n",
        "PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True,roundup_power2_divisions:16\n",
        "\n",
        "# =============================================================================\n",
        "# JUPYTER CONFIGURATION\n",
        "# =============================================================================\n",
        "JUPYTER_TOKEN=jupyter\n",
        "\n",
        "# =============================================================================\n",
        "# UV PACKAGE MANAGER CONFIGURATION\n",
        "# =============================================================================\n",
        "UV_PROJECT_ENVIRONMENT=/app/.venv\n",
        "\n",
        "# =============================================================================\n",
        "# COMPUTER VISION CONFIGURATION - SIMPLIFIED\n",
        "# =============================================================================\n",
        "# Roboflow API Key - Get from https://app.roboflow.com/settings/api\n",
        "# IMPORTANT: Replace the placeholder below with your actual API key\n",
        "ROBOFLOW_API_KEY=your_roboflow_api_key_here\n",
        "\n",
        "# Computer Vision Environment Variables\n",
        "YOLO_VERBOSE=false\n",
        "OPENCV_LOG_LEVEL=ERROR\n",
        "\n",
        "# Display Configuration for GUI Support\n",
        "DISPLAY=:0\n",
        "QT_X11_NO_MITSHM=1\n",
        "LIBGL_ALWAYS_INDIRECT=1\n",
        "\n",
        "# Video Processing Directories\n",
        "VIDEO_INPUT_DIR=/workspace/videos/input\n",
        "VIDEO_OUTPUT_DIR=/workspace/videos/output\n",
        "\n",
        "# =============================================================================\n",
        "# KAGGLE AUTHENTICATION (Optional)\n",
        "# =============================================================================\n",
        "KAGGLE_USERNAME=geoffhadfield \n",
        "KAGGLE_KEY=your_api_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/.dockerignore\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/.dockerignore\n",
        "# Reduce Docker build context\n",
        ".git\n",
        ".gitignore\n",
        ".gitattributes\n",
        ".gitmodules\n",
        ".vscode\n",
        ".idea\n",
        "*.swp\n",
        "*.swo\n",
        "*~\n",
        ".DS_Store\n",
        "Thumbs.db\n",
        "__pycache__\n",
        "*.pyc\n",
        "*.pyo\n",
        "*.pyd\n",
        ".Python\n",
        "*.so\n",
        ".coverage*\n",
        ".cache\n",
        ".pytest_cache\n",
        ".mypy_cache\n",
        ".tox\n",
        "pip-log.txt\n",
        "pip-delete-this-directory.txt\n",
        "env\n",
        "venv\n",
        "ENV\n",
        "env.bak\n",
        "venv.bak\n",
        ".ipynb_checkpoints\n",
        "# Large data (adjust as needed)\n",
        "data/raw\n",
        "data/external\n",
        "*.csv\n",
        "*.parquet\n",
        "*.h5\n",
        "*.hdf5\n",
        "# Models\n",
        "*.pt\n",
        "*.pth\n",
        "*.pkl\n",
        "*.joblib\n",
        "models/\n",
        "# Logs and temps\n",
        "*.log\n",
        "logs/\n",
        "*.tmp\n",
        "*.temp\n",
        ".tmp\n",
        "temp/\n",
        "# Build artifacts\n",
        "build/\n",
        "dist/\n",
        "*.egg-info/\n",
        ".eggs/\n",
        "# Node\n",
        "node_modules\n",
        "npm-debug.log*\n",
        "yarn-*.log*\n",
        ".npm\n",
        ".eslintcache\n",
        ".node_repl_history\n",
        "*.tgz\n",
        "*.tar.gz\n",
        "# Archives\n",
        "*.zip\n",
        "*.tar\n",
        "*.tar.bz2\n",
        "*.rar\n",
        "*.7z\n",
        "# Docs (opt‑in if needed)\n",
        "docs/\n",
        "*.md\n",
        "README*\n",
        "LICENSE*\n",
        "CHANGELOG*\n",
        "# Tests (opt‑in if needed)\n",
        "tests/\n",
        "test_*\n",
        "*_test.py\n",
        "# CI\n",
        ".github/\n",
        ".gitlab-ci.yml\n",
        ".travis.yml\n",
        ".circleci/\n",
        "azure-pipelines.yml\n",
        "# Env\n",
        ".env\n",
        ".env.local\n",
        ".env.*.local\n",
        ".editorconfig\n",
        ".prettierrc*\n",
        ".eslintrc*\n",
        "# Universal junk (de‑duped)\n",
        "*.py[cod]"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## DevContainer Configuration\n",
        "\n",
        "Setting up the VS Code devcontainer configuration files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/devcontainer.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/devcontainer.json\n",
        "{\n",
        "  \"name\": \"docker_dev_template_rtx4090\",\n",
        "  \"dockerComposeFile\": \"../docker-compose.yml\",\n",
        "  \"service\": \"datascience\",\n",
        "  \"workspaceFolder\": \"/workspace\",\n",
        "  \"shutdownAction\": \"stopCompose\",\n",
        "\n",
        "  \"overrideCommand\": false,\n",
        "  \"containerEnv\": {\n",
        "    \"CONTAINER_WORKSPACE_FOLDER\": \"/workspace\",\n",
        "    \"UV_PROJECT_ENVIRONMENT\": \"/app/.venv\",\n",
        "    \"VIRTUAL_ENV\": \"/app/.venv\",\n",
        "    \"PYTHONPATH\": \"/workspace\",\n",
        "    \"TERM\": \"xterm-256color\"\n",
        "  },\n",
        "\n",
        "  \"runArgs\": [\n",
        "    \"--gpus\", \"all\",\n",
        "    \"--name\", \"${localEnv:ENV_NAME:docker_dev_template}_datascience\"\n",
        "  ],\n",
        "\n",
        "  \"customizations\": {\n",
        "    \"vscode\": {\n",
        "      \"settings\": {\n",
        "        \"python.defaultInterpreterPath\": \"/app/.venv/bin/python\",\n",
        "        \"python.pythonPath\": \"/app/.venv/bin/python\",\n",
        "        \"python.terminal.activateEnvironment\": true,\n",
        "        \"python.terminal.activateEnvInCurrentTerminal\": true,\n",
        "        \"terminal.integrated.defaultProfile.linux\": \"bash\",\n",
        "        \"terminal.integrated.profiles.linux\": {\n",
        "          \"bash\": {\n",
        "            \"path\": \"/bin/bash\",\n",
        "            \"args\": [\"-l\"],\n",
        "            \"env\": {\n",
        "              \"VIRTUAL_ENV\": \"/app/.venv\",\n",
        "              \"PATH\": \"/app/.venv/bin:${env:PATH}\",\n",
        "              \"UV_PROJECT_ENVIRONMENT\": \"/app/.venv\",\n",
        "              \"PYTHONPATH\": \"/workspace\"\n",
        "            }\n",
        "          }\n",
        "        },\n",
        "        \"jupyter.notebookFileRoot\": \"/workspace\",\n",
        "        \"jupyter.kernels.filter\": [\n",
        "          {\n",
        "            \"path\": \"/app/.venv/bin/python\",\n",
        "            \"type\": \"pythonEnvironment\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      \"extensions\": [\n",
        "        \"ms-python.python\",\n",
        "        \"ms-toolsai.jupyter\",\n",
        "        \"ms-azuretools.vscode-docker\",\n",
        "        \"ms-python.flake8\",\n",
        "        \"ms-python.black-formatter\"\n",
        "      ]\n",
        "    }\n",
        "  },\n",
        "\n",
        "  \"onCreateCommand\": [\n",
        "    \"bash\", \"-lc\",\n",
        "    \"echo 'onCreate: validating environment'; ls -la /app/.venv/bin/; which python || echo 'python not found in PATH'\"\n",
        "  ],\n",
        "\n",
        "  \"postCreateCommand\": [\n",
        "    \"bash\", \"-lc\",\n",
        "    \"set -e; source /app/.venv/bin/activate; python -c 'import sys; print(f\\\"python: {sys.executable}\\\")'; uv pip install -U ipykernel jupyter-client -q; python -m ipykernel install --user --name='uv_docker_dev_template' --display-name='Python (UV Environment)'; jupyter kernelspec list; python /app/tests/test_summary.py\"\n",
        "  ],\n",
        "\n",
        "  \"postStartCommand\": [\n",
        "    \"bash\", \"-lc\",\n",
        "    \"source /app/.venv/bin/activate; python --version; python -c 'import torch; print(f\\\"pytorch cuda: {torch.cuda.is_available()}\\\")' || echo 'pytorch test failed'; python /app/validate_gpu.py --quick || echo 'gpu validation completed with warnings'\"\n",
        "  ],\n",
        "\n",
        "  \"features\": {},\n",
        "  \"forwardPorts\": [8888, 6008, 8050, 8501, 5000],\n",
        "  \"portsAttributes\": {\n",
        "    \"8888\": { \"label\": \"Jupyter Lab\", \"onAutoForward\": \"notify\" },\n",
        "    \"6008\": { \"label\": \"TensorBoard\", \"onAutoForward\": \"silent\" },\n",
        "    \"8050\": { \"label\": \"Explainer Dashboard\", \"onAutoForward\": \"silent\" },\n",
        "    \"8501\": { \"label\": \"Streamlit\", \"onAutoForward\": \"silent\" },\n",
        "    \"5000\": { \"label\": \"MLflow\", \"onAutoForward\": \"silent\" }\n",
        "  },\n",
        "\n",
        "  \"mounts\": [\n",
        "    \"source=docker_dev_template_uv_cache,target=/root/.cache/uv,type=volume\"\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/Dockerfile\n",
        "# Dockerfile: RTX 4090 devcontainer with UV, JAX, and PyTorch (CUDA 12.x)\n",
        "\n",
        "ARG CUDA_TAG=12.4.0\n",
        "FROM nvidia/cuda:${CUDA_TAG}-devel-ubuntu22.04\n",
        "\n",
        "ARG PYTHON_VER=3.10\n",
        "ARG ENV_NAME=docker_dev_template\n",
        "ENV DEBIAN_FRONTEND=noninteractive\n",
        "\n",
        "# System dependencies with Computer Vision additions\n",
        "RUN --mount=type=cache,id=apt-cache,target=/var/cache/apt,sharing=locked \\\n",
        "    --mount=type=cache,id=apt-lists,target=/var/lib/apt/lists,sharing=locked \\\n",
        "    apt-get update && apt-get install -y --no-install-recommends \\\n",
        "        bash curl ca-certificates git procps htop \\\n",
        "        python3 python3-venv python3-pip python3-dev \\\n",
        "        build-essential cmake pkg-config \\\n",
        "        libjemalloc2 libjemalloc-dev \\\n",
        "        iproute2 net-tools lsof wget \\\n",
        "        # Computer Vision dependencies\n",
        "        ffmpeg \\\n",
        "        libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1 \\\n",
        "        libgstreamer1.0-0 libgstreamer-plugins-base1.0-0 \\\n",
        "        libgtk-3-0 libgtk-3-dev \\\n",
        "        # X11 support for GUI applications\n",
        "        x11-apps xauth xvfb \\\n",
        "        # Video codec libraries\n",
        "        libavcodec-dev libavformat-dev libswscale-dev \\\n",
        "        libv4l-dev libxvidcore-dev libx264-dev \\\n",
        "        # Image format libraries\n",
        "        libjpeg-dev libpng-dev libtiff-dev \\\n",
        "        # OpenGL support for visualization\n",
        "        libgl1-mesa-glx libglu1-mesa-dev \\\n",
        "    && apt-get clean && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# UV package manager\n",
        "COPY --from=ghcr.io/astral-sh/uv:0.7.12 /uv /uvx /bin/\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "# Create venv managed by UV\n",
        "RUN uv venv .venv --python \"${PYTHON_VER}\" --prompt \"${ENV_NAME}\"\n",
        "\n",
        "ENV VIRTUAL_ENV=/app/.venv \\\n",
        "    PATH=\"/app/.venv/bin:${PATH}\" \\\n",
        "    UV_PROJECT_ENVIRONMENT=/app/.venv \\\n",
        "    PYTHONPATH=\"/workspace\"\n",
        "\n",
        "# Memory and allocator settings\n",
        "ENV LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2 \\\n",
        "    MALLOC_ARENA_MAX=2 \\\n",
        "    MALLOC_TCACHE_MAX=0 \\\n",
        "    PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
        "\n",
        "# GPU‑relevant environment\n",
        "ENV XLA_PYTHON_CLIENT_PREALLOCATE=false \\\n",
        "    XLA_PYTHON_CLIENT_MEM_FRACTION=0.4 \\\n",
        "    XLA_PYTHON_CLIENT_ALLOCATOR=platform \\\n",
        "    PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True \\\n",
        "    JAX_PREALLOCATION_SIZE_LIMIT_BYTES=17179869184\n",
        "\n",
        "# Computer Vision specific environment variables\n",
        "ENV OPENCV_VIDEOIO_PRIORITY_GSTREAMER=0 \\\n",
        "    QT_X11_NO_MITSHM=1 \\\n",
        "    DISPLAY=:0\n",
        "\n",
        "# Create directories for models and data\n",
        "RUN mkdir -p /app/models /app/data /app/weights \\\n",
        "    && chmod 755 /app/models /app/data /app/weights\n",
        "\n",
        "# Bring in project descriptors and tests\n",
        "COPY pyproject.toml /workspace/\n",
        "COPY uv.lock* /workspace/\n",
        "COPY .devcontainer/validate_gpu.py /app/validate_gpu.py\n",
        "COPY .devcontainer/tests/ /app/tests/\n",
        "\n",
        "# Resolve project dependencies with UV\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    cd /workspace && (uv sync --frozen --no-dev || (uv sync --no-dev && uv lock))\n",
        "\n",
        "# CRITICAL FIX 2: Install PyTorch first to establish CUDA environment\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"Installing PyTorch with CUDA 12.4...\" && \\\n",
        "    uv pip install --no-cache-dir torch torchvision torchaudio \\\n",
        "        --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# CRITICAL FIX 3: Install compatible CuDNN 9.8.0 to satisfy JAX requirements\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"Upgrading CuDNN to 9.8.0 for JAX compatibility...\" && \\\n",
        "    uv pip install --no-cache-dir --upgrade nvidia-cudnn-cu12==9.8.0.69 || \\\n",
        "    uv pip install --no-cache-dir --upgrade nvidia-cudnn-cu12>=9.8.0\n",
        "\n",
        "# CRITICAL FIX 4: Install JAX after CuDNN upgrade with proper dependency resolution\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"Removing any existing JAX installations...\" && \\\n",
        "    (uv pip uninstall jax jaxlib jax-cuda12-plugin jax-cuda12-pjrt || true) && \\\n",
        "    echo \"Installing JAX with CUDA 12 support...\" && \\\n",
        "    (uv pip install --no-cache-dir \"jax[cuda12-local]>=0.4.26\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html \\\n",
        "     || uv pip install --no-cache-dir \"jax[cpu]>=0.4.26\")\n",
        "\n",
        "# Install Computer Vision specific packages\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"Installing Computer Vision packages...\" && \\\n",
        "    # Ensure latest Ultralytics and dependencies\n",
        "    uv pip install --no-cache-dir --upgrade ultralytics==8.3.158 && \\\n",
        "    # Install tracking libraries\n",
        "    uv pip install --no-cache-dir supervision>=0.17.0 lap>=0.4.0 && \\\n",
        "    # Install additional CV utilities\n",
        "    uv pip install --no-cache-dir albumentations>=1.3.0 && \\\n",
        "    # Ensure opencv-contrib for advanced features\n",
        "    uv pip install --no-cache-dir opencv-contrib-python-headless>=4.10.0\n",
        "\n",
        "# REMOVED: Pre-download YOLO models (models will be downloaded on first use)\n",
        "# This reduces build time and container size significantly\n",
        "# Models will be cached in the mounted volumes during runtime\n",
        "\n",
        "# Jupyter kernel support\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    uv pip install ipykernel jupyter-client jupyterlab\n",
        "\n",
        "# CUDA libs in path - include both system and package CUDA libraries\n",
        "ENV LD_LIBRARY_PATH=\"/app/.venv/lib:/app/.venv/lib/python3.10/site-packages/nvidia/cudnn/lib:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}\"\n",
        "\n",
        "# Shell activation helper with updated library paths\n",
        "RUN echo '#!/bin/bash' > /app/activate_uv.sh && \\\n",
        "    echo 'export VIRTUAL_ENV=\"/app/.venv\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'export PATH=\"/app/.venv/bin:$PATH\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'export UV_PROJECT_ENVIRONMENT=\"/app/.venv\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'export PYTHONPATH=\"/workspace:$PYTHONPATH\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'export LD_LIBRARY_PATH=\"/app/.venv/lib:/app/.venv/lib/python3.10/site-packages/nvidia/cudnn/lib:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}\"' >> /app/activate_uv.sh && \\\n",
        "    echo '# Computer Vision environment' >> /app/activate_uv.sh && \\\n",
        "    echo 'export YOLO_VERBOSE=false' >> /app/activate_uv.sh && \\\n",
        "    echo 'export OPENCV_LOG_LEVEL=ERROR' >> /app/activate_uv.sh && \\\n",
        "    echo 'cd /workspace' >> /app/activate_uv.sh && \\\n",
        "    chmod +x /app/activate_uv.sh && \\\n",
        "    echo 'source /app/activate_uv.sh' > /etc/profile.d/10-uv-activate.sh && \\\n",
        "    echo 'source /app/activate_uv.sh' >> /root/.bashrc && \\\n",
        "    chmod +x /etc/profile.d/10-uv-activate.sh\n",
        "\n",
        "# Enhanced healthcheck with CV components (updated without YOLO model check)\n",
        "RUN echo '#!/bin/bash' > /app/healthcheck.sh && \\\n",
        "    echo 'source /app/.venv/bin/activate' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== Environment Check ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python --version' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== CuDNN Version Check ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import torch; print(f\\\"PyTorch CuDNN: {torch.backends.cudnn.version()}\\\")\" || echo \"PyTorch CuDNN check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== JAX Device Check ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import jax; print(f\\\"JAX devices: {jax.devices()}\\\")\" || echo \"JAX device check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== Computer Vision Check ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import cv2; print(f\\\"OpenCV: {cv2.__version__}\\\")\" || echo \"OpenCV check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"from ultralytics import YOLO; print(\\\"YOLO package: OK\\\")\" || echo \"YOLO package check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import roboflow; print(f\\\"Roboflow: {roboflow.__version__}\\\")\" || echo \"Roboflow check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== GPU Validation ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python /app/validate_gpu.py --quick' >> /app/healthcheck.sh && \\\n",
        "    chmod +x /app/healthcheck.sh\n",
        "\n",
        "WORKDIR /workspace\n",
        "CMD [\"bash\", \"-l\"]"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Docker Setup\n",
        "\n",
        "Creating the Docker Compose configuration and project files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../docker-compose.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../docker-compose.yml\n",
        "name: ${ENV_NAME:-docker_dev_template}\n",
        "\n",
        "services:\n",
        "  datascience:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: .devcontainer/Dockerfile\n",
        "      args:\n",
        "        CUDA_TAG: ${CUDA_TAG:-12.4.0}\n",
        "        PYTHON_VER: ${PYTHON_VER:-3.10}\n",
        "        ENV_NAME: ${ENV_NAME:-docker_dev_template}\n",
        "      cache_from:\n",
        "        - nvidia/cuda:${CUDA_TAG:-12.4.0}-devel-ubuntu22.04\n",
        "\n",
        "    container_name: ${ENV_NAME:-docker_dev_template}_datascience\n",
        "\n",
        "    # UPDATED: Reference environment template from .devcontainer folder\n",
        "    env_file:\n",
        "      - .devcontainer/.env\n",
        "\n",
        "    restart: unless-stopped\n",
        "    depends_on:\n",
        "      mlflow:\n",
        "        condition: service_healthy\n",
        "\n",
        "    deploy:\n",
        "      resources:\n",
        "        reservations:\n",
        "          devices:\n",
        "            - driver: nvidia\n",
        "              count: all\n",
        "              capabilities: [gpu, compute, utility, video]  # Added video capability\n",
        "\n",
        "    init: true\n",
        "    gpus: all\n",
        "    shm_size: 16g  # Increased for video processing\n",
        "    ulimits:\n",
        "      memlock: -1\n",
        "      stack: 67108864\n",
        "\n",
        "    environment:\n",
        "      - PYTHON_VER=${PYTHON_VER:-3.10}\n",
        "      - UV_PROJECT_ENVIRONMENT=/app/.venv\n",
        "      - VIRTUAL_ENV=/app/.venv\n",
        "      - PYTHONPATH=/workspace\n",
        "      - NVIDIA_VISIBLE_DEVICES=all\n",
        "      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video\n",
        "      - CUDA_VISIBLE_DEVICES=0\n",
        "      - LD_LIBRARY_PATH=/app/.venv/lib:/usr/local/cuda/lib64\n",
        "      - LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2\n",
        "      - MALLOC_ARENA_MAX=2\n",
        "      - MALLOC_TCACHE_MAX=0\n",
        "      - PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
        "      \n",
        "      # CRITICAL FIX: Removed inline comments from JAX environment variables\n",
        "      # These were causing \"could not convert string to float\" errors\n",
        "      - XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "      - XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
        "      - XLA_PYTHON_CLIENT_MEM_FRACTION=0.4\n",
        "      - XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda\n",
        "      - JAX_PREALLOCATION_SIZE_LIMIT_BYTES=17179869184\n",
        "      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True\n",
        "      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-jupyter}\n",
        "      \n",
        "      # Computer Vision configuration\n",
        "      - YOLO_VERBOSE=${YOLO_VERBOSE:-false}\n",
        "      - OPENCV_LOG_LEVEL=${OPENCV_LOG_LEVEL:-ERROR}\n",
        "      - ROBOFLOW_API_KEY=${ROBOFLOW_API_KEY:-}\n",
        "      - ULTRALYTICS_HUB_API_KEY=${ULTRALYTICS_HUB_API_KEY:-}\n",
        "      \n",
        "      # Display configuration for GUI support\n",
        "      - DISPLAY=${DISPLAY:-:0}\n",
        "      - QT_X11_NO_MITSHM=1\n",
        "      - LIBGL_ALWAYS_INDIRECT=1\n",
        "\n",
        "    volumes:\n",
        "      # Main workspace\n",
        "      - .:/workspace:delegated\n",
        "      \n",
        "      # MLflow artifacts\n",
        "      - ./mlruns:/workspace/mlruns\n",
        "      \n",
        "      # UV cache\n",
        "      - uv-cache:/root/.cache/uv\n",
        "      \n",
        "      # Computer Vision specific volumes\n",
        "      - ./models:/app/models:delegated\n",
        "      - ./weights:/app/weights:delegated\n",
        "      - ./data:/app/data:delegated\n",
        "      - ./videos:/workspace/videos:delegated\n",
        "      \n",
        "      # Ultralytics/YOLO cache\n",
        "      - yolo-cache:/root/.cache/ultralytics\n",
        "      \n",
        "      # Roboflow cache\n",
        "      - roboflow-cache:/root/.cache/roboflow\n",
        "      \n",
        "      # X11 socket for GUI (Linux/Unix only)\n",
        "      - /tmp/.X11-unix:/tmp/.X11-unix:rw\n",
        "      - ${HOME}/.Xauthority:/root/.Xauthority:rw\n",
        "\n",
        "    ports:\n",
        "      # Jupyter Lab\n",
        "      - \"${HOST_JUPYTER_PORT:-8891}:8888\"\n",
        "      \n",
        "      # TensorBoard\n",
        "      - \"${HOST_TENSORBOARD_PORT:-6008}:6008\"\n",
        "      \n",
        "      # Explainer Dashboard\n",
        "      - \"${HOST_EXPLAINER_PORT:-8050}:8050\"\n",
        "      \n",
        "      # Streamlit\n",
        "      - \"${HOST_STREAMLIT_PORT:-8501}:8501\"\n",
        "      \n",
        "      # Computer Vision specific ports\n",
        "      - \"${HOST_CV_API_PORT:-8080}:8080\"  # CV API server\n",
        "      - \"${HOST_CV_STREAM_PORT:-8554}:8554\"  # RTSP stream\n",
        "\n",
        "    command: >\n",
        "      bash -lc '\n",
        "        echo \"[boot] Starting container: ${ENV_NAME:-docker_dev_template}\";\n",
        "        echo \"[boot] Activating uv environment...\";\n",
        "        source /app/.venv/bin/activate;\n",
        "        echo \"[boot] Environment activated - Python: $(which python)\";\n",
        "        echo \"[boot] UV available: $(uv --version)\";\n",
        "        echo \"[boot] Running GPU validation...\";\n",
        "        python /app/validate_gpu.py || echo \"GPU validation warning - check logs\";\n",
        "        echo \"[boot] Checking Computer Vision components...\";\n",
        "        python /app/tests/test_cv.py || echo \"CV check warning - check logs\";\n",
        "        echo \"[boot] Starting Jupyter Lab on port 8888...\";\n",
        "        jupyter lab --ip=0.0.0.0 --port=8888 --allow-root \n",
        "        --NotebookApp.token=\"${JUPYTER_TOKEN}\" \n",
        "        --NotebookApp.allow_origin=\"*\" \n",
        "        --NotebookApp.open_browser=false\n",
        "      '\n",
        "\n",
        "    healthcheck:\n",
        "      test:\n",
        "        - CMD-SHELL\n",
        "        - |\n",
        "          python -c '\n",
        "          import torch, jax, cv2\n",
        "          from ultralytics import YOLO\n",
        "          assert torch.cuda.is_available()\n",
        "          assert any(\"gpu\" in str(d).lower() for d in jax.devices())\n",
        "          assert cv2.__version__ is not None\n",
        "          print(\"All systems operational\")\n",
        "          ' 2>/dev/null || exit 1\n",
        "      interval: 60s\n",
        "      timeout: 30s\n",
        "      retries: 3\n",
        "      start_period: 120s\n",
        "\n",
        "    labels:\n",
        "      - \"com.docker.compose.project=${ENV_NAME:-docker_dev_template}\"\n",
        "      - \"com.docker.compose.service=datascience\"\n",
        "      - \"description=RTX 4090 GPU Dev Environment with Computer Vision (PyTorch+JAX+YOLO) - CUDA 12.4\"\n",
        "\n",
        "  mlflow:\n",
        "    container_name: ${ENV_NAME:-docker_dev_template}_mlflow\n",
        "    image: ghcr.io/mlflow/mlflow:latest\n",
        "    command: >\n",
        "      mlflow server\n",
        "      --host 0.0.0.0\n",
        "      --port 5000\n",
        "      --backend-store-uri sqlite:///mlflow.db\n",
        "      --default-artifact-root /mlflow_artifacts\n",
        "    environment:\n",
        "      MLFLOW_EXPERIMENTS_DEFAULT_ARTIFACT_LOCATION: /mlflow_artifacts\n",
        "    volumes:\n",
        "      - ./mlruns:/mlflow_artifacts\n",
        "      - ./mlflow_db:/mlflow_db\n",
        "    ports:\n",
        "      - \"${HOST_MLFLOW_PORT:-5000}:5000\"\n",
        "    restart: unless-stopped\n",
        "    healthcheck:\n",
        "      test: [\"CMD\", \"python\", \"-c\", \"import requests; requests.get('http://localhost:5000/health').raise_for_status()\"]\n",
        "      interval: 30s\n",
        "      timeout: 10s\n",
        "      retries: 3\n",
        "      start_period: 30s\n",
        "\n",
        "volumes:\n",
        "  uv-cache:\n",
        "    driver: local\n",
        "  yolo-cache:\n",
        "    driver: local\n",
        "  roboflow-cache:\n",
        "    driver: local\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../pyproject.toml\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../pyproject.toml\n",
        "[project]\n",
        "name = \"docker_dev_template\"\n",
        "version = \"0.1.0\"\n",
        "description = \"Hierarchical Bayesian modeling for baseball exit velocity data\"\n",
        "authors = [\n",
        "  { name = \"Marlins Data Science Team\" },\n",
        "]\n",
        "license = \"MIT\"\n",
        "readme = \"README.md\"\n",
        "\n",
        "# ─── Restrict to Python 3.10–3.12 ──────────────────────────────\n",
        "requires-python = \">=3.10,<3.13\"\n",
        "\n",
        "dependencies = [\n",
        "  \"pandas>=2.0\",\n",
        "  \"numpy>=1.20,<2\",\n",
        "  \"matplotlib>=3.4.0\",\n",
        "  \"scikit-learn>=1.4.2\",\n",
        "  \"pymc>=5.0.0\",\n",
        "  \"arviz>=0.14.0\",\n",
        "  \"statsmodels>=0.13.0\",\n",
        "  \"jupyterlab>=3.0.0\",\n",
        "  \"seaborn>=0.11.0\",\n",
        "  \"tabulate>=0.9.0\",\n",
        "  \"shap>=0.40.0\",\n",
        "  \"xgboost>=1.5.0\",\n",
        "  \"lightgbm>=3.3.0\",\n",
        "  \"catboost>=1.0.0\",\n",
        "  \"scipy>=1.7.0\",\n",
        "  \"shapash[report]>=2.3.0\",\n",
        "  \"shapiq>=1.3.0\",\n",
        "  \"explainerdashboard>=0.3.0\",\n",
        "  \"ipywidgets>=8.0.0\",\n",
        "  \"nutpie>=0.7.1\",\n",
        "  \"numpyro>=0.18.0,<1.0.0\",\n",
        "  \"jax>=0.4.23\",\n",
        "  \"jaxlib>=0.4.23\",\n",
        "  \"pytensor>=2.18.3\",\n",
        "  \"aesara>=2.9.4\",\n",
        "  \"tqdm>=4.67.0\",\n",
        "  \"pyarrow>=12.0.0\",\n",
        "  \"streamlit>=1.20.0\",\n",
        "  \"sqlalchemy>=1.4\",\n",
        "  \"mysql-connector-python>=8.0\",\n",
        "  \"optuna>=4.3.0\",\n",
        "  \"bayesian-optimization>=1.2.0\",\n",
        "  \"pretty_errors>=1.2.0\",\n",
        "  \"gdown>=4.0.0\",\n",
        "  \"invoke>=2.2\",\n",
        "  # ▶ Video download stack\n",
        "  #   - pytube main-branch until next PyPI release (optional fallback)\n",
        "  \"pytube @ git+https://github.com/pytube/pytube\",\n",
        "  \"yt-dlp==2025.9.5\",  # Pinned for stability\n",
        "  #   - optional convenience wrapper (does NOT install ffmpeg binary!)\n",
        "  \"ffmpeg-python==0.2.0\",  # Pinned for stability\n",
        "\n",
        "  # ▶ Computer Vision Stack\n",
        "  # Core CV libraries\n",
        "  \"ultralytics==8.3.158\",  # YOLO v8 - pinned for stability\n",
        "  \"opencv-contrib-python-headless>=4.10.0\",  # OpenCV with contrib modules\n",
        "  \"roboflow==1.2.9\",  # Roboflow API client - pinned for stability\n",
        "  \n",
        "  # Object tracking and supervision\n",
        "  \"supervision>=0.17.0\",  # Modern CV utilities and tracking\n",
        "  \"lap>=0.4.0\",  # Linear Assignment Problem solver for tracking\n",
        "  \n",
        "  # Image augmentation and processing\n",
        "  \"albumentations>=1.3.0\",  # Fast image augmentation\n",
        "  \"imgaug>=0.4.0\",  # Image augmentation library\n",
        "  \"pillow>=10.0.0\",  # Image processing\n",
        "  \n",
        "  # Video processing and download\n",
        "  \"moviepy==2.2.1\",  # Video editing - pinned for stability\n",
        "  \"mlflow>=3.1.1,<4.0.0\",\n",
        "  \"optuna-integration[mlflow]>=4.4.0,<5.0.0\",\n",
        "  \n",
        "  # PyTorch core libraries - platform specific with PEP-508 compliant syntax\n",
        "  # CUDA wheels for Windows/Linux, CPU for macOS\n",
        "\"torch>=2.0.0\",\n",
        "\"torchvision>=0.15.0\",\n",
        "\"torchaudio>=2.0.0\",\n",
        "]\n",
        "\n",
        "[project.optional-dependencies]\n",
        "dev = [\n",
        "  \"pytest>=7.0.0\",\n",
        "  \"black>=23.0.0\",\n",
        "  \"isort>=5.0.0\",\n",
        "  \"flake8>=5.0.0\",\n",
        "  \"mypy>=1.0.0\",\n",
        "  \"pre-commit>=3.0.0\",\n",
        "]\n",
        "\n",
        "cuda = [\n",
        "  \"cupy-cuda12x>=12.0.0\",  # For CUDA 12.x\n",
        "]\n",
        "\n",
        "basketball = [\n",
        "  # Additional basketball-specific packages\n",
        "  \"sportsipy>=0.6.0\",  # Sports statistics\n",
        "  \"nba-api>=1.4.0\",  # NBA API client\n",
        "]\n",
        "\n",
        "# ─── uv configuration ──────────────────────────────────────────\n",
        "[tool.uv]                   # uv reads this block\n",
        "index-strategy = \"unsafe-best-match\"\n",
        "\n",
        "# Define named indexes for PyTorch CUDA variants\n",
        "[[tool.uv.index]]\n",
        "name = \"pytorch-cu121\"\n",
        "url = \"https://download.pytorch.org/whl/cu121\"\n",
        "explicit = true\n",
        "\n",
        "[[tool.uv.index]]\n",
        "name = \"pytorch-cu118\"\n",
        "url = \"https://download.pytorch.org/whl/cu118\"\n",
        "explicit = true\n",
        "\n",
        "[[tool.uv.index]]\n",
        "name = \"pytorch-cu124\"\n",
        "url = \"https://download.pytorch.org/whl/cu124\"\n",
        "explicit = true\n",
        "\n",
        "[[tool.uv.index]]\n",
        "name = \"pytorch-cu128\"\n",
        "url = \"https://download.pytorch.org/whl/cu128\"\n",
        "explicit = true\n",
        "\n",
        "# Removed unsupported option: torch-backend requires uv ≥0.5.3\n",
        "# To re-enable, first run: pip install -U uv>=0.5.3\n",
        "[tool.uv.pip]\n",
        "# (No unsupported keys here; configure only valid pip options.)\n",
        "\n",
        "# Map PyTorch dependencies to CUDA indexes for non-macOS platforms\n",
        "# Testing with CUDA 12.8\n",
        "[tool.uv.sources]\n",
        "torch = [\n",
        "  { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' or sys_platform == 'win32'\" },\n",
        "]\n",
        "torchvision = [\n",
        "  { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' or sys_platform == 'win32'\" },\n",
        "]\n",
        "torchaudio = [\n",
        "  { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' or sys_platform == 'win32'\" },\n",
        "]\n",
        "\n",
        "[tool.pytensor]\n",
        "device    = \"cuda\"\n",
        "floatX    = \"float32\"\n",
        "allow_gc  = true\n",
        "optimizer = \"fast_run\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/validate_gpu.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/validate_gpu.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "GPU validation and environment diagnostics for RTX 4090 devcontainer.\n",
        "Focus: verify JAX and PyTorch access to CUDA, report common misconfigurations.\n",
        "\"\"\"\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import warnings\n",
        "import textwrap\n",
        "import re\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def print_section(title: str) -> None:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"  {title}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def validate_environment_variables() -> bool:\n",
        "    \"\"\"Validate JAX‑related environment variables (no inline comments, valid types).\"\"\"\n",
        "    print_section(\"JAX ENVIRONMENT VARIABLE VALIDATION\")\n",
        "\n",
        "    jax_numeric_vars = {\n",
        "        'XLA_PYTHON_CLIENT_MEM_FRACTION': {'type': 'float', 'range': (0.0, 1.0)},\n",
        "        'JAX_PREALLOCATION_SIZE_LIMIT_BYTES': {'type': 'int', 'range': (0, None)},\n",
        "    }\n",
        "    jax_string_vars = {\n",
        "        'XLA_FLAGS', 'JAX_PLATFORM_NAME', 'XLA_PYTHON_CLIENT_ALLOCATOR', 'XLA_PYTHON_CLIENT_PREALLOCATE'\n",
        "    }\n",
        "\n",
        "    ok = True\n",
        "    problems = []\n",
        "\n",
        "    for var, cfg in jax_numeric_vars.items():\n",
        "        value = os.environ.get(var)\n",
        "        print(f\"\\nCheck {var} -> {value}\")\n",
        "        if value is None:\n",
        "            print(\"  not set; defaults apply\")\n",
        "            continue\n",
        "        if '#' in value:\n",
        "            clean = value.split('#')[0].strip()\n",
        "            print(\"  contains inline comment; use:\", clean)\n",
        "            problems.append((var, value, clean))\n",
        "            ok = False\n",
        "            continue\n",
        "        try:\n",
        "            if cfg['type'] == 'float':\n",
        "                v = float(value)\n",
        "                low, high = cfg['range']\n",
        "                if (low is not None and v < low) or (high is not None and v > high):\n",
        "                    print(\"  out of recommended range\")\n",
        "                else:\n",
        "                    print(\"  ok\")\n",
        "            else:\n",
        "                v = int(value)\n",
        "                print(\"  ok\")\n",
        "        except ValueError as e:\n",
        "            print(\"  invalid numeric value:\", e)\n",
        "            ok = False\n",
        "\n",
        "    for var in jax_string_vars:\n",
        "        value = os.environ.get(var)\n",
        "        if value and '#' in value:\n",
        "            print(f\"warn: {var} contains '#', which can break parsing\")\n",
        "\n",
        "    if problems:\n",
        "        print(\"\\nFix suggestions:\")\n",
        "        for var, bad, clean in problems:\n",
        "            print(f\"export {var}={clean}\")\n",
        "    return ok\n",
        "\n",
        "\n",
        "def check_environment() -> None:\n",
        "    print_section(\"ENVIRONMENT CHECK\")\n",
        "    print(\"python:\", sys.executable)\n",
        "    print(\"version:\", sys.version)\n",
        "    print(\"VIRTUAL_ENV:\", os.environ.get('VIRTUAL_ENV'))\n",
        "    print(\"PATH contains .venv:\", '.venv/bin' in os.environ.get('PATH', ''))\n",
        "\n",
        "    cuda_vars = ['CUDA_HOME', 'CUDA_PATH', 'CUDA_VISIBLE_DEVICES', 'LD_LIBRARY_PATH', 'NVIDIA_VISIBLE_DEVICES']\n",
        "    print(\"\\nCUDA variables:\")\n",
        "    for var in cuda_vars:\n",
        "        print(f\"  {var}:\", os.environ.get(var, 'not set'))\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            ['nvidia-smi', '--query-gpu=name,driver_version,memory.total', '--format=csv,noheader'],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            print(\"\\nGPU:\", result.stdout.strip())\n",
        "        else:\n",
        "            print(\"\\nwarn: nvidia-smi returned non‑zero\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nwarn: nvidia-smi not found in path\")\n",
        "\n",
        "\n",
        "def test_pytorch() -> bool:\n",
        "    print_section(\"PYTORCH GPU TEST\")\n",
        "    try:\n",
        "        import torch\n",
        "        print(\"version:\", torch.__version__)\n",
        "        print(\"cuda available:\", torch.cuda.is_available())\n",
        "        if torch.cuda.is_available():\n",
        "            print(\"device count:\", torch.cuda.device_count())\n",
        "            print(\"device 0:\", torch.cuda.get_device_name(0))\n",
        "            # quick matmul\n",
        "            import time\n",
        "            dev = torch.device('cuda')\n",
        "            x = torch.randn(2000, 2000, device=dev)\n",
        "            y = torch.randn(2000, 2000, device=dev)\n",
        "            _ = x @ y\n",
        "            torch.cuda.synchronize()\n",
        "            t0 = time.time()\n",
        "            r = x @ y\n",
        "            torch.cuda.synchronize()\n",
        "            print(\"matmul elapsed s:\", round(time.time() - t0, 3))\n",
        "            _ = r.sum().item()\n",
        "            return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(\"pytorch test error:\", e)\n",
        "        return False\n",
        "\n",
        "\n",
        "def check_cudnn_compatibility() -> bool:\n",
        "    \"\"\"Check CuDNN version compatibility between PyTorch and JAX.\"\"\"\n",
        "    print_section(\"CUDNN COMPATIBILITY CHECK\")\n",
        "    try:\n",
        "        import torch\n",
        "        import subprocess\n",
        "        import glob\n",
        "        \n",
        "        # Check PyTorch CuDNN version\n",
        "        pytorch_cudnn = torch.backends.cudnn.version()\n",
        "        print(f\"PyTorch CuDNN version: {pytorch_cudnn}\")\n",
        "        \n",
        "        # Check installed nvidia-cudnn-cu12 package version\n",
        "        try:\n",
        "            result = subprocess.run(['uv', 'pip', 'list'], capture_output=True, text=True)\n",
        "            if result.returncode == 0:\n",
        "                lines = result.stdout.split('\\n')\n",
        "                for line in lines:\n",
        "                    if 'nvidia-cudnn-cu12' in line:\n",
        "                        print(f\"Installed CuDNN package: {line.strip()}\")\n",
        "                        break\n",
        "        except Exception as e:\n",
        "            print(f\"Could not check CuDNN package version: {e}\")\n",
        "        \n",
        "        # Check CuDNN library files\n",
        "        cudnn_paths = [\n",
        "            \"/app/.venv/lib/python3.10/site-packages/nvidia/cudnn/lib\",\n",
        "            \"/usr/local/cuda/lib64\",\n",
        "            \"/usr/lib/x86_64-linux-gnu\"\n",
        "        ]\n",
        "        \n",
        "        print(\"\\nCuDNN library search:\")\n",
        "        for path in cudnn_paths:\n",
        "            if os.path.exists(path):\n",
        "                cudnn_libs = glob.glob(f\"{path}/libcudnn*\")\n",
        "                if cudnn_libs:\n",
        "                    print(f\"  {path}: {len(cudnn_libs)} CuDNN libraries found\")\n",
        "                    for lib in cudnn_libs[:3]:  # Show first 3\n",
        "                        print(f\"    - {os.path.basename(lib)}\")\n",
        "                else:\n",
        "                    print(f\"  {path}: No CuDNN libraries found\")\n",
        "            else:\n",
        "                print(f\"  {path}: Path does not exist\")\n",
        "        \n",
        "        # Check LD_LIBRARY_PATH\n",
        "        ld_path = os.environ.get('LD_LIBRARY_PATH', '')\n",
        "        print(f\"\\nLD_LIBRARY_PATH: {ld_path}\")\n",
        "        \n",
        "        # Version compatibility check\n",
        "        if pytorch_cudnn < 9000:  # Assuming version format like 9100 for 9.1.0\n",
        "            print(\"WARNING: PyTorch CuDNN version may be too old for JAX\")\n",
        "            return False\n",
        "        \n",
        "        print(\"CuDNN compatibility check passed\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"CuDNN compatibility check failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_jax_initialization() -> bool:\n",
        "    print_section(\"JAX INITIALIZATION TEST\")\n",
        "    try:\n",
        "        os.environ['JAX_TRACEBACK_FILTERING'] = 'off'\n",
        "        import jax\n",
        "        import jaxlib\n",
        "        from jaxlib import xla_client\n",
        "        print(\"jax:\", jax.__version__, \"jaxlib:\", jaxlib.__version__)\n",
        "        \n",
        "        # Check for CuDNN version mismatch errors\n",
        "        try:\n",
        "            opts = xla_client.generate_pjrt_gpu_plugin_options()\n",
        "            print(\"gpu plugin options ok; memory_fraction:\", opts.get('memory_fraction', 'not set'))\n",
        "        except Exception as e:\n",
        "            print(\"gpu plugin options error:\", e)\n",
        "            if \"could not convert string to float\" in str(e):\n",
        "                print(\"hint: check XLA_PYTHON_CLIENT_MEM_FRACTION for inline comments\")\n",
        "            elif \"CuDNN\" in str(e) and \"version\" in str(e):\n",
        "                print(\"hint: CuDNN version mismatch detected - check compatibility\")\n",
        "            return False\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"jax init error:\", e)\n",
        "        if \"CuDNN\" in str(e):\n",
        "            print(\"hint: CuDNN-related error detected\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_jax() -> bool:\n",
        "    print_section(\"JAX GPU TEST\")\n",
        "    try:\n",
        "        os.environ['JAX_TRACEBACK_FILTERING'] = 'off'\n",
        "        import jax, jax.numpy as jnp\n",
        "        from jax.lib import xla_bridge\n",
        "        print(\"backend:\", xla_bridge.get_backend().platform)\n",
        "        devices = jax.devices()\n",
        "        print(\"devices:\", devices)\n",
        "        gpus = [d for d in devices if 'gpu' in str(d).lower() or getattr(d, 'platform', '') == 'gpu']\n",
        "        if not gpus:\n",
        "            print(\"no gpu devices detected by jax\")\n",
        "            return False\n",
        "        # quick compute\n",
        "        import time\n",
        "        key = jax.random.PRNGKey(0)\n",
        "        x = jax.random.normal(key, (2000, 2000))\n",
        "        x = jax.device_put(x, gpus[0])\n",
        "        t0 = time.time()\n",
        "        s = jnp.sum(x @ x).block_until_ready()\n",
        "        print(\"matmul elapsed s:\", round(time.time() - t0, 3), \"sum:\", float(s))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"jax test error:\", e)\n",
        "        return False\n",
        "\n",
        "\n",
        "def main() -> int:\n",
        "    import argparse\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument('--quick', action='store_true')\n",
        "    p.add_argument('--fix', action='store_true', help='Run with fix recommendations')\n",
        "    args = p.parse_args()\n",
        "\n",
        "    if args.quick:\n",
        "        env_ok = validate_environment_variables()\n",
        "        pt_ok = test_pytorch()\n",
        "        return 0 if (env_ok and pt_ok) else 1\n",
        "\n",
        "    env_ok = validate_environment_variables()\n",
        "    check_environment()\n",
        "    cudnn_ok = check_cudnn_compatibility()\n",
        "    jax_init_ok = test_jax_initialization()\n",
        "    jax_ok = test_jax()\n",
        "    pt_ok = test_pytorch()\n",
        "\n",
        "    print_section(\"SUMMARY\")\n",
        "    print(\"env vars:\", \"ok\" if env_ok else \"fail\")\n",
        "    print(\"cudnn compatibility:\", \"ok\" if cudnn_ok else \"fail\")\n",
        "    print(\"jax init:\", \"ok\" if jax_init_ok else \"fail\")\n",
        "    print(\"jax compute:\", \"ok\" if jax_ok else \"fail\")\n",
        "    print(\"pytorch:\", \"ok\" if pt_ok else \"fail\")\n",
        "\n",
        "    # Provide fix recommendations if requested\n",
        "    if args.fix and not (env_ok and cudnn_ok and jax_init_ok and jax_ok and pt_ok):\n",
        "        print_section(\"FIX RECOMMENDATIONS\")\n",
        "        if not cudnn_ok:\n",
        "            print(\"1. CuDNN version mismatch detected:\")\n",
        "            print(\"   - Upgrade nvidia-cudnn-cu12 to version >= 9.8.0\")\n",
        "            print(\"   - Ensure LD_LIBRARY_PATH includes CuDNN library paths\")\n",
        "        if not jax_init_ok:\n",
        "            print(\"2. JAX initialization failed:\")\n",
        "            print(\"   - Check CuDNN compatibility\")\n",
        "            print(\"   - Verify XLA environment variables (no inline comments)\")\n",
        "        if not jax_ok:\n",
        "            print(\"3. JAX GPU computation failed:\")\n",
        "            print(\"   - Verify GPU is accessible\")\n",
        "            print(\"   - Check CUDA driver compatibility\")\n",
        "\n",
        "    return 0 if (env_ok and cudnn_ok and jax_init_ok and jax_ok and pt_ok) else 1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## BuildKit Cache Fix & Testing\n",
        "\n",
        "The Dockerfile has been updated with isolated BuildKit cache mounts to prevent \n",
        "`archive/tar: invalid tar header` errors. If you encounter build issues:\n",
        "\n",
        "**Quick Fix:**\n",
        "```bash\n",
        "python scripts/fix_build.py\n",
        "```\n",
        "\n",
        "**Manual Fix Steps:**\n",
        "1. Clear corrupted caches: `docker builder prune --all --force`\n",
        "2. Clean build: `docker-compose build --no-cache`\n",
        "3. Test cached build: `docker-compose build`\n",
        "\n",
        "**Key Improvements:**\n",
        "- Added explicit cache IDs: `apt-cache`, `apt-lists`, `uv-cache`\n",
        "- Prevents cache key collisions and corruption\n",
        "- Maintains fast build times with reliable caching\n",
        "\n",
        "## Testing & Diagnostics\n",
        "\n",
        "Creating comprehensive testing and diagnostic scripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_pytorch_gpu.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_pytorch_gpu.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"Small PyTorch GPU benchmark.\"\"\"\n",
        "import time\n",
        "\n",
        "\n",
        "def test_pytorch(force_cpu: bool = False) -> None:\n",
        "    import torch\n",
        "    cuda_ok = torch.cuda.is_available() and not force_cpu\n",
        "    if cuda_ok:\n",
        "        name = torch.cuda.get_device_name(0)\n",
        "        major, minor = torch.cuda.get_device_capability()\n",
        "        print(f\"device: {name} (sm_{major}{minor:02d})\")\n",
        "        device = torch.device(\"cuda:0\")\n",
        "    else:\n",
        "        print(\"falling back to cpu\")\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    size = (1000, 1000)\n",
        "    a, b = (torch.randn(size, device=device) for _ in range(2))\n",
        "    _ = a @ b\n",
        "    t0 = time.time()\n",
        "    _ = (a @ b).sum().item()\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "    print(f\"matmul on {device} took {(time.time()-t0)*1000:.2f} ms\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_pytorch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_cv.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_cv.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Computer Vision validation and testing for Basketball Detection setup.\n",
        "Tests YOLO, Roboflow, OpenCV, and tracking libraries.\n",
        "\"\"\"\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def print_section(title: str) -> None:\n",
        "    \"\"\"Print a formatted section header.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"  {title}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def test_opencv() -> bool:\n",
        "    \"\"\"Test OpenCV installation and basic functionality.\"\"\"\n",
        "    print_section(\"OPENCV TEST\")\n",
        "    try:\n",
        "        import cv2\n",
        "        print(f\"OpenCV version: {cv2.__version__}\")\n",
        "        print(f\"Build info: {cv2.getBuildInformation().split('General configuration')[0][:100]}...\")\n",
        "        \n",
        "        # Check available video backends\n",
        "        backends = []\n",
        "        for backend in [cv2.CAP_FFMPEG, cv2.CAP_GSTREAMER, cv2.CAP_V4L2]:\n",
        "            try:\n",
        "                cap = cv2.VideoCapture()\n",
        "                if cap.open(0, backend):\n",
        "                    backends.append(backend)\n",
        "                    cap.release()\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        print(f\"Available video backends: {backends}\")\n",
        "        \n",
        "        # Test basic image operations\n",
        "        test_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
        "        gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "        \n",
        "        print(f\"Image processing test: OK (edges shape: {edges.shape})\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"OpenCV test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_ultralytics() -> bool:\n",
        "    \"\"\"Test Ultralytics YOLO installation and model loading.\"\"\"\n",
        "    print_section(\"ULTRALYTICS YOLO TEST\")\n",
        "    try:\n",
        "        from ultralytics import YOLO, __version__\n",
        "        from ultralytics.utils.checks import check_requirements\n",
        "        \n",
        "        print(f\"Ultralytics version: {__version__}\")\n",
        "        \n",
        "        # Check if CUDA is available for YOLO\n",
        "        import torch\n",
        "        print(f\"YOLO CUDA available: {torch.cuda.is_available()}\")\n",
        "        \n",
        "        # Test loading a model (will download if not cached)\n",
        "        model_path = \"/app/weights/yolov8n.pt\"\n",
        "        if not os.path.exists(model_path):\n",
        "            print(\"Downloading YOLOv8n model...\")\n",
        "            model = YOLO(\"yolov8n.pt\")\n",
        "        else:\n",
        "            print(f\"Loading cached model from {model_path}\")\n",
        "            model = YOLO(model_path)\n",
        "        \n",
        "        print(f\"Model loaded: {model.model.__class__.__name__}\")\n",
        "        print(f\"Model device: {model.device}\")\n",
        "        \n",
        "        # Test inference on dummy image\n",
        "        dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
        "        results = model(dummy_img, verbose=False)\n",
        "        \n",
        "        print(f\"Inference test: OK (processed {len(results)} image)\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Ultralytics test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_roboflow() -> bool:\n",
        "    \"\"\"Test Roboflow installation and API connectivity.\"\"\"\n",
        "    print_section(\"ROBOFLOW TEST\")\n",
        "    try:\n",
        "        import roboflow\n",
        "        from roboflow import Roboflow\n",
        "        \n",
        "        print(f\"Roboflow version: {roboflow.__version__}\")\n",
        "        \n",
        "        # Check if API key is set\n",
        "        api_key = os.environ.get('ROBOFLOW_API_KEY', '')\n",
        "        if api_key:\n",
        "            print(\"Roboflow API key: Set\")\n",
        "            \n",
        "            # Test API connection (won't actually download without valid key)\n",
        "            try:\n",
        "                rf = Roboflow(api_key=api_key)\n",
        "                print(\"Roboflow client initialized successfully\")\n",
        "                \n",
        "                # Try to access basketball court detection project\n",
        "                workspace = os.environ.get('ROBOFLOW_WORKSPACE', 'basketball-formations')\n",
        "                project = os.environ.get('ROBOFLOW_PROJECT', 'basketball-court-detection-2-mlopt')\n",
        "                version = os.environ.get('ROBOFLOW_VERSION', '1')\n",
        "                \n",
        "                print(f\"Workspace: {workspace}\")\n",
        "                print(f\"Project: {project}\")\n",
        "                print(f\"Version: {version}\")\n",
        "                \n",
        "                # Note: This will fail without valid API key, which is expected\n",
        "                # project = rf.workspace(workspace).project(project)\n",
        "                # dataset = project.version(version)\n",
        "                # print(f\"Dataset accessible: {dataset.name}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Note: Full Roboflow test requires valid API key: {e}\")\n",
        "        else:\n",
        "            print(\"Roboflow API key: Not set (set ROBOFLOW_API_KEY to enable)\")\n",
        "            print(\"Get your API key from: https://app.roboflow.com/settings/api\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Roboflow test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_supervision() -> bool:\n",
        "    \"\"\"Test supervision library for tracking and annotation.\"\"\"\n",
        "    print_section(\"SUPERVISION TRACKING TEST\")\n",
        "    try:\n",
        "        import supervision as sv\n",
        "        \n",
        "        print(f\"Supervision version: {sv.__version__}\")\n",
        "        \n",
        "        # Test basic detection utilities\n",
        "        from supervision import Detections, BoxAnnotator\n",
        "        \n",
        "        # Create dummy detections\n",
        "        xyxy = np.array([[100, 100, 200, 200], [300, 300, 400, 400]])\n",
        "        confidence = np.array([0.9, 0.8])\n",
        "        class_id = np.array([0, 1])\n",
        "        \n",
        "        detections = Detections(\n",
        "            xyxy=xyxy,\n",
        "            confidence=confidence,\n",
        "            class_id=class_id\n",
        "        )\n",
        "        \n",
        "        print(f\"Created {len(detections)} dummy detections\")\n",
        "        \n",
        "        # Test annotator\n",
        "        annotator = BoxAnnotator()\n",
        "        print(\"Box annotator initialized\")\n",
        "        \n",
        "        # Test tracker availability\n",
        "        try:\n",
        "            from supervision import ByteTrack\n",
        "            tracker = ByteTrack()\n",
        "            print(\"ByteTrack tracker available\")\n",
        "        except ImportError:\n",
        "            print(\"ByteTrack tracker not available (optional)\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Supervision test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_video_processing() -> bool:\n",
        "    \"\"\"Test video processing capabilities.\"\"\"\n",
        "    print_section(\"VIDEO PROCESSING TEST\")\n",
        "    try:\n",
        "        # Test ffmpeg-python\n",
        "        import ffmpeg\n",
        "        print(\"ffmpeg-python: Available\")\n",
        "        \n",
        "        # Check ffmpeg binary\n",
        "        import subprocess\n",
        "        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            ffmpeg_version = result.stdout.split('\\n')[0]\n",
        "            print(f\"ffmpeg binary: {ffmpeg_version}\")\n",
        "        else:\n",
        "            print(\"ffmpeg binary: Not found or error\")\n",
        "            \n",
        "        # Test moviepy\n",
        "        try:\n",
        "            import moviepy\n",
        "            print(f\"MoviePy version: {moviepy.__version__}\")\n",
        "        except Exception as e:\n",
        "            print(f\"MoviePy: {e}\")\n",
        "            \n",
        "        # Test yt-dlp\n",
        "        try:\n",
        "            import yt_dlp\n",
        "            print(f\"yt-dlp version: {yt_dlp.version.__version__}\")\n",
        "        except Exception as e:\n",
        "            print(f\"yt-dlp: {e}\")\n",
        "            \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Video processing test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_basketball_models() -> bool:\n",
        "    \"\"\"Test basketball-specific model configurations.\"\"\"\n",
        "    print_section(\"BASKETBALL MODELS CONFIGURATION\")\n",
        "    \n",
        "    print(\"Basketball Detection Models:\")\n",
        "    print(\"1. Court Detection: roboflow/basketball-court-detection-2\")\n",
        "    print(\"2. Player Detection: YOLOv8 (person class)\")\n",
        "    print(\"3. Ball Detection: Custom YOLO model\")\n",
        "    print(\"4. Jersey Number OCR: Available via Roboflow\")\n",
        "    \n",
        "    # Check model directories\n",
        "    model_dirs = ['/app/models', '/app/weights', '/workspace/models']\n",
        "    for dir_path in model_dirs:\n",
        "        if os.path.exists(dir_path):\n",
        "            files = os.listdir(dir_path)\n",
        "            if files:\n",
        "                print(f\"\\n{dir_path}: {len(files)} files\")\n",
        "                for f in files[:5]:  # Show first 5 files\n",
        "                    print(f\"  - {f}\")\n",
        "            else:\n",
        "                print(f\"\\n{dir_path}: Empty\")\n",
        "        else:\n",
        "            print(f\"\\n{dir_path}: Not created yet\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "\n",
        "def main() -> int:\n",
        "    \"\"\"Run all computer vision tests.\"\"\"\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(description=\"Test Computer Vision components\")\n",
        "    parser.add_argument('--quick', action='store_true', help='Run quick tests only')\n",
        "    parser.add_argument('--verbose', action='store_true', help='Verbose output')\n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    if args.verbose:\n",
        "        print_section(\"ENVIRONMENT VARIABLES\")\n",
        "        cv_vars = ['ROBOFLOW_API_KEY', 'YOLO_VERBOSE', 'OPENCV_LOG_LEVEL', \n",
        "                   'VIDEO_INPUT_DIR', 'VIDEO_OUTPUT_DIR', 'DISPLAY']\n",
        "        for var in cv_vars:\n",
        "            value = os.environ.get(var, 'Not set')\n",
        "            if var == 'ROBOFLOW_API_KEY' and value != 'Not set':\n",
        "                value = value[:10] + '...' if len(value) > 10 else value\n",
        "            print(f\"{var}: {value}\")\n",
        "    \n",
        "    # Run tests\n",
        "    opencv_ok = test_opencv()\n",
        "    yolo_ok = test_ultralytics()\n",
        "    \n",
        "    if args.quick:\n",
        "        print_section(\"QUICK TEST SUMMARY\")\n",
        "        print(f\"OpenCV: {'✓' if opencv_ok else '✗'}\")\n",
        "        print(f\"YOLO: {'✓' if yolo_ok else '✗'}\")\n",
        "        return 0 if (opencv_ok and yolo_ok) else 1\n",
        "    \n",
        "    roboflow_ok = test_roboflow()\n",
        "    supervision_ok = test_supervision()\n",
        "    video_ok = test_video_processing()\n",
        "    basketball_ok = test_basketball_models()\n",
        "    \n",
        "    print_section(\"COMPUTER VISION TEST SUMMARY\")\n",
        "    results = {\n",
        "        \"OpenCV\": opencv_ok,\n",
        "        \"YOLO/Ultralytics\": yolo_ok,\n",
        "        \"Roboflow\": roboflow_ok,\n",
        "        \"Supervision\": supervision_ok,\n",
        "        \"Video Processing\": video_ok,\n",
        "        \"Basketball Config\": basketball_ok\n",
        "    }\n",
        "    \n",
        "    for component, status in results.items():\n",
        "        status_symbol = \"✓\" if status else \"✗\"\n",
        "        print(f\"{component}: {status_symbol}\")\n",
        "    \n",
        "    all_ok = all(results.values())\n",
        "    \n",
        "    if not all_ok:\n",
        "        print(\"\\n⚠️  Some components failed. Check the logs above for details.\")\n",
        "        print(\"Common fixes:\")\n",
        "        print(\"  - Set ROBOFLOW_API_KEY for Roboflow integration\")\n",
        "        print(\"  - Ensure ffmpeg is installed for video processing\")\n",
        "        print(\"  - Check GPU drivers for YOLO acceleration\")\n",
        "    else:\n",
        "        print(\"\\n✅ All computer vision components are working correctly!\")\n",
        "    \n",
        "    return 0 if all_ok else 1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ../../.devcontainer/tests/test_yolo_bas\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_yolo_bas\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "YOLO Basketball Detection Test\n",
        "Tests YOLO functionality on basketball images to ensure the package works correctly.\n",
        "\"\"\"\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class YOLOBasketballTester:\n",
        "    \"\"\"Test YOLO functionality with basketball-specific scenarios.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name=\"yolov8n.pt\", force_cpu=False):\n",
        "        \"\"\"Initialize the YOLO tester.\"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.force_cpu = force_cpu\n",
        "        self.model = None\n",
        "        self.device = \"cpu\" if force_cpu else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        # Create directories for test data\n",
        "        self.data_dir = Path(\"/workspace/data\")\n",
        "        self.images_dir = self.data_dir / \"images\"\n",
        "        self.output_dir = self.data_dir / \"output\"\n",
        "        \n",
        "        for dir_path in [self.data_dir, self.images_dir, self.output_dir]:\n",
        "            dir_path.mkdir(exist_ok=True, parents=True)\n",
        "        \n",
        "        self.test_image_path = self.images_dir / \"basketball_test.jpg\"\n",
        "        \n",
        "    def setup_test_environment(self):\n",
        "        \"\"\"Set up the test environment and download test image if needed.\"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"YOLO BASKETBALL DETECTION TEST\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        # Check environment\n",
        "        print(f\"Python version: {sys.version}\")\n",
        "        print(f\"OpenCV version: {cv2.__version__}\")\n",
        "        print(f\"PyTorch version: {torch.__version__}\")\n",
        "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "        print(f\"Device selected: {self.device}\")\n",
        "        \n",
        "        # Get or create test image\n",
        "        if not self.test_image_path.exists():\n",
        "            print(f\"\\nTest image not found at {self.test_image_path}\")\n",
        "            self._create_or_download_test_image()\n",
        "        else:\n",
        "            print(f\"Using existing test image: {self.test_image_path}\")\n",
        "    \n",
        "    def _create_or_download_test_image(self):\n",
        "        \"\"\"Create or download a basketball test image.\"\"\"\n",
        "        print(\"Creating synthetic basketball test image...\")\n",
        "        \n",
        "        # Create a synthetic basketball court scene\n",
        "        image = self._create_synthetic_basketball_scene()\n",
        "        \n",
        "        # Save the image\n",
        "        cv2.imwrite(str(self.test_image_path), image)\n",
        "        print(f\"Created synthetic test image: {self.test_image_path}\")\n",
        "        \n",
        "        return str(self.test_image_path)\n",
        "    \n",
        "    def _create_synthetic_basketball_scene(self):\n",
        "        \"\"\"Create a synthetic basketball scene for testing.\"\"\"\n",
        "        # Create a 1280x720 image (HD resolution)\n",
        "        width, height = 1280, 720\n",
        "        image = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        \n",
        "        # Basketball court background (brown/tan)\n",
        "        court_color = (139, 115, 85)  # Brown color in BGR\n",
        "        image[:] = court_color\n",
        "        \n",
        "        # Draw court lines (white)\n",
        "        line_color = (255, 255, 255)\n",
        "        line_thickness = 3\n",
        "        \n",
        "        # Center line\n",
        "        cv2.line(image, (width//2, 0), (width//2, height), line_color, line_thickness)\n",
        "        \n",
        "        # Center circle\n",
        "        cv2.circle(image, (width//2, height//2), 100, line_color, line_thickness)\n",
        "        \n",
        "        # Free throw lines\n",
        "        ft_line_y = height // 4\n",
        "        cv2.line(image, (0, ft_line_y), (width, ft_line_y), line_color, line_thickness)\n",
        "        cv2.line(image, (0, height - ft_line_y), (width, height - ft_line_y), line_color, line_thickness)\n",
        "        \n",
        "        # Add some \"players\" (rectangles representing people)\n",
        "        player_color = (255, 0, 0)  # Blue jerseys\n",
        "        player_positions = [\n",
        "            (200, 300, 60, 120),  # x, y, width, height\n",
        "            (400, 400, 60, 120),\n",
        "            (800, 350, 60, 120),\n",
        "            (1000, 250, 60, 120),\n",
        "            (600, 500, 60, 120),\n",
        "        ]\n",
        "        \n",
        "        for x, y, w, h in player_positions:\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), player_color, -1)\n",
        "            # Add head (circle)\n",
        "            cv2.circle(image, (x + w//2, y - 20), 15, (255, 200, 150), -1)\n",
        "        \n",
        "        # Add a \"basketball\" (orange circle)\n",
        "        ball_center = (640, 360)  # Center of image\n",
        "        ball_radius = 15\n",
        "        ball_color = (0, 165, 255)  # Orange in BGR\n",
        "        cv2.circle(image, ball_center, ball_radius, ball_color, -1)\n",
        "        \n",
        "        # Add some lines to make it look more like a basketball\n",
        "        cv2.line(image, (ball_center[0] - ball_radius, ball_center[1]), \n",
        "                (ball_center[0] + ball_radius, ball_center[1]), (0, 0, 0), 2)\n",
        "        cv2.line(image, (ball_center[0], ball_center[1] - ball_radius), \n",
        "                (ball_center[0], ball_center[1] + ball_radius), (0, 0, 0), 2)\n",
        "        \n",
        "        return image\n",
        "    \n",
        "    def load_yolo_model(self):\n",
        "        \"\"\"Load the YOLO model.\"\"\"\n",
        "        print(f\"\\nLoading YOLO model: {self.model_name}\")\n",
        "        \n",
        "        try:\n",
        "            # Load model\n",
        "            self.model = YOLO(self.model_name)\n",
        "            \n",
        "            # Move to appropriate device\n",
        "            if self.device == \"cuda\":\n",
        "                self.model.to('cuda')\n",
        "            \n",
        "            print(f\"Model loaded successfully on {self.device}\")\n",
        "            print(f\"Model classes: {len(self.model.names)} total\")\n",
        "            \n",
        "            # Show relevant classes for basketball\n",
        "\n",
        "%%writefile ../../.devcontainer/validate_gpu.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "YOLO Basketball Detection Test\n",
        "Tests YOLO functionality on basketball images to ensure the package works correctly.\n",
        "\"\"\"\n",
        "            for class_id, class_name in relevant_classes.items():\n",
        "                if class_id in self.model.names:\n",
        "                    print(f\"  {class_id}: {self.model.names[class_id]}\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading YOLO model: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def test_yolo_detection(self):\n",
        "        \"\"\"Test YOLO detection on the basketball image.\"\"\"\n",
        "        print(f\"\\nTesting YOLO detection on {self.test_image_path}\")\n",
        "        \n",
        "        # Load image\n",
        "        image = cv2.imread(str(self.test_image_path))\n",
        "        if image is None:\n",
        "            print(f\"Error: Could not load image from {self.test_image_path}\")\n",
        "            return False\n",
        "        \n",
        "        print(f\"Image loaded: {image.shape}\")\n",
        "        \n",
        "        try:\n",
        "            # Run detection\n",
        "            print(\"Running YOLO detection...\")\n",
        "            results = self.model(\n",
        "                image,\n",
        "                conf=0.25,  # Lower confidence for testing\n",
        "                iou=0.45,\n",
        "                verbose=False\n",
        "            )\n",
        "            \n",
        "            # Process results\n",
        "            detections = results[0]\n",
        "            \n",
        "            print(f\"Detection completed!\")\n",
        "            print(f\"Number of detections: {len(detections.boxes) if detections.boxes is not None else 0}\")\n",
        "            \n",
        "            # Analyze detections\n",
        "            detection_summary = self._analyze_detections(detections)\n",
        "            \n",
        "            # Create annotated image\n",
        "            annotated_image = self._create_annotated_image(image, detections)\n",
        "            \n",
        "            # Save results\n",
        "            output_path = self.output_dir / \"basketball_test_result.jpg\"\n",
        "            cv2.imwrite(str(output_path), annotated_image)\n",
        "            print(f\"Annotated result saved to: {output_path}\")\n",
        "            \n",
        "            return True, detection_summary, str(output_path)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error during YOLO detection: {e}\")\n",
        "            return False, None, None\n",
        "    \n",
        "    def _analyze_detections(self, detections):\n",
        "        \"\"\"Analyze detection results.\"\"\"\n",
        "        summary = {\n",
        "            'total_detections': 0,\n",
        "            'persons': 0,\n",
        "            'sports_balls': 0,\n",
        "            'other_objects': 0,\n",
        "            'confidence_scores': [],\n",
        "            'class_names': []\n",
        "        }\n",
        "        \n",
        "        if detections.boxes is None:\n",
        "            print(\"No detections found.\")\n",
        "            return summary\n",
        "        \n",
        "        boxes = detections.boxes\n",
        "        summary['total_detections'] = len(boxes)\n",
        "        \n",
        "        for i in range(len(boxes)):\n",
        "            class_id = int(boxes.cls[i])\n",
        "            confidence = float(boxes.conf[i])\n",
        "            class_name = self.model.names[class_id]\n",
        "            \n",
        "            summary['confidence_scores'].append(confidence)\n",
        "            summary['class_names'].append(class_name)\n",
        "            \n",
        "            if class_id == 0:  # person\n",
        "                summary['persons'] += 1\n",
        "            elif class_id == 32:  # sports ball\n",
        "                summary['sports_balls'] += 1\n",
        "            else:\n",
        "                summary['other_objects'] += 1\n",
        "            \n",
        "            print(f\"  Detection {i+1}: {class_name} (confidence: {confidence:.3f})\")\n",
        "        \n",
        "        return summary\n",
        "    \n",
        "    def _create_annotated_image(self, image, detections):\n",
        "        \"\"\"Create annotated image with detection results.\"\"\"\n",
        "        annotated = image.copy()\n",
        "        \n",
        "        if detections.boxes is None:\n",
        "            return annotated\n",
        "        \n",
        "        boxes = detections.boxes\n",
        "        \n",
        "        for i in range(len(boxes)):\n",
        "            # Get box coordinates\n",
        "            x1, y1, x2, y2 = boxes.xyxy[i].int().tolist()\n",
        "            class_id = int(boxes.cls[i])\n",
        "            confidence = float(boxes.conf[i])\n",
        "            class_name = self.model.names[class_id]\n",
        "            \n",
        "            # Choose color based on class\n",
        "            if class_id == 0:  # person\n",
        "                color = (255, 0, 0)  # Blue\n",
        "            elif class_id == 32:  # sports ball\n",
        "                color = (0, 255, 255)  # Yellow\n",
        "            else:\n",
        "                color = (0, 255, 0)  # Green\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
        "            \n",
        "            # Draw label\n",
        "            label = f\"{class_name}: {confidence:.2f}\"\n",
        "            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
        "            cv2.rectangle(annotated, (x1, y1 - label_size[1] - 10), \n",
        "                         (x1 + label_size[0], y1), color, -1)\n",
        "            cv2.putText(annotated, label, (x1, y1 - 5), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "        \n",
        "        return annotated\n",
        "    \n",
        "    def display_results(self, image_path, annotated_path):\n",
        "        \"\"\"Display the original and annotated images.\"\"\"\n",
        "        try:\n",
        "            # Load images\n",
        "            original = cv2.imread(image_path)\n",
        "            annotated = cv2.imread(annotated_path)\n",
        "            \n",
        "            # Convert BGR to RGB for matplotlib\n",
        "            original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
        "            annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # Create subplot\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
        "            \n",
        "            axes[0].imshow(original_rgb)\n",
        "            axes[0].set_title(\"Original Basketball Test Image\")\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            axes[1].imshow(annotated_rgb)\n",
        "            axes[1].set_title(\"YOLO Detection Results\")\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error displaying results: {e}\")\n",
        "    \n",
        "    def run_full_test(self):\n",
        "        \"\"\"Run the complete YOLO basketball test.\"\"\"\n",
        "        print(\"Starting YOLO Basketball Detection Test...\")\n",
        "        \n",
        "        # Step 1: Setup environment\n",
        "        self.setup_test_environment()\n",
        "        \n",
        "        # Step 2: Load YOLO model\n",
        "        if not self.load_yolo_model():\n",
        "            print(\"Failed to load YOLO model. Test aborted.\")\n",
        "            return False\n",
        "        \n",
        "        # Step 3: Test detection\n",
        "        success, summary, output_path = self.test_yolo_detection()\n",
        "        \n",
        "        if not success:\n",
        "            print(\"YOLO detection test failed.\")\n",
        "            return False\n",
        "        \n",
        "        # Step 4: Display results\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TEST RESULTS SUMMARY\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Total detections: {summary['total_detections']}\")\n",
        "        print(f\"Persons detected: {summary['persons']}\")\n",
        "        print(f\"Sports balls detected: {summary['sports_balls']}\")\n",
        "        print(f\"Other objects detected: {summary['other_objects']}\")\n",
        "        \n",
        "        if summary['confidence_scores']:\n",
        "            avg_confidence = np.mean(summary['confidence_scores'])\n",
        "            print(f\"Average confidence: {avg_confidence:.3f}\")\n",
        "        \n",
        "        print(f\"Results saved to: {output_path}\")\n",
        "        \n",
        "        # Step 5: Visual display (if in Jupyter/interactive environment)\n",
        "        try:\n",
        "            self.display_results(str(self.test_image_path), output_path)\n",
        "        except:\n",
        "            print(\"Note: Visual display not available (likely running in non-interactive mode)\")\n",
        "        \n",
        "        print(\"\\n✅ YOLO Basketball Detection Test COMPLETED SUCCESSFULLY!\")\n",
        "        return True\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the test.\"\"\"\n",
        "    import argparse\n",
        "    \n",
        "    parser = argparse.ArgumentParser(description=\"Test YOLO on basketball images\")\n",
        "    parser.add_argument(\"--model\", default=\"yolov8n.pt\", help=\"YOLO model to use\")\n",
        "    parser.add_argument(\"--cpu\", action=\"store_true\", help=\"Force CPU usage\")\n",
        "    parser.add_argument(\"--image\", help=\"Path to custom test image\")\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    # Create tester\n",
        "    tester = YOLOBasketballTester(model_name=args.model, force_cpu=args.cpu)\n",
        "    \n",
        "    # Use custom image if provided\n",
        "    if args.image and os.path.exists(args.image):\n",
        "        tester.test_image_path = Path(args.image)\n",
        "        print(f\"Using custom test image: {args.image}\")\n",
        "    \n",
        "    # Run test\n",
        "    success = tester.run_full_test()\n",
        "    \n",
        "    return 0 if success else 1\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    exit(main())"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Verification\n",
        "\n",
        "Now let's test that our environment setup is working correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_pytorch.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_pytorch.py\n",
        "print(\"PyTorch quick check\")\n",
        "try:\n",
        "    import torch\n",
        "    print(\"version:\", torch.__version__)\n",
        "    print(\"cuda:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"devices:\", torch.cuda.device_count())\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            print(i, torch.cuda.get_device_name(i))\n",
        "        x = torch.ones(100, 100, device='cuda:0')\n",
        "        print(\"sum:\", float(torch.sum(x)))\n",
        "except Exception as e:\n",
        "    print(\"error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_uv.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_uv.py\n",
        "# Test other critical packages\n",
        "print(\"\\n📦 Testing other critical packages...\")\n",
        "\n",
        "packages_to_test = [\n",
        "    'numpy', 'pandas', 'matplotlib', 'scipy', 'sklearn', \n",
        "    'jupyterlab', 'seaborn', 'tqdm'\n",
        "]\n",
        "\n",
        "for package in packages_to_test:\n",
        "    try:\n",
        "        if package == 'sklearn':\n",
        "            import sklearn\n",
        "            version = sklearn.__version__\n",
        "        else:\n",
        "            module = __import__(package)\n",
        "            version = getattr(module, '__version__', 'unknown')\n",
        "        print(f\"   ✅ {package}: {version}\")\n",
        "    except ImportError:\n",
        "        print(f\"   ❌ {package}: Not installed\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  {package}: Error - {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_summary.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_summary.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"Aggregated checks for the devcontainer layout and GPU readiness.\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "\n",
        "def section(t):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(t)\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def test_structure() -> bool:\n",
        "    section(\"STRUCTURE\")\n",
        "    expected = [\n",
        "        '/workspace/docker-compose.yml',\n",
        "        '/workspace/pyproject.toml',\n",
        "        '/workspace/.devcontainer/devcontainer.json',\n",
        "        '/workspace/.devcontainer/Dockerfile',\n",
        "        '/workspace/.devcontainer/.env.template',\n",
        "        '/workspace/.devcontainer/.dockerignore',\n",
        "        '/app/validate_gpu.py',\n",
        "        '/app/tests/'\n",
        "    ]\n",
        "    ok = True\n",
        "    for p in expected:\n",
        "        if os.path.exists(p):\n",
        "            print(\"ok:\", p)\n",
        "        else:\n",
        "            print(\"missing:\", p)\n",
        "            ok = False\n",
        "    return ok\n",
        "\n",
        "\n",
        "def test_uv() -> bool:\n",
        "    section(\"UV\")\n",
        "    try:\n",
        "        r = subprocess.run(['uv', '--version'], capture_output=True, text=True)\n",
        "        print(r.stdout.strip() or r.stderr.strip())\n",
        "        return r.returncode == 0\n",
        "    except FileNotFoundError:\n",
        "        print('uv not in PATH')\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_pytorch() -> bool:\n",
        "    section(\"PYTORCH\")\n",
        "    try:\n",
        "        import torch\n",
        "        print(\"version:\", torch.__version__)\n",
        "        print(\"cuda:\", torch.cuda.is_available())\n",
        "        if torch.cuda.is_available():\n",
        "            d = torch.device('cuda:0')\n",
        "            x = torch.ones(512, 512, device=d)\n",
        "            y = torch.sum(x)\n",
        "            print(\"sum:\", y.item())\n",
        "            return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(\"error:\", e)\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_jax() -> bool:\n",
        "    section(\"JAX\")\n",
        "    try:\n",
        "        import jax, jax.numpy as jnp\n",
        "\n",
        "        # Show all devices for visibility\n",
        "        devs = jax.devices()\n",
        "        print(\"devices:\", devs)\n",
        "\n",
        "        # Prefer the supported filtered query\n",
        "        gpus = jax.devices(\"gpu\")\n",
        "\n",
        "        # Fallback for older/newer renderings (e.g., \"CudaDevice(id=0)\")\n",
        "        if not gpus:\n",
        "            gpus = [\n",
        "                d for d in devs\n",
        "                if getattr(d, \"platform\", \"\").lower() in {\"gpu\", \"cuda\"} or \"cuda\" in str(d).lower()\n",
        "            ]\n",
        "\n",
        "        if not gpus:\n",
        "            print(\"no gpu devices detected by jax\")\n",
        "            return False\n",
        "\n",
        "        # Tiny compute on the first GPU to ensure execution\n",
        "        x = jnp.ones((512, 512), dtype=jnp.float32)\n",
        "        x = jax.device_put(x, gpus[0])\n",
        "        s = jnp.sum(x).block_until_ready()\n",
        "        print(\"sum:\", float(s))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"error:\", e)\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "def main() -> int:\n",
        "    s_ok = test_structure()\n",
        "    uv_ok = test_uv()\n",
        "    pt_ok = test_pytorch()\n",
        "    j_ok = test_jax()\n",
        "\n",
        "    section(\"SUMMARY\")\n",
        "    print(\"structure:\", s_ok, \"uv:\", uv_ok, \"pytorch:\", pt_ok, \"jax:\", j_ok)\n",
        "    return 0 if all([s_ok, uv_ok, pt_ok, j_ok]) else 1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Streamlined Docker Development Environment Setup\n",
        "\n",
        "This notebook sets up a streamlined Docker-based development environment with:\n",
        "- PyTorch with GPU support (official base image)\n",
        "- UV package manager for fast dependency resolution\n",
        "- VS Code devcontainer integration\n",
        "- Simplified configuration and testing\n",
        "\n",
        "**Key improvements over previous setup:**\n",
        "- ~40% faster build time using official PyTorch base image\n",
        "- Simplified environment configuration\n",
        "- PyTorch/Jax-focused GPU acceleration\n",
        "\n",
        "goal: have a container that can utilize jax and pytorch on gpu on a nvidia 4090 gpu. Let's ensure that each of the requirements are set and that once in the container it have the uv environemnt set up as well for development. It should show errors and the root of the problem otherwise, so have plenty of healthchecks to ensure everything is going correctly.  \n",
        "\n",
        "├── pyproject.toml ( for local development)\n",
        "└── .devcontainer/\n",
        "    ├── docker-compose.yml\n",
        "    ├── Dockerfile (for docker build)\n",
        "    ├── devcontainer.json\n",
        "    ├── .env.template\n",
        "    ├── .dockerignore\n",
        "    ├── validate_gpu.py\n",
        "    └── tests/\n",
        "        ├── test_summary.py\n",
        "        ├── test_pytorch.py\n",
        "        ├── test_pytorch_gpu.py\n",
        "        └── test_uv.py\n",
        "        └── test_yolo.py\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "1. [Environment Files](#environment-files)\n",
        "2. [DevContainer Configuration](#devcontainer-configuration)\n",
        "3. [Docker Setup](#docker-setup)\n",
        "4. [Testing & Diagnostics](#testing--diagnostics)\n",
        "5. [Verification](#verification)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Environment Files\n",
        "\n",
        "First, let's create the necessary environment configuration files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/.env.template\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/.env.template\n",
        "# =============================================================================\n",
        "# CONTAINER CONFIGURATION - Primary Settings\n",
        "# =============================================================================\n",
        "ENV_NAME=docker_dev_template\n",
        "\n",
        "# =============================================================================\n",
        "# DOCKER & CUDA CONFIGURATION  \n",
        "# =============================================================================\n",
        "CUDA_TAG=12.4.0\n",
        "DOCKER_BUILDKIT=1\n",
        "\n",
        "# =============================================================================\n",
        "# HOST PORT MAPPINGS - ENHANCED with Computer Vision Services\n",
        "# =============================================================================\n",
        "HOST_JUPYTER_PORT=8895\n",
        "HOST_TENSORBOARD_PORT=6005\n",
        "HOST_EXPLAINER_PORT=8055\n",
        "HOST_STREAMLIT_PORT=8505\n",
        "HOST_MLFLOW_PORT=5005\n",
        "\n",
        "# ▶ Computer Vision Service Ports - INTEGRATED\n",
        "HOST_CV_API_PORT=8080\n",
        "HOST_CV_STREAM_PORT=8554\n",
        "\n",
        "# =============================================================================\n",
        "# PYTHON & RUNTIME CONFIGURATION\n",
        "# =============================================================================\n",
        "PYTHON_VER=3.10\n",
        "\n",
        "# =============================================================================\n",
        "# GPU MEMORY MANAGEMENT - ENHANCED for PyTorch + JAX + Computer Vision\n",
        "# =============================================================================\n",
        "JAX_PLATFORM_NAME=\n",
        "\n",
        "# Optimized for RTX 4090 - PyTorch + JAX + Computer Vision memory sharing\n",
        "XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "XLA_PYTHON_CLIENT_ALLOCATOR=platform  \n",
        "XLA_PYTHON_CLIENT_MEM_FRACTION=0.35\n",
        "XLA_FLAGS=--xla_force_host_platform_device_count=1\n",
        "JAX_DISABLE_JIT=false\n",
        "JAX_ENABLE_X64=false\n",
        "JAX_PREALLOCATION_SIZE_LIMIT_BYTES=10737418240\n",
        "\n",
        "# PyTorch memory management for RTX 4090 with CV workloads\n",
        "PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True,roundup_power2_divisions:16\n",
        "\n",
        "# =============================================================================\n",
        "# JUPYTER CONFIGURATION\n",
        "# =============================================================================\n",
        "JUPYTER_TOKEN=jupyter\n",
        "\n",
        "# =============================================================================\n",
        "# UV PACKAGE MANAGER CONFIGURATION\n",
        "# =============================================================================\n",
        "UV_PROJECT_ENVIRONMENT=/app/.venv\n",
        "\n",
        "# =============================================================================\n",
        "# ▶ COMPUTER VISION CONFIGURATION - INTEGRATED\n",
        "# =============================================================================\n",
        "\n",
        "# Roboflow API Configuration\n",
        "# IMPORTANT: Replace the placeholder below with your actual API key\n",
        "# Get your API key from: https://app.roboflow.com/settings/api\n",
        "ROBOFLOW_API_KEY=ROBOFLOW_API_KEY\n",
        "ROBOFLOW_WORKSPACE=basketball-formations\n",
        "ROBOFLOW_PROJECT=basketball-court-detection-2-mlopt\n",
        "ROBOFLOW_VERSION=1\n",
        "\n",
        "\n",
        "# Computer Vision Environment Variables\n",
        "YOLO_VERBOSE=false\n",
        "OPENCV_LOG_LEVEL=ERROR\n",
        "\n",
        "# Display Configuration for GUI Support\n",
        "DISPLAY=:0\n",
        "QT_X11_NO_MITSHM=1\n",
        "LIBGL_ALWAYS_INDIRECT=1\n",
        "\n",
        "# Video Processing Configuration\n",
        "VIDEO_INPUT_DIR=/workspace/videos/input\n",
        "VIDEO_OUTPUT_DIR=/workspace/videos/output\n",
        "\n",
        "# OpenCV Configuration\n",
        "OPENCV_VIDEOIO_PRIORITY_GSTREAMER=0\n",
        "\n",
        "# Model Storage Configuration\n",
        "YOLO_MODELS_DIR=/app/weights\n",
        "CV_MODELS_DIR=/app/models\n",
        "CV_DATA_DIR=/app/data\n",
        "\n",
        "# =============================================================================\n",
        "# BASKETBALL-SPECIFIC CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "# Basketball court detection model configuration\n",
        "BASKETBALL_COURT_MODEL=basketball-court-detection-2-mlopt\n",
        "PLAYER_DETECTION_MODEL=yolov8n.pt\n",
        "BALL_DETECTION_MODEL=basketball-ball-detection\n",
        "\n",
        "# Tracking configuration for basketball\n",
        "TRACKING_MAX_AGE=30\n",
        "TRACKING_IOU_THRESHOLD=0.3\n",
        "TRACKING_CONFIDENCE_THRESHOLD=0.5\n",
        "\n",
        "# Basketball-specific processing parameters\n",
        "COURT_DETECTION_CONFIDENCE=0.7\n",
        "PLAYER_DETECTION_CONFIDENCE=0.5\n",
        "BALL_DETECTION_CONFIDENCE=0.4\n",
        "\n",
        "# =============================================================================\n",
        "# KAGGLE AUTHENTICATION (Optional)\n",
        "# =============================================================================\n",
        "KAGGLE_USERNAME=geoffhadfield \n",
        "KAGGLE_KEY=your_api_token\n",
        "\n",
        "# =============================================================================\n",
        "# ADDITIONAL ENVIRONMENT VARIABLES FOR DEVELOPMENT\n",
        "# =============================================================================\n",
        "\n",
        "# Python environment optimization\n",
        "PYTHONUNBUFFERED=1\n",
        "PYTHONHASHSEED=random\n",
        "\n",
        "# Disable certain warnings for cleaner output\n",
        "PYTHONWARNINGS=ignore::UserWarning\n",
        "TF_CPP_MIN_LOG_LEVEL=2\n",
        "\n",
        "# Memory optimization for large datasets\n",
        "MALLOC_ARENA_MAX=2\n",
        "MALLOC_TCACHE_MAX=0\n",
        "\n",
        "# OpenMP configuration for multi-threading\n",
        "OMP_NUM_THREADS=4\n",
        "MKL_NUM_THREADS=4\n",
        "\n",
        "# Development flags\n",
        "DEBUG_MODE=false\n",
        "VERBOSE_LOGGING=false"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/.dockerignore\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/.dockerignore\n",
        "# Reduce Docker build context\n",
        ".git\n",
        ".gitignore\n",
        ".gitattributes\n",
        ".gitmodules\n",
        ".vscode\n",
        ".idea\n",
        "*.swp\n",
        "*.swo\n",
        "*~\n",
        ".DS_Store\n",
        "Thumbs.db\n",
        "__pycache__\n",
        "*.pyc\n",
        "*.pyo\n",
        "*.pyd\n",
        ".Python\n",
        "*.so\n",
        ".coverage*\n",
        ".cache\n",
        ".pytest_cache\n",
        ".mypy_cache\n",
        ".tox\n",
        "pip-log.txt\n",
        "pip-delete-this-directory.txt\n",
        "env\n",
        "venv\n",
        "ENV\n",
        "env.bak\n",
        "venv.bak\n",
        ".ipynb_checkpoints\n",
        "# Large data (adjust as needed)\n",
        "data/raw\n",
        "data/external\n",
        "*.csv\n",
        "*.parquet\n",
        "*.h5\n",
        "*.hdf5\n",
        "# Models\n",
        "*.pt\n",
        "*.pth\n",
        "*.pkl\n",
        "*.joblib\n",
        "models/\n",
        "# Logs and temps\n",
        "*.log\n",
        "logs/\n",
        "*.tmp\n",
        "*.temp\n",
        ".tmp\n",
        "temp/\n",
        "# Build artifacts\n",
        "build/\n",
        "dist/\n",
        "*.egg-info/\n",
        ".eggs/\n",
        "# Node\n",
        "node_modules\n",
        "npm-debug.log*\n",
        "yarn-*.log*\n",
        ".npm\n",
        ".eslintcache\n",
        ".node_repl_history\n",
        "*.tgz\n",
        "*.tar.gz\n",
        "# Archives\n",
        "*.zip\n",
        "*.tar\n",
        "*.tar.bz2\n",
        "*.rar\n",
        "*.7z\n",
        "# Docs (opt‑in if needed)\n",
        "docs/\n",
        "*.md\n",
        "README*\n",
        "LICENSE*\n",
        "CHANGELOG*\n",
        "# Tests (opt‑in if needed)\n",
        "tests/\n",
        "test_*\n",
        "*_test.py\n",
        "# CI\n",
        ".github/\n",
        ".gitlab-ci.yml\n",
        ".travis.yml\n",
        ".circleci/\n",
        "azure-pipelines.yml\n",
        "# Env\n",
        ".env\n",
        ".env.local\n",
        ".env.*.local\n",
        ".editorconfig\n",
        ".prettierrc*\n",
        ".eslintrc*\n",
        "# Universal junk (de‑duped)\n",
        "*.py[cod]"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## DevContainer Configuration\n",
        "\n",
        "Setting up the VS Code devcontainer configuration files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/devcontainer.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/devcontainer.json\n",
        "{\n",
        "  \"name\": \"docker_dev_template\",\n",
        "  \"dockerComposeFile\": \"docker-compose.yml\",\n",
        "  \"service\": \"datascience\",\n",
        "  \"workspaceFolder\": \"/workspace\",\n",
        "  \"shutdownAction\": \"stopCompose\",\n",
        "\n",
        "  \"overrideCommand\": false,\n",
        "  \n",
        "  \"containerEnv\": {\n",
        "    \"CONTAINER_WORKSPACE_FOLDER\": \"/workspace\",\n",
        "    \"UV_PROJECT_ENVIRONMENT\": \"/app/.venv\",\n",
        "    \"VIRTUAL_ENV\": \"/app/.venv\",\n",
        "    \"PYTHONPATH\": \"/workspace\",\n",
        "    \"TERM\": \"xterm-256color\",\n",
        "    \"DEBIAN_FRONTEND\": \"noninteractive\"\n",
        "  },\n",
        "\n",
        "  \"runArgs\": [\n",
        "    \"--gpus\", \"all\",\n",
        "    \"--name\", \"${localEnv:ENV_NAME:docker_dev_template}_datascience\",\n",
        "    \"--shm-size\", \"16g\"\n",
        "  ],\n",
        "\n",
        "  \"customizations\": {\n",
        "    \"vscode\": {\n",
        "      \"settings\": {\n",
        "        \"python.defaultInterpreterPath\": \"/app/.venv/bin/python\",\n",
        "        \"python.pythonPath\": \"/app/.venv/bin/python\",\n",
        "        \"python.terminal.activateEnvironment\": true,\n",
        "        \"python.terminal.activateEnvInCurrentTerminal\": true,\n",
        "        \n",
        "        \"terminal.integrated.defaultProfile.linux\": \"bash\",\n",
        "        \"terminal.integrated.profiles.linux\": {\n",
        "          \"bash\": {\n",
        "            \"path\": \"/bin/bash\",\n",
        "            \"args\": [\"-l\"],\n",
        "            \"env\": {\n",
        "              \"VIRTUAL_ENV\": \"/app/.venv\",\n",
        "              \"PATH\": \"/app/.venv/bin:${env:PATH}\",\n",
        "              \"UV_PROJECT_ENVIRONMENT\": \"/app/.venv\",\n",
        "              \"PYTHONPATH\": \"/workspace\"\n",
        "            }\n",
        "          }\n",
        "        },\n",
        "        \n",
        "        \"jupyter.notebookFileRoot\": \"/workspace\",\n",
        "        \"jupyter.kernels.filter\": [\n",
        "          {\n",
        "            \"path\": \"/app/.venv/bin/python\",\n",
        "            \"type\": \"pythonEnvironment\"\n",
        "          }\n",
        "        ],\n",
        "        \"jupyter.interactiveWindow.creationMode\": \"perFile\",\n",
        "        \n",
        "        \"files.watcherExclude\": {\n",
        "          \"**/.git/**\": true,\n",
        "          \"**/node_modules/**\": true,\n",
        "          \"**/__pycache__/**\": true,\n",
        "          \"**/.pytest_cache/**\": true,\n",
        "          \"**/.venv/**\": true,\n",
        "          \"**/videos/**\": true,\n",
        "          \"**/models/**\": true,\n",
        "          \"**/weights/**\": true\n",
        "        },\n",
        "        \n",
        "        \"files.associations\": {\n",
        "          \"*.py\": \"python\",\n",
        "          \"*.ipynb\": \"jupyter-notebook\",\n",
        "          \"*.yml\": \"yaml\",\n",
        "          \"*.yaml\": \"yaml\",\n",
        "          \"*.toml\": \"toml\"\n",
        "        },\n",
        "\n",
        "        \"python.analysis.extraPaths\": [\n",
        "          \"/workspace\",\n",
        "          \"/app/.venv/lib/python3.10/site-packages\"\n",
        "        ],\n",
        "        \n",
        "        \"python.linting.enabled\": true,\n",
        "        \"python.linting.pylintEnabled\": false,\n",
        "        \"python.linting.flake8Enabled\": true,\n",
        "        \"python.formatting.provider\": \"black\",\n",
        "        \"python.defaultInterpreterPath\": \"/app/.venv/bin/python\",\n",
        "        \n",
        "        \"[python]\": {\n",
        "          \"editor.formatOnSave\": true,\n",
        "          \"editor.codeActionsOnSave\": {\n",
        "            \"source.organizeImports\": true\n",
        "          }\n",
        "        },\n",
        "        \n",
        "        \"docker.showStartPage\": false,\n",
        "        \"git.autofetch\": true,\n",
        "        \"editor.minimap.enabled\": false,\n",
        "        \"workbench.colorTheme\": \"Default Dark+\",\n",
        "        \"editor.fontSize\": 14,\n",
        "        \"terminal.integrated.fontSize\": 13\n",
        "      },\n",
        "      \n",
        "      \"extensions\": [\n",
        "        \"ms-python.python\",\n",
        "        \"ms-python.flake8\", \n",
        "        \"ms-python.black-formatter\",\n",
        "        \"ms-toolsai.jupyter\",\n",
        "        \"ms-azuretools.vscode-docker\",\n",
        "        \"ms-vscode.makefile-tools\",\n",
        "        \"tamasfe.even-better-toml\",\n",
        "        \"ms-vscode.vscode-json\",\n",
        "        \"redhat.vscode-yaml\",\n",
        "        \"ms-python.mypy-type-checker\",\n",
        "        \"ms-toolsai.vscode-ai\",\n",
        "        \"github.copilot\",\n",
        "        \"github.copilot-chat\",\n",
        "        \"ms-toolsai.vscode-jupyter-powertoys\"\n",
        "      ]\n",
        "    }\n",
        "  },\n",
        "\n",
        "  \"onCreateCommand\": {\n",
        "    \"validate-environment\": [\n",
        "      \"bash\", \"-lc\", \n",
        "      \"set -e && echo '[ON-CREATE] Validating environment...' && ls -la /app/.venv/bin/ || echo 'Virtual env not ready' && which python || echo 'Python not found in PATH' && echo '[ON-CREATE] Creating CV directories...' && mkdir -p /app/models /app/weights /workspace/videos/input /workspace/videos/output && echo '[ON-CREATE] Validation complete'\"\n",
        "    ]\n",
        "  },\n",
        "\n",
        "  \"postCreateCommand\": {\n",
        "    \"setup-enhanced-environment\": [\n",
        "      \"bash\", \"-lc\",\n",
        "      \"set -e && echo '[POST-CREATE] Setting up enhanced development environment...' && source /app/.venv/bin/activate && echo '[POST-CREATE] Environment activated' && python -c 'import sys; print(f\\\"Python: {sys.executable}\\\")' && echo '[POST-CREATE] Installing Jupyter kernel...' && python -m ipykernel install --user --name=docker-dev-cv --display-name='Docker Dev CV Environment' && echo '[POST-CREATE] Jupyter kernel installed' && echo '[POST-CREATE] Testing core packages...' && python -c 'import torch, jax, cv2; print(\\\"Core packages: OK\\\")' && echo '[POST-CREATE] Setup completed successfully!'\"\n",
        "    ]\n",
        "  },\n",
        "\n",
        "  \"postStartCommand\": {\n",
        "    \"validate-full-stack\": [\n",
        "      \"bash\", \"-lc\",\n",
        "      \"echo '[POST-START] Running full stack validation...' && source /app/.venv/bin/activate && echo '[POST-START] Environment activated' && python --version && echo '[POST-START] Testing GPU integration...' && python -c 'import torch; print(f\\\"PyTorch CUDA: {torch.cuda.is_available()}\\\")' || echo 'PyTorch GPU validation failed' && python -c 'import jax; gpus=[d for d in jax.devices() if \\\"gpu\\\" in str(d).lower()]; print(f\\\"JAX GPUs: {len(gpus)}\\\")' || echo 'JAX GPU validation failed' && echo '[POST-START] Container ready for development!'\"\n",
        "    ]\n",
        "  },\n",
        "\n",
        "  \"forwardPorts\": [8888, 6008, 8050, 8501, 5000, 8080, 8554],\n",
        "  \"portsAttributes\": {\n",
        "    \"8888\": { \n",
        "      \"label\": \"Jupyter Lab\", \n",
        "      \"onAutoForward\": \"notify\",\n",
        "      \"protocol\": \"http\"\n",
        "    },\n",
        "    \"6008\": { \n",
        "      \"label\": \"TensorBoard\", \n",
        "      \"onAutoForward\": \"silent\",\n",
        "      \"protocol\": \"http\"\n",
        "    },\n",
        "    \"8050\": { \n",
        "      \"label\": \"Explainer Dashboard\", \n",
        "      \"onAutoForward\": \"silent\",\n",
        "      \"protocol\": \"http\"\n",
        "    },\n",
        "    \"8501\": { \n",
        "      \"label\": \"Streamlit\", \n",
        "      \"onAutoForward\": \"silent\",\n",
        "      \"protocol\": \"http\"\n",
        "    },\n",
        "    \"5000\": { \n",
        "      \"label\": \"MLflow\", \n",
        "      \"onAutoForward\": \"silent\",\n",
        "      \"protocol\": \"http\"\n",
        "    },\n",
        "    \"8080\": { \n",
        "      \"label\": \"CV API Server\", \n",
        "      \"onAutoForward\": \"silent\",\n",
        "      \"protocol\": \"http\"\n",
        "    },\n",
        "    \"8554\": { \n",
        "      \"label\": \"RTSP Stream\", \n",
        "      \"onAutoForward\": \"silent\",\n",
        "      \"protocol\": \"rtsp\"\n",
        "    }\n",
        "  },\n",
        "\n",
        "  \"mounts\": [\n",
        "    \"source=docker_dev_template_uv_cache,target=/root/.cache/uv,type=volume\",\n",
        "    \"source=docker_dev_template_yolo_cache,target=/root/.cache/ultralytics,type=volume\",\n",
        "    \"source=docker_dev_template_roboflow_cache,target=/root/.cache/roboflow,type=volume\"\n",
        "  ],\n",
        "\n",
        "  \"features\": {},\n",
        "  \n",
        "  \"waitFor\": \"postCreateCommand\",\n",
        "  \n",
        "  \"postCreateCommand.timeout\": 600,\n",
        "  \"postStartCommand.timeout\": 180,\n",
        "\n",
        "  \"remoteUser\": \"root\",\n",
        "  \n",
        "  \"containerUser\": \"root\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/Dockerfile\n",
        "# ENHANCED Dockerfile: RTX 4090 devcontainer with UV, JAX, PyTorch, and Computer Vision (CUDA 12.x)\n",
        "# ENHANCED WITH: Better debugging, error handling, and build validation\n",
        "\n",
        "ARG CUDA_TAG=12.4.0\n",
        "FROM nvidia/cuda:${CUDA_TAG}-devel-ubuntu22.04 as runtime\n",
        "\n",
        "ARG PYTHON_VER=3.10\n",
        "ARG ENV_NAME=docker_dev_template\n",
        "ENV DEBIAN_FRONTEND=noninteractive\n",
        "\n",
        "# ADDED: Build debugging information\n",
        "RUN echo \"=================================================================\" && \\\n",
        "    echo \"STARTING BUILD: ${ENV_NAME}\" && \\\n",
        "    echo \"CUDA_TAG: ${CUDA_TAG}\" && \\\n",
        "    echo \"PYTHON_VER: ${PYTHON_VER}\" && \\\n",
        "    echo \"BASE IMAGE: nvidia/cuda:${CUDA_TAG}-devel-ubuntu22.04\" && \\\n",
        "    echo \"=================================================================\"\n",
        "\n",
        "# Enhanced system dependencies with Computer Vision additions\n",
        "RUN --mount=type=cache,id=apt-cache-${CUDA_TAG},target=/var/cache/apt,sharing=locked \\\n",
        "    --mount=type=cache,id=apt-lists-${CUDA_TAG},target=/var/lib/apt/lists,sharing=locked \\\n",
        "    echo \"STEP: Installing system dependencies...\" && \\\n",
        "    apt-get update && apt-get install -y --no-install-recommends \\\n",
        "        # CRITICAL: Essential core utilities (fixes missing commands)\n",
        "        coreutils \\\n",
        "        util-linux \\\n",
        "        # Base system packages\n",
        "        bash curl ca-certificates git procps htop \\\n",
        "        python3 python3-venv python3-pip python3-dev \\\n",
        "        build-essential cmake pkg-config \\\n",
        "        libjemalloc2 libjemalloc-dev \\\n",
        "        iproute2 net-tools lsof wget \\\n",
        "        # Additional essential tools\n",
        "        grep sed gawk findutils \\\n",
        "        # Computer Vision system dependencies\n",
        "        ffmpeg \\\n",
        "        libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1 \\\n",
        "        libgstreamer1.0-0 libgstreamer-plugins-base1.0-0 \\\n",
        "        libgtk-3-0 libgtk-3-dev \\\n",
        "        # X11 support for GUI applications (optional for headless)\n",
        "        x11-apps xauth xvfb \\\n",
        "        # Video codec libraries for comprehensive video support\n",
        "        libavcodec-dev libavformat-dev libswscale-dev \\\n",
        "        libv4l-dev libxvidcore-dev libx264-dev \\\n",
        "        # Image format libraries for OpenCV\n",
        "        libjpeg-dev libpng-dev libtiff-dev \\\n",
        "        # OpenGL support for visualization (optional)\n",
        "        libgl1-mesa-glx libglu1-mesa-dev \\\n",
        "    && apt-get clean && rm -rf /var/lib/apt/lists/* && \\\n",
        "    echo \"✅ System dependencies installed successfully\" && \\\n",
        "    echo \"STEP: Verifying essential commands...\" && \\\n",
        "    which groups && echo \"✅ groups command available\" && \\\n",
        "    which dircolors && echo \"✅ dircolors command available\" && \\\n",
        "    which uname && echo \"✅ uname command available\" && \\\n",
        "    echo \"✅ Essential commands verification complete\"\n",
        "\n",
        "# UV package manager with version validation\n",
        "COPY --from=ghcr.io/astral-sh/uv:0.7.12 /uv /uvx /bin/\n",
        "RUN echo \"STEP: Validating UV installation...\" && \\\n",
        "    uv --version && \\\n",
        "    echo \"✅ UV installed successfully\"\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "# Create venv managed by UV with debugging\n",
        "RUN echo \"STEP: Creating UV virtual environment...\" && \\\n",
        "    uv venv .venv --python \"${PYTHON_VER}\" --prompt \"${ENV_NAME}\" && \\\n",
        "    echo \"✅ Virtual environment created at /app/.venv\" && \\\n",
        "    ls -la .venv/\n",
        "\n",
        "ENV VIRTUAL_ENV=/app/.venv \\\n",
        "    PATH=\"/app/.venv/bin:${PATH}\" \\\n",
        "    UV_PROJECT_ENVIRONMENT=/app/.venv \\\n",
        "    PYTHONPATH=\"/workspace\"\n",
        "\n",
        "# Validate Python installation\n",
        "RUN echo \"STEP: Validating Python environment...\" && \\\n",
        "    bash -c \"source /app/.venv/bin/activate && python --version && which python && pip --version\" && \\\n",
        "    echo \"✅ Python environment validated\"\n",
        "\n",
        "# Enhanced memory and allocator settings for CV workloads\n",
        "ENV LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2 \\\n",
        "    MALLOC_ARENA_MAX=2 \\\n",
        "    MALLOC_TCACHE_MAX=0 \\\n",
        "    PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
        "\n",
        "# GPU-relevant environment (enhanced for CV)\n",
        "ENV XLA_PYTHON_CLIENT_PREALLOCATE=false \\\n",
        "    XLA_PYTHON_CLIENT_MEM_FRACTION=0.35 \\\n",
        "    XLA_PYTHON_CLIENT_ALLOCATOR=platform \\\n",
        "    PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True,roundup_power2_divisions:16 \\\n",
        "    JAX_PREALLOCATION_SIZE_LIMIT_BYTES=10737418240\n",
        "\n",
        "# Computer Vision specific environment variables\n",
        "ENV OPENCV_VIDEOIO_PRIORITY_GSTREAMER=0 \\\n",
        "    QT_X11_NO_MITSHM=1 \\\n",
        "    DISPLAY=:0 \\\n",
        "    YOLO_VERBOSE=false \\\n",
        "    OPENCV_LOG_LEVEL=ERROR\n",
        "\n",
        "# Create directories for CV models, data, and videos with debugging\n",
        "RUN echo \"STEP: Creating CV directories...\" && \\\n",
        "    mkdir -p /app/models /app/data /app/weights \\\n",
        "    /workspace/videos/input /workspace/videos/output && \\\n",
        "    chmod 755 /app/models /app/data /app/weights && \\\n",
        "    chmod 755 /workspace/videos /workspace/videos/input /workspace/videos/output && \\\n",
        "    echo \"✅ CV directories created:\" && \\\n",
        "    ls -la /app/ && \\\n",
        "    ls -la /workspace/\n",
        "\n",
        "# CRITICAL FIX: Check for pyproject.toml with debugging\n",
        "RUN echo \"STEP: Checking for project files...\" && \\\n",
        "    echo \"Current working directory: $(pwd)\" && \\\n",
        "    echo \"Contents of /workspace:\" && \\\n",
        "    ls -la /workspace/ || echo \"WARNING: /workspace not accessible during build\" && \\\n",
        "    echo \"Looking for pyproject.toml in expected locations...\"\n",
        "\n",
        "# Copy project files with validation\n",
        "COPY pyproject.toml /workspace/\n",
        "RUN echo \"STEP: Validating copied project files...\" && \\\n",
        "    ls -la /workspace/pyproject.toml && \\\n",
        "    echo \"✅ pyproject.toml copied successfully\"\n",
        "\n",
        "# Copy optional lock file\n",
        "COPY uv.lock* /workspace/\n",
        "RUN echo \"Checking for uv.lock file...\" && \\\n",
        "    ls -la /workspace/uv.lock* || echo \"No uv.lock file found (will be generated)\"\n",
        "\n",
        "# Devcontainer tests and validator (enhanced)\n",
        "COPY .devcontainer/validate_gpu.py /app/validate_gpu.py\n",
        "COPY .devcontainer/tests/ /app/tests/\n",
        "RUN echo \"STEP: Validating test files...\" && \\\n",
        "    ls -la /app/validate_gpu.py /app/tests/ && \\\n",
        "    echo \"✅ Test files copied successfully\"\n",
        "\n",
        "# Resolve project dependencies with UV (enhanced with debugging)\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"STEP: Resolving UV project dependencies...\" && \\\n",
        "    cd /workspace && \\\n",
        "    echo \"Current directory: $(pwd)\" && \\\n",
        "    echo \"Contents:\" && \\\n",
        "    ls -la && \\\n",
        "    if [ ! -f uv.lock ]; then \\\n",
        "      echo \"[uv] No uv.lock found; creating from existing pyproject.toml\"; \\\n",
        "      uv lock --refresh; \\\n",
        "    else \\\n",
        "      echo \"[uv] Using existing uv.lock\"; \\\n",
        "    fi && \\\n",
        "    echo \"✅ UV dependencies resolved\"\n",
        "\n",
        "# Install core dependencies first (excluding GPU packages)\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"STEP: Installing core dependencies...\" && \\\n",
        "    cd /workspace && \\\n",
        "    (uv sync --frozen --no-dev 2>/dev/null || \\\n",
        "     uv sync --no-dev 2>/dev/null || \\\n",
        "     (echo \"[uv] Installing basic dependencies...\" && uv add numpy pandas matplotlib scipy)) && \\\n",
        "    echo \"✅ Core dependencies installed\"\n",
        "\n",
        "# CRITICAL: Install PyTorch with CUDA 12.4 support - ENHANCED with validation\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"STEP: Installing PyTorch with CUDA 12.4...\" && \\\n",
        "    uv pip install --no-cache-dir torch torchvision torchaudio \\\n",
        "        --index-url https://download.pytorch.org/whl/cu124 && \\\n",
        "    echo \"STEP: Validating PyTorch installation...\" && \\\n",
        "    python - <<'PY'\n",
        "import torch\n",
        "print(\"✅ PyTorch version:\", torch.__version__)\n",
        "print(\"✅ PyTorch CUDA available during build:\", torch.cuda.is_available())\n",
        "print(\"✅ PyTorch CUDA version:\", torch.version.cuda if hasattr(torch.version, 'cuda') else 'Unknown')\n",
        "print(\"Note: GPU functionality will be available at runtime when container has GPU access\")\n",
        "PY\n",
        "\n",
        "# CRITICAL: Install compatible CuDNN for JAX compatibility - ENHANCED  \n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"STEP: Upgrading CuDNN to 9.8.0 for JAX compatibility...\" && \\\n",
        "    uv pip install --no-cache-dir --upgrade nvidia-cudnn-cu12==9.8.0.69 || \\\n",
        "    uv pip install --no-cache-dir --upgrade nvidia-cudnn-cu12>=9.8.0 && \\\n",
        "    echo \"✅ CuDNN installed/upgraded\"\n",
        "\n",
        "# NVJITLINK enables runtime JIT linking for CUDA 12 (helps PyTorch/JAX fused kernels)\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"STEP: Installing NVJITLINK for CUDA 12...\" && \\\n",
        "    uv pip install --no-cache-dir nvidia-nvjitlink-cu12>=12.4 && \\\n",
        "    echo \"✅ NVJITLINK installed\"\n",
        "\n",
        "# CRITICAL: Install JAX with CUDA 12 support - ENHANCED with better error handling\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"STEP: Installing JAX with CUDA 12 support...\" && \\\n",
        "    echo \"Removing any existing JAX installations...\" && \\\n",
        "    (uv pip uninstall jax jaxlib jax-cuda12-plugin jax-cuda12-pjrt || true) && \\\n",
        "    echo \"Installing JAX with CUDA 12 support...\" && \\\n",
        "    (uv pip install --no-cache-dir \"jax[cuda12-local]>=0.4.26\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html \\\n",
        "     || uv pip install --no-cache-dir \"jax[cpu]>=0.4.26\") && \\\n",
        "    echo \"STEP: Validating JAX installation...\" && \\\n",
        "    python - <<'PY'\n",
        "import jax, jaxlib\n",
        "print(\"✅ JAX version:\", jax.__version__, \"JAXLIB:\", jaxlib.__version__)\n",
        "print(\"✅ JAX devices during build:\", jax.devices())\n",
        "print(\"Note: GPU devices will be available at runtime when container has GPU access\")\n",
        "PY\n",
        "\n",
        "# NEW: Install Computer Vision packages with validation\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"STEP: Installing Computer Vision packages...\" && \\\n",
        "    # Core CV libraries with specific versions for stability\n",
        "    uv pip install --no-cache-dir --upgrade ultralytics==8.3.158 && \\\n",
        "    echo \"✅ Ultralytics installed\" && \\\n",
        "    # Object tracking and supervision libraries\n",
        "    uv pip install --no-cache-dir supervision>=0.17.0 lap>=0.4.0 && \\\n",
        "    echo \"✅ Supervision and LAP installed\" && \\\n",
        "    # Image processing and augmentation\n",
        "    uv pip install --no-cache-dir albumentations>=1.3.0 imgaug>=0.4.0 && \\\n",
        "    echo \"✅ Image processing libraries installed\" && \\\n",
        "    # OpenCV with contrib modules (headless for Docker)\n",
        "    uv pip install --no-cache-dir opencv-contrib-python-headless>=4.10.0 && \\\n",
        "    echo \"✅ OpenCV installed\" && \\\n",
        "    # Roboflow integration\n",
        "    uv pip install --no-cache-dir roboflow==1.2.9 && \\\n",
        "    echo \"✅ Roboflow installed\" && \\\n",
        "    # Video processing libraries\n",
        "    uv pip install --no-cache-dir moviepy==2.2.1 yt-dlp==2025.9.5 ffmpeg-python==0.2.0 && \\\n",
        "    echo \"✅ Video processing libraries installed\" && \\\n",
        "    echo \"✅ Computer Vision packages installed successfully\"\n",
        "\n",
        "# NEW: Pre-validate CV installation with enhanced debugging\n",
        "RUN echo \"STEP: Validating Computer Vision installation...\" && \\\n",
        "    python - <<'PY'\n",
        "print(\"=== Computer Vision Validation ===\")\n",
        "try:\n",
        "    import cv2\n",
        "    print(f\"✅ OpenCV: {cv2.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ OpenCV: {e}\")\n",
        "\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    print(\"✅ YOLO/Ultralytics: Available\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ YOLO: {e}\")\n",
        "\n",
        "try:\n",
        "    import roboflow\n",
        "    print(f\"✅ Roboflow: {roboflow.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Roboflow: {e}\")\n",
        "\n",
        "try:\n",
        "    import supervision as sv\n",
        "    print(f\"✅ Supervision: {sv.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Supervision: {e}\")\n",
        "\n",
        "print(\"✅ CV validation completed\")\n",
        "PY\n",
        "\n",
        "# Jupyter & kernel with enhanced dependencies and validation\n",
        "RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked \\\n",
        "    echo \"STEP: Installing Jupyter and kernel dependencies...\" && \\\n",
        "    uv pip install --no-cache-dir \\\n",
        "        psutil==5.9.8 \\\n",
        "        debugpy==1.8.7 \\\n",
        "        ipykernel==6.29.5 \\\n",
        "        jupyter-client==8.6.1 \\\n",
        "        jupyterlab==4.2.5 && \\\n",
        "    echo \"✅ Jupyter components installed\"\n",
        "\n",
        "# Enhanced CUDA libs path - include CV library paths\n",
        "ENV LD_LIBRARY_PATH=\"/app/.venv/lib:/app/.venv/lib/python3.10/site-packages/nvidia/cudnn/lib:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}\"\n",
        "\n",
        "# Enhanced shell activation helper with CV environment and debugging\n",
        "RUN echo \"STEP: Creating robust shell activation helper...\" && \\\n",
        "    echo '#!/bin/bash' > /app/activate_uv.sh && \\\n",
        "    echo 'export VIRTUAL_ENV=\"/app/.venv\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'export PATH=\"/app/.venv/bin:$PATH\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'export UV_PROJECT_ENVIRONMENT=\"/app/.venv\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'export PYTHONPATH=\"/workspace:$PYTHONPATH\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'export LD_LIBRARY_PATH=\"/app/.venv/lib:/app/.venv/lib/python3.10/site-packages/nvidia/cudnn/lib:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}\"' >> /app/activate_uv.sh && \\\n",
        "    echo '# Computer Vision environment' >> /app/activate_uv.sh && \\\n",
        "    echo 'export YOLO_VERBOSE=false' >> /app/activate_uv.sh && \\\n",
        "    echo 'export OPENCV_LOG_LEVEL=ERROR' >> /app/activate_uv.sh && \\\n",
        "    echo 'export DISPLAY=${DISPLAY:-:0}' >> /app/activate_uv.sh && \\\n",
        "    echo '# Check for essential commands and provide helpful messages' >> /app/activate_uv.sh && \\\n",
        "    echo 'command -v uname >/dev/null 2>&1 || echo \"Warning: uname command not available\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'command -v groups >/dev/null 2>&1 || echo \"Warning: groups command not available\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'command -v dircolors >/dev/null 2>&1 || echo \"Warning: dircolors command not available\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'echo \"🐍 UV Environment activated: $(python --version 2>/dev/null || echo Python not found)\"' >> /app/activate_uv.sh && \\\n",
        "    echo 'cd /workspace' >> /app/activate_uv.sh && \\\n",
        "    chmod +x /app/activate_uv.sh && \\\n",
        "    echo 'source /app/activate_uv.sh' > /etc/profile.d/10-uv-activate.sh && \\\n",
        "    echo 'source /app/activate_uv.sh' >> /root/.bashrc && \\\n",
        "    chmod +x /etc/profile.d/10-uv-activate.sh && \\\n",
        "    echo \"✅ Robust shell activation helper created\"\n",
        "\n",
        "# Enhanced healthcheck with CV components and debugging\n",
        "RUN echo \"STEP: Creating enhanced healthcheck script...\" && \\\n",
        "    echo '#!/bin/bash' > /app/healthcheck.sh && \\\n",
        "    echo 'source /app/.venv/bin/activate' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== Environment Check ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python --version' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== GPU Check ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import torch; print(f\\\"PyTorch CUDA: {torch.cuda.is_available()}\\\")\" || echo \"PyTorch check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import jax; print(f\\\"JAX devices: {jax.devices()}\\\")\" || echo \"JAX check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== Computer Vision Check ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import cv2; print(f\\\"OpenCV: {cv2.__version__}\\\")\" || echo \"OpenCV check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"from ultralytics import YOLO; print(\\\"YOLO package: OK\\\")\" || echo \"YOLO package check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import roboflow; print(f\\\"Roboflow: {roboflow.__version__}\\\")\" || echo \"Roboflow check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python -c \"import supervision; print(f\\\"Supervision: {supervision.__version__}\\\")\" || echo \"Supervision check failed\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'echo \"=== Final GPU Validation ===\"' >> /app/healthcheck.sh && \\\n",
        "    echo 'python /app/validate_gpu.py --quick' >> /app/healthcheck.sh && \\\n",
        "    chmod +x /app/healthcheck.sh && \\\n",
        "    echo \"✅ Enhanced healthcheck script created\"\n",
        "\n",
        "# Final validation step\n",
        "RUN echo \"=================================================================\" && \\\n",
        "    echo \"BUILD COMPLETE: ${ENV_NAME}\" && \\\n",
        "    echo \"CUDA_TAG: ${CUDA_TAG}\" && \\\n",
        "    echo \"PYTHON_VER: ${PYTHON_VER}\" && \\\n",
        "    echo \"=================================================================\" && \\\n",
        "    echo \"Final environment validation:\" && \\\n",
        "    bash -c \"source /app/.venv/bin/activate && python --version && uv --version\" && \\\n",
        "    echo \"✅ Build completed successfully\" && \\\n",
        "    echo \"=================================================================\"\n",
        "\n",
        "WORKDIR /workspace\n",
        "CMD [\"bash\", \"-l\"]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Docker Setup\n",
        "\n",
        "Creating the Docker Compose configuration and project files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/docker-compose.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/docker-compose.yml\n",
        "# FIXED .devcontainer/docker-compose.yml - Corrected volume paths and configuration\n",
        "# KEY FIXES:\n",
        "# 1. Fixed volume paths (../mlruns instead of ./mlruns)  \n",
        "# 2. Fixed env_file reference (.env instead of .env.template)\n",
        "# 3. Added explicit image name to prevent \"ultralytics\" phantom pulls\n",
        "# 4. Enhanced debugging and error handling\n",
        "\n",
        "name: ${ENV_NAME:-docker_dev_template}\n",
        "\n",
        "services:\n",
        "  datascience:\n",
        "    build:\n",
        "      # FIXED: Build context is parent directory (project root)\n",
        "      context: ..\n",
        "      dockerfile: .devcontainer/Dockerfile\n",
        "      args:\n",
        "        CUDA_TAG: ${CUDA_TAG:-12.4.0}\n",
        "        PYTHON_VER: ${PYTHON_VER:-3.10}\n",
        "        ENV_NAME: ${ENV_NAME:-docker_dev_template}\n",
        "      cache_from:\n",
        "        - nvidia/cuda:${CUDA_TAG:-12.4.0}-devel-ubuntu22.04\n",
        "      extra_hosts:\n",
        "        - \"host.docker.internal:host-gateway\"\n",
        "      # ADDED: Explicit tags to prevent phantom image pulls\n",
        "      target: runtime\n",
        "\n",
        "    # ADDED: Explicit image name to avoid confusion\n",
        "    image: ${ENV_NAME:-docker_dev_template}_datascience:latest\n",
        "    \n",
        "    container_name: ${ENV_NAME:-docker_dev_template}_datascience\n",
        "\n",
        "    # FIXED: Reference .env file instead of .env.template\n",
        "    env_file:\n",
        "      - .env\n",
        "\n",
        "    restart: unless-stopped\n",
        "    depends_on:\n",
        "      mlflow:\n",
        "        condition: service_started\n",
        "\n",
        "    deploy:\n",
        "      resources:\n",
        "        reservations:\n",
        "          devices:\n",
        "            - driver: nvidia\n",
        "              count: all\n",
        "              capabilities: [gpu, compute, utility, video]\n",
        "\n",
        "    init: true\n",
        "    \n",
        "    # ENHANCED: GPU configuration with explicit all access\n",
        "    runtime: nvidia\n",
        "    \n",
        "    shm_size: 16g\n",
        "    ulimits:\n",
        "      memlock: -1\n",
        "      stack: 67108864\n",
        "\n",
        "    environment:\n",
        "      # Base container environment\n",
        "      - PYTHON_VER=${PYTHON_VER:-3.10}\n",
        "      - CUDA_TAG=${CUDA_TAG:-12.4.0}\n",
        "      - ENV_NAME=${ENV_NAME:-docker_dev_template}\n",
        "      - UV_PROJECT_ENVIRONMENT=/app/.venv\n",
        "      - VIRTUAL_ENV=/app/.venv\n",
        "      - PYTHONPATH=/workspace\n",
        "      - NVIDIA_VISIBLE_DEVICES=all\n",
        "      - NVIDIA_DRIVER_CAPABILITIES=all\n",
        "      - CUDA_VISIBLE_DEVICES=0\n",
        "      - LD_LIBRARY_PATH=/app/.venv/lib:/usr/local/cuda/lib64\n",
        "      - LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2\n",
        "      - MALLOC_ARENA_MAX=2\n",
        "      - MALLOC_TCACHE_MAX=0\n",
        "      - PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
        "      \n",
        "      # GPU Memory Management - Enhanced for CV workloads\n",
        "      - XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "      - XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
        "      - XLA_PYTHON_CLIENT_MEM_FRACTION=0.35\n",
        "      - XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda\n",
        "      - JAX_PREALLOCATION_SIZE_LIMIT_BYTES=10737418240\n",
        "      - JAX_DISABLE_JIT=false\n",
        "      - JAX_ENABLE_X64=false\n",
        "      - JAX_PLATFORM_NAME=\n",
        "      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024,expandable_segments:True,roundup_power2_divisions:16\n",
        "      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-jupyter}\n",
        "      \n",
        "      # Computer Vision Configuration\n",
        "      - YOLO_VERBOSE=${YOLO_VERBOSE:-false}\n",
        "      - OPENCV_LOG_LEVEL=${OPENCV_LOG_LEVEL:-ERROR}\n",
        "      - ROBOFLOW_API_KEY=${ROBOFLOW_API_KEY:-htpcxp3XQh7SsgMfjJns}\n",
        "      - ROBOFLOW_WORKSPACE=${ROBOFLOW_WORKSPACE:-basketball-formations}\n",
        "      - ROBOFLOW_PROJECT=${ROBOFLOW_PROJECT:-basketball-court-detection-2-mlopt}\n",
        "      - ROBOFLOW_VERSION=${ROBOFLOW_VERSION:-1}\n",
        "      \n",
        "      # Display configuration for GUI support\n",
        "      - DISPLAY=${DISPLAY:-:0}\n",
        "      - QT_X11_NO_MITSHM=1\n",
        "      - LIBGL_ALWAYS_INDIRECT=1\n",
        "      \n",
        "      # Video processing configuration\n",
        "      - VIDEO_INPUT_DIR=${VIDEO_INPUT_DIR:-/workspace/videos/input}\n",
        "      - VIDEO_OUTPUT_DIR=${VIDEO_OUTPUT_DIR:-/workspace/videos/output}\n",
        "      - OPENCV_VIDEOIO_PRIORITY_GSTREAMER=0\n",
        "      \n",
        "      # Model directories\n",
        "      - YOLO_MODELS_DIR=/app/weights\n",
        "      - CV_MODELS_DIR=/app/models\n",
        "      - CV_DATA_DIR=/app/data\n",
        "      \n",
        "      # Basketball-specific configuration\n",
        "      - BASKETBALL_COURT_MODEL=${BASKETBALL_COURT_MODEL:-basketball-court-detection-2-mlopt}\n",
        "      - PLAYER_DETECTION_MODEL=${PLAYER_DETECTION_MODEL:-yolov8n.pt}\n",
        "      - BALL_DETECTION_MODEL=${BALL_DETECTION_MODEL:-basketball-ball-detection}\n",
        "      - COURT_DETECTION_CONFIDENCE=${COURT_DETECTION_CONFIDENCE:-0.7}\n",
        "      - PLAYER_DETECTION_CONFIDENCE=${PLAYER_DETECTION_CONFIDENCE:-0.5}\n",
        "      - BALL_DETECTION_CONFIDENCE=${BALL_DETECTION_CONFIDENCE:-0.4}\n",
        "      \n",
        "      # Tracking configuration\n",
        "      - TRACKING_CONFIDENCE_THRESHOLD=${TRACKING_CONFIDENCE_THRESHOLD:-0.5}\n",
        "      - TRACKING_IOU_THRESHOLD=${TRACKING_IOU_THRESHOLD:-0.3}\n",
        "      - TRACKING_MAX_AGE=${TRACKING_MAX_AGE:-30}\n",
        "      \n",
        "      # Development settings\n",
        "      - DEBUG_MODE=${DEBUG_MODE:-false}\n",
        "      - VERBOSE_LOGGING=${VERBOSE_LOGGING:-false}\n",
        "      - PYTHONUNBUFFERED=1\n",
        "      - PYTHONHASHSEED=random\n",
        "      - PYTHONWARNINGS=ignore::UserWarning\n",
        "      - TF_CPP_MIN_LOG_LEVEL=2\n",
        "      - OMP_NUM_THREADS=4\n",
        "      - MKL_NUM_THREADS=4\n",
        "\n",
        "    volumes:\n",
        "      # FIXED: Volume paths corrected to use parent directory references\n",
        "      # Main workspace - project root mounted to /workspace\n",
        "      - ..:/workspace:cached\n",
        "      \n",
        "      # FIXED: MLflow artifacts - corrected paths relative to project root\n",
        "      - ../mlruns:/workspace/mlruns:cached\n",
        "      - ../mlflow_db:/workspace/mlflow_db:cached\n",
        "      \n",
        "      # UV cache for faster builds\n",
        "      - uv-cache:/root/.cache/uv\n",
        "      \n",
        "      # FIXED: Computer Vision specific volumes - corrected paths\n",
        "      - ../models:/app/models:cached\n",
        "      - ../weights:/app/weights:cached  \n",
        "      - ../data:/app/data:cached\n",
        "      - ../videos:/workspace/videos:cached\n",
        "      \n",
        "      # CV library caches\n",
        "      - yolo-cache:/root/.cache/ultralytics\n",
        "      - roboflow-cache:/root/.cache/roboflow\n",
        "      \n",
        "      # X11 socket for GUI applications (Linux/Unix only)\n",
        "      - /tmp/.X11-unix:/tmp/.X11-unix:rw\n",
        "      # FIXED: More robust X11 authority handling\n",
        "      - ${HOME}/.Xauthority:/root/.Xauthority:rw\n",
        "\n",
        "    ports:\n",
        "      # Original ports\n",
        "      - \"${HOST_JUPYTER_PORT:-8895}:8888\"\n",
        "      - \"${HOST_TENSORBOARD_PORT:-6005}:6008\"\n",
        "      - \"${HOST_EXPLAINER_PORT:-8055}:8050\"\n",
        "      - \"${HOST_STREAMLIT_PORT:-8505}:8501\"\n",
        "      \n",
        "      # Computer Vision specific ports\n",
        "      - \"${HOST_CV_API_PORT:-8080}:8080\"\n",
        "      - \"${HOST_CV_STREAM_PORT:-8554}:8554\"\n",
        "\n",
        "    # ENHANCED: Startup command with better error handling and debugging\n",
        "    command: >\n",
        "      bash -lc '\n",
        "        set -e;\n",
        "        echo \"[boot] Starting enhanced container: ${ENV_NAME:-docker_dev_template}\";\n",
        "        echo \"[boot] System info: $$(uname -a)\";\n",
        "        echo \"[boot] GPU info: $$(nvidia-smi --query-gpu=name,memory.total --format=csv,noheader || echo \"nvidia-smi not available\")\";\n",
        "        echo \"[boot] Working directory: $$(pwd)\";\n",
        "        echo \"[boot] Files in /workspace: $$(ls -la /workspace/ | head -5)\";\n",
        "        echo \"[boot] Activating uv environment...\";\n",
        "        source /app/.venv/bin/activate;\n",
        "        echo \"[boot] Environment activated - Python: $$(which python)\";\n",
        "        echo \"[boot] Python version: $$(python --version)\";\n",
        "        echo \"[boot] UV available: $$(uv --version 2>/dev/null || echo \"uv not found\")\";\n",
        "        echo \"[boot] Running GPU validation...\";\n",
        "        python /app/validate_gpu.py --quick || echo \"GPU validation completed with warnings\";\n",
        "        echo \"[boot] Running Computer Vision validation...\";\n",
        "        python /app/tests/test_yolo.py --quick || echo \"CV validation completed with warnings\";\n",
        "        echo \"[boot] Creating necessary directories...\";\n",
        "        mkdir -p /workspace/videos/input /workspace/videos/output /workspace/models /workspace/weights;\n",
        "        echo \"[boot] Starting Jupyter Lab on port 8888...\";\n",
        "        exec jupyter lab --ip=0.0.0.0 --port=8888 --allow-root \\\n",
        "        --ServerApp.token=\"${JUPYTER_TOKEN:-jupyter}\" \\\n",
        "        --ServerApp.allow_origin=\"*\" \\\n",
        "        --ServerApp.open_browser=false \\\n",
        "        --ServerApp.root_dir=\"/workspace\"\n",
        "      '\n",
        "\n",
        "    # ENHANCED: Healthcheck with CV components\n",
        "    healthcheck:\n",
        "      test: |\n",
        "        bash -c '\n",
        "          source /app/.venv/bin/activate 2>/dev/null || exit 1;\n",
        "          python -c \"\n",
        "            import sys, torch, jax, cv2;\n",
        "            from ultralytics import YOLO;\n",
        "            assert torch.cuda.is_available(), \\\"PyTorch CUDA not available\\\";\n",
        "            gpu_devs = [d for d in jax.devices() if \\\"gpu\\\" in str(d).lower()];\n",
        "            assert len(gpu_devs) > 0, \\\"JAX GPU devices not found\\\";\n",
        "            assert cv2.__version__ is not None, \\\"OpenCV not available\\\";\n",
        "            print(f\\\"Health check OK: PyTorch CUDA={torch.cuda.is_available()}, JAX GPUs={len(gpu_devs)}, OpenCV={cv2.__version__}, YOLO=OK\\\")\n",
        "          \" 2>/dev/null || (echo \"Health check failed\" && exit 1)\n",
        "        '\n",
        "      interval: 60s\n",
        "      timeout: 30s\n",
        "      retries: 3\n",
        "      start_period: 300s\n",
        "\n",
        "    labels:\n",
        "      - \"com.docker.compose.project=${ENV_NAME:-docker_dev_template}\"\n",
        "      - \"com.docker.compose.service=datascience\"\n",
        "      - \"description=RTX 4090 GPU Dev Environment with Computer Vision (PyTorch+JAX+YOLO+OpenCV) - CUDA 12.4\"\n",
        "\n",
        "  # FIXED: MLflow service with corrected volume paths\n",
        "  mlflow:\n",
        "    container_name: ${ENV_NAME:-docker_dev_template}_mlflow\n",
        "    image: ghcr.io/mlflow/mlflow:latest\n",
        "    \n",
        "    command: >\n",
        "      bash -c '\n",
        "        set -e;\n",
        "        echo \"[MLflow] Starting MLflow server...\";\n",
        "        mkdir -p /mlflow_artifacts /mlflow_db;\n",
        "        echo \"[MLflow] Created directories\";\n",
        "        echo \"[MLflow] Database path: /mlflow_db/mlflow.db\";\n",
        "        echo \"[MLflow] Artifacts path: /mlflow_artifacts\";\n",
        "        exec mlflow server\n",
        "        --host 0.0.0.0\n",
        "        --port 5000\n",
        "        --backend-store-uri sqlite:////mlflow_db/mlflow.db\n",
        "        --default-artifact-root /mlflow_artifacts\n",
        "        --serve-artifacts\n",
        "      '\n",
        "    \n",
        "    environment:\n",
        "      MLFLOW_EXPERIMENTS_DEFAULT_ARTIFACT_LOCATION: /mlflow_artifacts\n",
        "    \n",
        "    volumes:\n",
        "      # FIXED: Volume paths corrected to match main service\n",
        "      - ../mlruns:/mlflow_artifacts:cached\n",
        "      - ../mlflow_db:/mlflow_db:cached\n",
        "    \n",
        "    ports:\n",
        "      - \"${HOST_MLFLOW_PORT:-5005}:5000\"\n",
        "    \n",
        "    restart: unless-stopped\n",
        "    \n",
        "    # FIXED: More reliable healthcheck\n",
        "    healthcheck:\n",
        "      test: |\n",
        "        timeout 10 bash -c '</dev/tcp/localhost/5000' || \n",
        "        curl -f -s http://localhost:5000 >/dev/null 2>&1 || \n",
        "        wget --quiet --tries=1 --timeout=5 --spider http://localhost:5000 || \n",
        "        exit 1\n",
        "      interval: 30s\n",
        "      timeout: 15s\n",
        "      retries: 10\n",
        "      start_period: 120s\n",
        "\n",
        "    labels:\n",
        "      - \"com.docker.compose.project=${ENV_NAME:-docker_dev_template}\"\n",
        "      - \"description=MLflow Experiment Tracking Server with CV Support\"\n",
        "\n",
        "# Named volumes for cache persistence\n",
        "volumes:\n",
        "  uv-cache:\n",
        "    driver: local\n",
        "  yolo-cache:\n",
        "    driver: local\n",
        "  roboflow-cache:\n",
        "    driver: local\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../pyproject.toml\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../pyproject.toml\n",
        "[project]\n",
        "name = \"docker_dev_template\"\n",
        "version = \"0.1.0\"\n",
        "description = \"Hierarchical Bayesian modeling for baseball exit velocity data with Computer Vision\"\n",
        "authors = [\n",
        "  { name = \"Marlins Data Science Team\" },\n",
        "]\n",
        "license = \"MIT\"\n",
        "readme = \"README.md\"\n",
        "\n",
        "# ─── Restrict to Python 3.10–3.12 ──────────────────────────────\n",
        "requires-python = \">=3.10,<3.13\"\n",
        "\n",
        "dependencies = [\n",
        "  # Core Data Science Stack\n",
        "  \"pandas>=2.0\",\n",
        "  \"numpy>=1.20,<2\",\n",
        "  \"matplotlib>=3.4.0\",\n",
        "  \"scikit-learn>=1.4.2\",\n",
        "  \"scipy>=1.7.0\",\n",
        "  \"seaborn>=0.11.0\",\n",
        "  \"tabulate>=0.9.0\",\n",
        "  \"pyarrow>=12.0.0\",\n",
        "\n",
        "  # Bayesian Modeling Stack\n",
        "  \"pymc>=5.0.0\",\n",
        "  \"arviz>=0.14.0\",\n",
        "  \"statsmodels>=0.13.0\",\n",
        "  \"nutpie>=0.7.1\",\n",
        "  \"numpyro>=0.18.0,<1.0.0\",\n",
        "  \"pytensor>=2.18.3\",\n",
        "  \"aesara>=2.9.4\",\n",
        "\n",
        "  # Machine Learning Stack\n",
        "  \"xgboost>=1.5.0\",\n",
        "  \"lightgbm>=3.3.0\",\n",
        "  \"catboost>=1.0.0\",\n",
        "  \"shap>=0.40.0\",\n",
        "  \"shapash[report]>=2.3.0\",\n",
        "  \"shapiq>=1.3.0\",\n",
        "  \"explainerdashboard>=0.3.0\",\n",
        "  \"optuna>=4.3.0\",\n",
        "  \"bayesian-optimization>=1.2.0\",\n",
        "\n",
        "  # Development and Jupyter Stack\n",
        "  \"jupyterlab>=3.0.0\",\n",
        "  \"ipywidgets>=8.0.0\",\n",
        "  \"tqdm>=4.67.0\",\n",
        "  \"pretty_errors>=1.2.0\",\n",
        "\n",
        "  # MLflow and Experiment Tracking\n",
        "  \"mlflow>=3.1.1,<4.0.0\",\n",
        "  \"optuna-integration[mlflow]>=4.4.0,<5.0.0\",\n",
        "\n",
        "  # Web and Database Stack  \n",
        "  \"streamlit>=1.20.0\",\n",
        "  \"sqlalchemy>=1.4\",\n",
        "  \"mysql-connector-python>=8.0\",\n",
        "\n",
        "  # Utilities\n",
        "  \"gdown>=4.0.0\",\n",
        "  \"invoke>=2.2\",\n",
        "  \"pydantic>=2.0.0\",\n",
        "  \"pydantic-settings>=2.0.0\",\n",
        "\n",
        "  # ▶ Computer Vision Stack - INTEGRATED\n",
        "  # Core CV libraries\n",
        "  \"ultralytics==8.3.158\",  # YOLO v8 - pinned for stability\n",
        "  \"opencv-contrib-python-headless>=4.10.0\",  # OpenCV with contrib modules, headless for Docker\n",
        "  \"roboflow==1.2.9\",  # Roboflow API client - pinned for stability\n",
        "  \n",
        "  # Object tracking and supervision\n",
        "  \"supervision>=0.17.0\",  # Modern CV utilities and tracking\n",
        "  \"lap>=0.4.0\",  # Linear Assignment Problem solver for tracking\n",
        "  \n",
        "  # Image augmentation and processing\n",
        "  \"albumentations>=1.3.0\",  # Fast image augmentation\n",
        "  \"imgaug>=0.4.0\",  # Image augmentation library\n",
        "  \"pillow>=10.0.0\",  # Image processing\n",
        "\n",
        "  # ▶ Video processing and download stack\n",
        "  \"moviepy==2.2.1\",  # Video editing - pinned for stability\n",
        "  # pytube main-branch until next PyPI release (optional fallback)\n",
        "  \"pytube @ git+https://github.com/pytube/pytube\",\n",
        "  \"yt-dlp==2025.9.5\",  # Video download - pinned for stability\n",
        "  # optional convenience wrapper (does NOT install ffmpeg binary!)\n",
        "  \"ffmpeg-python==0.2.0\",  # FFmpeg Python wrapper - pinned for stability\n",
        "\n",
        "  # ▶ JAX Integration (already in existing container)\n",
        "  \"jax>=0.4.23\",\n",
        "  \"jaxlib>=0.4.23\",\n",
        "\n",
        "  # ▶ PyTorch Integration - platform specific with PEP-508 compliant syntax\n",
        "  # Note: Actual PyTorch installation handled in Dockerfile for proper CUDA support\n",
        "  # \"torch>=2.0.0\",\n",
        "  # \"torchvision>=0.15.0\", \n",
        "  # \"torchaudio>=2.0.0\",\n",
        "]\n",
        "\n",
        "[project.optional-dependencies]\n",
        "dev = [\n",
        "  \"pytest>=7.0.0\",\n",
        "  \"black>=23.0.0\",\n",
        "  \"isort>=5.0.0\",\n",
        "  \"flake8>=5.0.0\",\n",
        "  \"mypy>=1.0.0\",\n",
        "  \"pre-commit>=3.0.0\",\n",
        "]\n",
        "\n",
        "cuda = [\n",
        "  \"cupy-cuda12x>=12.0.0\",  # For CUDA 12.x\n",
        "]\n",
        "\n",
        "basketball = [\n",
        "  # Additional basketball-specific packages\n",
        "  \"sportsipy>=0.6.0\",  # Sports statistics\n",
        "  \"nba-api>=1.4.0\",  # NBA API client\n",
        "]\n",
        "\n",
        "# ─── uv configuration ──────────────────────────────────────────\n",
        "[tool.uv]\n",
        "index-strategy = \"unsafe-best-match\"\n",
        "\n",
        "# Define named indexes for PyTorch CUDA variants\n",
        "[[tool.uv.index]]\n",
        "name = \"pytorch-cu121\"\n",
        "url = \"https://download.pytorch.org/whl/cu121\"\n",
        "explicit = true\n",
        "\n",
        "[[tool.uv.index]]\n",
        "name = \"pytorch-cu118\"\n",
        "url = \"https://download.pytorch.org/whl/cu118\"\n",
        "explicit = true\n",
        "\n",
        "[[tool.uv.index]]\n",
        "name = \"pytorch-cu124\"\n",
        "url = \"https://download.pytorch.org/whl/cu124\"\n",
        "explicit = true\n",
        "\n",
        "[[tool.uv.index]]\n",
        "name = \"pytorch-cu128\"\n",
        "url = \"https://download.pytorch.org/whl/cu128\"\n",
        "explicit = true\n",
        "\n",
        "[tool.uv.pip]\n",
        "# Configure UV pip behavior for optimal package resolution\n",
        "\n",
        "# Map PyTorch dependencies to CUDA indexes for non-macOS platforms\n",
        "[tool.uv.sources]\n",
        "torch = [\n",
        "  { index = \"pytorch-cu124\", marker = \"sys_platform == 'linux' or sys_platform == 'win32'\" },\n",
        "]\n",
        "torchvision = [\n",
        "  { index = \"pytorch-cu124\", marker = \"sys_platform == 'linux' or sys_platform == 'win32'\" },\n",
        "]\n",
        "torchaudio = [\n",
        "  { index = \"pytorch-cu124\", marker = \"sys_platform == 'linux' or sys_platform == 'win32'\" },\n",
        "]\n",
        "\n",
        "[tool.pytensor]\n",
        "device    = \"cuda\"\n",
        "floatX    = \"float32\"\n",
        "allow_gc  = true\n",
        "optimizer = \"fast_run\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/validate_gpu.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/validate_gpu.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Docker Build & GPU Validation Script (container-friendly)\n",
        "- Adds --quick mode to skip Docker CLI checks\n",
        "- Skips Docker checks automatically if docker is unavailable\n",
        "- Keeps strict on GPU/Torch/JAX checks\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import subprocess\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "def print_section(title: str) -> None:\n",
        "    print(f\"\\n{'='*60}\\n  {title}\\n{'='*60}\")\n",
        "\n",
        "\n",
        "def run_command(cmd: List[str], timeout: int = 60) -> Tuple[bool, str, str]:\n",
        "    try:\n",
        "        r = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)\n",
        "        return r.returncode == 0, r.stdout, r.stderr\n",
        "    except Exception as e:\n",
        "        return False, \"\", str(e)\n",
        "\n",
        "\n",
        "def docker_available() -> bool:\n",
        "    return shutil.which(\"docker\") is not None\n",
        "\n",
        "\n",
        "def ensure_project_structure() -> bool:\n",
        "    print_section(\"ENSURING PROJECT STRUCTURE\")\n",
        "    cwd = Path.cwd()\n",
        "    print(f\"Current directory: {cwd}\")\n",
        "\n",
        "    if (cwd / \".devcontainer\").exists():\n",
        "        project_root = cwd\n",
        "    elif cwd.name == \".devcontainer\":\n",
        "        project_root = cwd.parent\n",
        "    else:\n",
        "        project_root = cwd\n",
        "        (project_root / \".devcontainer\").mkdir(exist_ok=True)\n",
        "\n",
        "    dev_dir = project_root / \".devcontainer\"\n",
        "    print(f\"Project root: {project_root}\")\n",
        "    print(f\"DevContainer directory: {dev_dir}\")\n",
        "\n",
        "    (dev_dir / \"tests\").mkdir(exist_ok=True)\n",
        "\n",
        "    pyproject = project_root / \"pyproject.toml\"\n",
        "    if not pyproject.exists():\n",
        "        print(\"Creating minimal pyproject.toml...\")\n",
        "        pyproject.write_text(\n",
        "            \"\"\"[project]\n",
        "name = \"docker_dev_template\"\n",
        "version = \"0.1.0\"\n",
        "description = \"Docker development environment\"\n",
        "requires-python = \">=3.10,<3.13\"\n",
        "\n",
        "dependencies = [\n",
        "    \"pandas>=2.0\",\n",
        "    \"numpy>=1.20,<2\",\n",
        "    \"matplotlib>=3.4.0\",\n",
        "    \"scipy>=1.7.0\",\n",
        "    \"jupyterlab>=3.0.0\",\n",
        "]\n",
        "\n",
        "[tool.uv]\n",
        "index-strategy = \"unsafe-best-match\"\n",
        "\"\"\"\n",
        "        )\n",
        "        print(\"✅ Created pyproject.toml\")\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def create_env_file() -> bool:\n",
        "    print_section(\"CREATING ENVIRONMENT FILE\")\n",
        "    t = Path(\".devcontainer/.env.template\")\n",
        "    f = Path(\".devcontainer/.env\")\n",
        "    if t.exists() and not f.exists():\n",
        "        f.write_bytes(t.read_bytes())\n",
        "        print(\"✅ Created .env from template\")\n",
        "        return True\n",
        "    elif f.exists():\n",
        "        print(\"✅ .env file already exists\")\n",
        "        return True\n",
        "    else:\n",
        "        f.write_text(\n",
        "            \"\"\"ENV_NAME=docker_dev_template\n",
        "CUDA_TAG=12.4.0\n",
        "PYTHON_VER=3.10\n",
        "HOST_JUPYTER_PORT=8891\n",
        "HOST_TENSORBOARD_PORT=6008\n",
        "HOST_EXPLAINER_PORT=8050\n",
        "HOST_STREAMLIT_PORT=8501\n",
        "HOST_MLFLOW_PORT=5000\n",
        "\"\"\"\n",
        "        )\n",
        "        print(\"✅ Created minimal .env file\")\n",
        "        return True\n",
        "\n",
        "\n",
        "def fix_file_permissions() -> bool:\n",
        "    print_section(\"FIXING FILE PERMISSIONS\")\n",
        "    try:\n",
        "        is_wsl = \"microsoft\" in os.uname().release.lower()\n",
        "    except Exception:\n",
        "        is_wsl = False\n",
        "\n",
        "    if os.name == \"nt\" or is_wsl:\n",
        "        print(\"Detected Windows/WSL environment\")\n",
        "        for p in [\n",
        "            \".devcontainer/validate_gpu.py\",\n",
        "            \".devcontainer/tests/test_summary.py\",\n",
        "            \".devcontainer/tests/test_pytorch.py\",\n",
        "            \".devcontainer/tests/test_pytorch_gpu.py\",\n",
        "            \".devcontainer/tests/test_uv.py\",\n",
        "        ]:\n",
        "            fp = Path(p)\n",
        "            if fp.exists():\n",
        "                try:\n",
        "                    os.chmod(fp, 0o755)\n",
        "                    print(f\"✅ Fixed permissions for {p}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ Could not fix permissions for {p}: {e}\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def validate_docker_environment() -> bool:\n",
        "    print_section(\"VALIDATING DOCKER ENVIRONMENT\")\n",
        "    if not docker_available():\n",
        "        print(\"ℹ️ Docker CLI not found in this environment; skipping Docker checks.\")\n",
        "        return True  # treat as success inside containers\n",
        "    ok, out, err = run_command([\"docker\", \"info\"])\n",
        "    if not ok:\n",
        "        print(f\"❌ Docker daemon not accessible: {err}\")\n",
        "        return False\n",
        "    print(\"✅ Docker daemon is running\")\n",
        "\n",
        "    ok, out, err = run_command([\"docker\", \"compose\", \"version\"])\n",
        "    if not ok:\n",
        "        print(f\"❌ Docker Compose not available: {err}\")\n",
        "        return False\n",
        "    print(f\"✅ Docker Compose: {out.strip()}\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def stop_and_remove_containers() -> bool:\n",
        "    print_section(\"CLEANING EXISTING CONTAINERS\")\n",
        "    if not docker_available():\n",
        "        print(\"ℹ️ Docker CLI not found; skipping container cleanup.\")\n",
        "        return True\n",
        "    ok, _, err = run_command(\n",
        "        [\"docker\", \"compose\", \"-f\", \".devcontainer/docker-compose.yml\", \"down\", \"--volumes\"]\n",
        "    )\n",
        "    if not ok:\n",
        "        print(f\"⚠️ Could not stop containers (may not exist): {err}\")\n",
        "    for name in [\"docker_dev_template_datascience\", \"docker_dev_template_mlflow\"]:\n",
        "        run_command([\"docker\", \"rm\", \"-f\", name])\n",
        "    print(\"✅ Container cleanup complete\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def clean_docker_cache() -> bool:\n",
        "    print_section(\"CLEANING DOCKER CACHE\")\n",
        "    if not docker_available():\n",
        "        print(\"ℹ️ Docker CLI not found; skipping cache prune.\")\n",
        "        return True\n",
        "    ok, out, err = run_command([\"docker\", \"builder\", \"prune\", \"--all\", \"--force\"])\n",
        "    if ok:\n",
        "        print(\"✅ Docker build cache cleaned\")\n",
        "        if out:\n",
        "            print(out)\n",
        "        return True\n",
        "    print(f\"❌ Failed to clean Docker cache: {err}\")\n",
        "    return False\n",
        "\n",
        "\n",
        "def test_build() -> bool:\n",
        "    print_section(\"TESTING DOCKER BUILD\")\n",
        "    if not docker_available():\n",
        "        print(\"ℹ️ Docker CLI not found; skipping compose build test.\")\n",
        "        return True\n",
        "    if Path.cwd().name == \".devcontainer\":\n",
        "        os.chdir(\"..\")\n",
        "    compose_file = \".devcontainer/docker-compose.yml\"\n",
        "    print(f\"Using compose file: {Path(compose_file).absolute()}\")\n",
        "    print(f\"Build context: {Path('.').absolute()}\")\n",
        "    ok, out, err = run_command(\n",
        "        [\"docker\", \"compose\", \"-f\", compose_file, \"build\", \"--no-cache\"], timeout=600\n",
        "    )\n",
        "    if ok:\n",
        "        print(\"✅ Docker build successful!\")\n",
        "        print(\"\\n\".join(out.splitlines()[-10:]))\n",
        "        return True\n",
        "    print(\"❌ Docker build failed\")\n",
        "    print(\"STDERR:\\n\", err)\n",
        "    print(\"STDOUT (last 20 lines):\\n\", \"\\n\".join(out.splitlines()[-20:]))\n",
        "    return False\n",
        "\n",
        "\n",
        "def section_summary(struct_ok, uv_ok, pt_ok, jax_ok):\n",
        "    print_section(\"SUMMARY\")\n",
        "    print(f\"structure: {struct_ok} uv: {uv_ok} pytorch: {pt_ok} jax: {jax_ok}\")\n",
        "\n",
        "\n",
        "def test_uv() -> bool:\n",
        "    print_section(\"UV\")\n",
        "    ok, out, err = run_command([\"uv\", \"--version\"])\n",
        "    print((out or err).strip() or \"uv not in PATH\")\n",
        "    return ok\n",
        "\n",
        "\n",
        "def test_pytorch() -> bool:\n",
        "    print_section(\"PYTORCH\")\n",
        "    try:\n",
        "        import torch\n",
        "        print(\"version:\", torch.__version__)\n",
        "        print(\"cuda:\", torch.cuda.is_available())\n",
        "        if torch.cuda.is_available():\n",
        "            d = torch.device(\"cuda:0\")\n",
        "            import time\n",
        "            x = torch.randn((512, 512), device=d)\n",
        "            t0 = time.time()\n",
        "            y = (x @ x.T).sum()\n",
        "            torch.cuda.synchronize()\n",
        "            print(\"sum:\", float(y))\n",
        "            print(f\"gpu op ms: {(time.time() - t0)*1000:.2f}\")\n",
        "            return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(\"error:\", e)\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_jax() -> bool:\n",
        "    print_section(\"JAX\")\n",
        "    try:\n",
        "        import jax\n",
        "        import jax.numpy as jnp\n",
        "\n",
        "        devs = jax.devices()\n",
        "        print(\"devices:\", devs)\n",
        "        gpus = jax.devices(\"gpu\") or [\n",
        "            d for d in devs\n",
        "            if getattr(d, \"platform\", \"\").lower() in {\"gpu\", \"cuda\"} or \"cuda\" in str(d).lower()\n",
        "        ]\n",
        "        if not gpus:\n",
        "            print(\"no gpu devices detected by jax\")\n",
        "            return False\n",
        "        \n",
        "        # Enhanced JAX GPU test with CuDNN compatibility check\n",
        "        print(\"Testing JAX GPU computation with CuDNN compatibility...\")\n",
        "        try:\n",
        "            x = jnp.ones((512, 512), dtype=jnp.float32)\n",
        "            x = jax.device_put(x, gpus[0])\n",
        "            s = jnp.sum(x).block_until_ready()\n",
        "            print(\"sum:\", float(s))\n",
        "            \n",
        "            # Test more complex operations that might trigger CuDNN\n",
        "            y = jnp.dot(x, x.T)\n",
        "            result = jnp.sum(y).block_until_ready()\n",
        "            print(\"matrix multiplication result:\", float(result))\n",
        "            return True\n",
        "        except Exception as cudnn_error:\n",
        "            print(f\"JAX GPU computation failed (likely CuDNN issue): {cudnn_error}\")\n",
        "            print(\"This is likely due to CuDNN version mismatch between PyTorch and JAX\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(\"error:\", e)\n",
        "        return False\n",
        "\n",
        "\n",
        "def fix_cudnn_compatibility() -> bool:\n",
        "    \"\"\"Attempt to fix CuDNN compatibility issues.\"\"\"\n",
        "    print_section(\"CUDNN COMPATIBILITY FIX\")\n",
        "    \n",
        "    try:\n",
        "        import subprocess\n",
        "        \n",
        "        # Check current CuDNN versions\n",
        "        print(\"Checking current CuDNN versions...\")\n",
        "        \n",
        "        # Try to upgrade CuDNN to compatible version\n",
        "        print(\"Attempting to upgrade CuDNN to compatible version...\")\n",
        "        result = subprocess.run([\n",
        "            'uv', 'pip', 'install', '--upgrade', \n",
        "            'nvidia-cudnn-cu12==9.8.0.69'\n",
        "        ], capture_output=True, text=True, timeout=300)\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print(\"✅ CuDNN upgraded successfully\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"⚠️ CuDNN upgrade failed: {result.stderr}\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ CuDNN fix failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def parse_args() -> argparse.Namespace:\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--quick\", action=\"store_true\",\n",
        "                   help=\"Skip Docker checks; run only structure/UV/Torch/JAX\")\n",
        "    p.add_argument(\"--fix-cudnn\", action=\"store_true\",\n",
        "                   help=\"Attempt to fix CuDNN compatibility issues\")\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "def main() -> int:\n",
        "    args = parse_args()\n",
        "    print(\"Docker DevContainer Build & GPU Validation\")\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "    # Always run these\n",
        "    struct_ok = ensure_project_structure()\n",
        "    env_ok = create_env_file()\n",
        "    perm_ok = fix_file_permissions()\n",
        "\n",
        "    # Optional Docker checks\n",
        "    docker_ok = True\n",
        "    build_ok = True\n",
        "    cache_ok = True\n",
        "    stop_ok = True\n",
        "\n",
        "    if not args.quick:\n",
        "        docker_ok = validate_docker_environment()\n",
        "        stop_ok = stop_and_remove_containers()\n",
        "        cache_ok = clean_docker_cache()\n",
        "        build_ok = test_build()\n",
        "\n",
        "    uv_ok = test_uv()\n",
        "    pt_ok = test_pytorch()\n",
        "    jax_ok = test_jax()\n",
        "    \n",
        "    # Attempt CuDNN fix if requested and JAX failed\n",
        "    if args.fix_cudnn and not jax_ok:\n",
        "        print(\"\\nJAX GPU test failed, attempting CuDNN compatibility fix...\")\n",
        "        cudnn_fix_ok = fix_cudnn_compatibility()\n",
        "        if cudnn_fix_ok:\n",
        "            print(\"Retesting JAX after CuDNN fix...\")\n",
        "            jax_ok = test_jax()\n",
        "\n",
        "    section_summary(struct_ok, uv_ok, pt_ok, jax_ok)\n",
        "\n",
        "    # In quick mode, ignore Docker results entirely.\n",
        "    if args.quick:\n",
        "        return 0 if all([struct_ok, uv_ok, pt_ok, jax_ok]) else 1\n",
        "\n",
        "    # Otherwise include Docker outcomes.\n",
        "    ok = all([\n",
        "        struct_ok, env_ok, perm_ok,\n",
        "        docker_ok, stop_ok, cache_ok, build_ok,\n",
        "        uv_ok, pt_ok, jax_ok\n",
        "    ])\n",
        "    return 0 if ok else 1\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sys.exit(main())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## BuildKit Cache Fix & Testing\n",
        "\n",
        "The Dockerfile has been updated with isolated BuildKit cache mounts to prevent \n",
        "`archive/tar: invalid tar header` errors. If you encounter build issues:\n",
        "\n",
        "**Quick Fix:**\n",
        "```bash\n",
        "python scripts/fix_build.py\n",
        "```\n",
        "\n",
        "**Manual Fix Steps:**\n",
        "1. Clear corrupted caches: `docker builder prune --all --force`\n",
        "2. Clean build: `docker-compose build --no-cache`\n",
        "3. Test cached build: `docker-compose build`\n",
        "\n",
        "**Key Improvements:**\n",
        "- Added explicit cache IDs: `apt-cache`, `apt-lists`, `uv-cache`\n",
        "- Prevents cache key collisions and corruption\n",
        "- Maintains fast build times with reliable caching\n",
        "\n",
        "## Testing & Diagnostics\n",
        "\n",
        "Creating comprehensive testing and diagnostic scripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_pytorch_gpu.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_pytorch_gpu.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"Small PyTorch GPU benchmark.\"\"\"\n",
        "import time\n",
        "\n",
        "\n",
        "def test_pytorch(force_cpu: bool = False) -> None:\n",
        "    import torch\n",
        "    cuda_ok = torch.cuda.is_available() and not force_cpu\n",
        "    if cuda_ok:\n",
        "        name = torch.cuda.get_device_name(0)\n",
        "        major, minor = torch.cuda.get_device_capability()\n",
        "        print(f\"device: {name} (sm_{major}{minor:02d})\")\n",
        "        device = torch.device(\"cuda:0\")\n",
        "    else:\n",
        "        print(\"falling back to cpu\")\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    size = (1000, 1000)\n",
        "    a, b = (torch.randn(size, device=device) for _ in range(2))\n",
        "    _ = a @ b\n",
        "    t0 = time.time()\n",
        "    _ = (a @ b).sum().item()\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "    print(f\"matmul on {device} took {(time.time()-t0)*1000:.2f} ms\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_pytorch()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Verification\n",
        "\n",
        "Now let's test that our environment setup is working correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_pytorch.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_pytorch.py\n",
        "print(\"PyTorch quick check\")\n",
        "try:\n",
        "    import torch\n",
        "    print(\"version:\", torch.__version__)\n",
        "    print(\"cuda:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"devices:\", torch.cuda.device_count())\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            print(i, torch.cuda.get_device_name(i))\n",
        "        x = torch.ones(100, 100, device='cuda:0')\n",
        "        print(\"sum:\", float(torch.sum(x)))\n",
        "except Exception as e:\n",
        "    print(\"error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_uv.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_uv.py\n",
        "# Test other critical packages\n",
        "print(\"\\n📦 Testing other critical packages...\")\n",
        "\n",
        "packages_to_test = [\n",
        "    'numpy', 'pandas', 'matplotlib', 'scipy', 'sklearn', \n",
        "    'jupyterlab', 'seaborn', 'tqdm'\n",
        "]\n",
        "\n",
        "for package in packages_to_test:\n",
        "    try:\n",
        "        if package == 'sklearn':\n",
        "            import sklearn\n",
        "            version = sklearn.__version__\n",
        "        else:\n",
        "            module = __import__(package)\n",
        "            version = getattr(module, '__version__', 'unknown')\n",
        "        print(f\"   ✅ {package}: {version}\")\n",
        "    except ImportError:\n",
        "        print(f\"   ❌ {package}: Not installed\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  {package}: Error - {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_yolo.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_yolo.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Computer Vision validation and testing for Basketball Detection Pipeline.\n",
        "Tests YOLO, Roboflow, OpenCV, and tracking libraries integration with PyTorch/JAX GPU container.\n",
        "\"\"\"\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import time\n",
        "from pathlib import Path\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def print_section(title: str) -> None:\n",
        "    \"\"\"Print a formatted section header.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"  {title}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def test_environment_setup() -> bool:\n",
        "    \"\"\"Test that environment variables are properly configured for CV.\"\"\"\n",
        "    print_section(\"ENVIRONMENT SETUP VALIDATION\")\n",
        "    \n",
        "    required_vars = {\n",
        "        'YOLO_VERBOSE': 'false',\n",
        "        'OPENCV_LOG_LEVEL': 'ERROR', \n",
        "        'VIDEO_INPUT_DIR': '/workspace/videos/input',\n",
        "        'VIDEO_OUTPUT_DIR': '/workspace/videos/output'\n",
        "    }\n",
        "    \n",
        "    optional_vars = {\n",
        "        'ROBOFLOW_API_KEY': 'Roboflow integration',\n",
        "        'DISPLAY': 'GUI support'\n",
        "    }\n",
        "    \n",
        "    all_ok = True\n",
        "    \n",
        "    print(\"Required environment variables:\")\n",
        "    for var, expected in required_vars.items():\n",
        "        value = os.environ.get(var)\n",
        "        if value:\n",
        "            status = \"✅\" if value == expected else \"⚠️\"\n",
        "            print(f\"  {var}: {value} {status}\")\n",
        "        else:\n",
        "            print(f\"  {var}: Not set ❌\")\n",
        "            all_ok = False\n",
        "    \n",
        "    print(\"\\nOptional environment variables:\")\n",
        "    for var, purpose in optional_vars.items():\n",
        "        value = os.environ.get(var, 'Not set')\n",
        "        if var == 'ROBOFLOW_API_KEY' and value != 'Not set':\n",
        "            value = value[:10] + '...' if len(value) > 10 else value\n",
        "        print(f\"  {var}: {value} ({purpose})\")\n",
        "    \n",
        "    return all_ok\n",
        "\n",
        "\n",
        "def test_directories() -> bool:\n",
        "    \"\"\"Test that required directories exist and are writable.\"\"\"\n",
        "    print_section(\"DIRECTORY STRUCTURE VALIDATION\")\n",
        "    \n",
        "    directories = [\n",
        "        '/app/models',\n",
        "        '/app/weights', \n",
        "        '/app/data',\n",
        "        '/workspace/videos',\n",
        "        '/workspace/videos/input',\n",
        "        '/workspace/videos/output'\n",
        "    ]\n",
        "    \n",
        "    all_ok = True\n",
        "    for dir_path in directories:\n",
        "        path = Path(dir_path)\n",
        "        if path.exists():\n",
        "            try:\n",
        "                # Test write permission\n",
        "                test_file = path / '.write_test'\n",
        "                test_file.write_text('test')\n",
        "                test_file.unlink()\n",
        "                print(f\"  {dir_path}: ✅ Exists and writable\")\n",
        "            except Exception as e:\n",
        "                print(f\"  {dir_path}: ⚠️ Exists but not writable: {e}\")\n",
        "                all_ok = False\n",
        "        else:\n",
        "            try:\n",
        "                path.mkdir(parents=True, exist_ok=True)\n",
        "                print(f\"  {dir_path}: ✅ Created successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"  {dir_path}: ❌ Cannot create: {e}\")\n",
        "                all_ok = False\n",
        "    \n",
        "    return all_ok\n",
        "\n",
        "\n",
        "def test_opencv() -> bool:\n",
        "    \"\"\"Test OpenCV installation and basic functionality.\"\"\"\n",
        "    print_section(\"OPENCV INTEGRATION TEST\")\n",
        "    try:\n",
        "        import cv2\n",
        "        print(f\"OpenCV version: {cv2.__version__}\")\n",
        "        \n",
        "        # Test basic image operations\n",
        "        test_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
        "        gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "        \n",
        "        # Test video backends\n",
        "        backends = []\n",
        "        backend_names = {\n",
        "            cv2.CAP_FFMPEG: 'FFMPEG',\n",
        "            cv2.CAP_GSTREAMER: 'GSTREAMER', \n",
        "            cv2.CAP_V4L2: 'V4L2'\n",
        "        }\n",
        "        \n",
        "        for backend_id, name in backend_names.items():\n",
        "            try:\n",
        "                cap = cv2.VideoCapture()\n",
        "                if hasattr(cv2, 'CAP_' + name):\n",
        "                    backends.append(name)\n",
        "                cap.release()\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        print(f\"Available video backends: {backends}\")\n",
        "        print(f\"Image processing test: OK (edges shape: {edges.shape})\")\n",
        "        \n",
        "        # Test CUDA support in OpenCV (if available)\n",
        "        try:\n",
        "            cuda_devices = cv2.cuda.getCudaEnabledDeviceCount()\n",
        "            print(f\"OpenCV CUDA devices: {cuda_devices}\")\n",
        "        except:\n",
        "            print(\"OpenCV CUDA support: Not available (CPU only)\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"OpenCV test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_ultralytics_yolo() -> bool:\n",
        "    \"\"\"Test Ultralytics YOLO installation and GPU acceleration.\"\"\"\n",
        "    print_section(\"ULTRALYTICS YOLO INTEGRATION TEST\")\n",
        "    try:\n",
        "        from ultralytics import YOLO, __version__\n",
        "        print(f\"Ultralytics version: {__version__}\")\n",
        "        \n",
        "        # Check PyTorch integration\n",
        "        import torch\n",
        "        print(f\"PyTorch CUDA available for YOLO: {torch.cuda.is_available()}\")\n",
        "        \n",
        "        # Test model loading\n",
        "        print(\"Loading YOLOv8n model...\")\n",
        "        start_time = time.time()\n",
        "        model = YOLO(\"yolov8n.pt\")\n",
        "        load_time = time.time() - start_time\n",
        "        print(f\"Model loaded in {load_time:.2f}s\")\n",
        "        print(f\"Model device: {model.device}\")\n",
        "        \n",
        "        # Test inference on dummy image\n",
        "        dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
        "        print(\"Running inference test...\")\n",
        "        start_time = time.time()\n",
        "        results = model(dummy_img, verbose=False)\n",
        "        inference_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"Inference completed in {inference_time:.3f}s\")\n",
        "        print(f\"Results: {len(results)} outputs\")\n",
        "        \n",
        "        # Test model info\n",
        "        if hasattr(model, 'info'):\n",
        "            try:\n",
        "                model.info()\n",
        "            except:\n",
        "                print(\"Model info: Available but verbose output suppressed\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Ultralytics test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_roboflow_integration() -> bool:\n",
        "    \"\"\"Test Roboflow installation and API connectivity.\"\"\"\n",
        "    print_section(\"ROBOFLOW INTEGRATION TEST\")\n",
        "    try:\n",
        "        import roboflow\n",
        "        from roboflow import Roboflow\n",
        "        \n",
        "        print(f\"Roboflow version: {roboflow.__version__}\")\n",
        "        \n",
        "        # Check API key configuration\n",
        "        api_key = os.environ.get('ROBOFLOW_API_KEY', '')\n",
        "        if api_key and api_key != 'your_roboflow_api_key_here':\n",
        "            print(\"Roboflow API key: Configured\")\n",
        "            \n",
        "            try:\n",
        "                # Test API connection\n",
        "                rf = Roboflow(api_key=api_key)\n",
        "                print(\"Roboflow client initialized successfully\")\n",
        "                \n",
        "                # Get configuration for basketball detection\n",
        "                workspace = os.environ.get('ROBOFLOW_WORKSPACE', 'basketball-formations')\n",
        "                project = os.environ.get('ROBOFLOW_PROJECT', 'basketball-court-detection-2-mlopt')\n",
        "                version = os.environ.get('ROBOFLOW_VERSION', '1')\n",
        "                \n",
        "                print(f\"Basketball Detection Configuration:\")\n",
        "                print(f\"  Workspace: {workspace}\")\n",
        "                print(f\"  Project: {project}\")\n",
        "                print(f\"  Version: {version}\")\n",
        "                \n",
        "                # Note: Actual project access requires valid API key\n",
        "                print(\"Note: Full project access requires valid API key\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"API connection test: {e}\")\n",
        "                print(\"This is normal without a valid API key\")\n",
        "        else:\n",
        "            print(\"Roboflow API key: Not configured\")\n",
        "            print(\"Set ROBOFLOW_API_KEY to enable full integration\")\n",
        "            print(\"Get your API key from: https://app.roboflow.com/settings/api\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Roboflow test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_supervision_tracking() -> bool:\n",
        "    \"\"\"Test supervision library for object tracking and annotation.\"\"\"\n",
        "    print_section(\"SUPERVISION TRACKING TEST\")\n",
        "    try:\n",
        "        import supervision as sv\n",
        "        print(f\"Supervision version: {sv.__version__}\")\n",
        "        \n",
        "        # Test detection utilities\n",
        "        from supervision import Detections, BoxAnnotator\n",
        "        \n",
        "        # Create dummy detections (basketball court, players, ball)\n",
        "        xyxy = np.array([\n",
        "            [100, 100, 200, 200],  # Player 1\n",
        "            [300, 300, 400, 400],  # Player 2  \n",
        "            [450, 150, 470, 170],  # Ball\n",
        "            [0, 0, 640, 480]       # Court\n",
        "        ])\n",
        "        confidence = np.array([0.9, 0.8, 0.7, 0.95])\n",
        "        class_id = np.array([0, 0, 1, 2])  # 0=person, 1=ball, 2=court\n",
        "        \n",
        "        detections = Detections(\n",
        "            xyxy=xyxy,\n",
        "            confidence=confidence,\n",
        "            class_id=class_id\n",
        "        )\n",
        "        \n",
        "        print(f\"Created {len(detections)} dummy detections\")\n",
        "        \n",
        "        # Test annotation\n",
        "        annotator = BoxAnnotator()\n",
        "        print(\"Box annotator initialized\")\n",
        "        \n",
        "        # Test tracking capabilities\n",
        "        try:\n",
        "            from supervision import ByteTracker\n",
        "            tracker = ByteTracker()\n",
        "            print(\"ByteTracker initialized\")\n",
        "            \n",
        "            # Test tracking update\n",
        "            tracked_detections = tracker.update_with_detections(detections)\n",
        "            print(f\"Tracking update successful: {len(tracked_detections)} tracked objects\")\n",
        "            \n",
        "        except ImportError:\n",
        "            print(\"ByteTracker not available (optional advanced tracking)\")\n",
        "        except Exception as e:\n",
        "            print(f\"Tracking test: {e}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Supervision test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_video_processing() -> bool:\n",
        "    \"\"\"Test video processing capabilities.\"\"\"\n",
        "    print_section(\"VIDEO PROCESSING TEST\")\n",
        "    try:\n",
        "        # Test ffmpeg-python\n",
        "        import ffmpeg\n",
        "        print(\"ffmpeg-python: Available\")\n",
        "        \n",
        "        # Check ffmpeg binary\n",
        "        import subprocess\n",
        "        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, timeout=10)\n",
        "        if result.returncode == 0:\n",
        "            version_line = result.stdout.split('\\n')[0]\n",
        "            print(f\"ffmpeg binary: {version_line}\")\n",
        "        else:\n",
        "            print(\"ffmpeg binary: Not found or error\")\n",
        "            \n",
        "        # Test moviepy\n",
        "        try:\n",
        "            import moviepy\n",
        "            from moviepy.editor import ColorClip\n",
        "            print(f\"MoviePy version: {moviepy.__version__}\")\n",
        "            \n",
        "            # Test basic video creation\n",
        "            clip = ColorClip(size=(100, 100), color=(255, 0, 0), duration=1)\n",
        "            print(\"MoviePy functionality: OK\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"MoviePy test: {e}\")\n",
        "            \n",
        "        # Test yt-dlp\n",
        "        try:\n",
        "            import yt_dlp\n",
        "            print(f\"yt-dlp version: {yt_dlp.version.__version__}\")\n",
        "        except Exception as e:\n",
        "            print(f\"yt-dlp test: {e}\")\n",
        "            \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Video processing test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_basketball_pipeline() -> bool:\n",
        "    \"\"\"Test basketball-specific detection pipeline.\"\"\"\n",
        "    print_section(\"BASKETBALL DETECTION PIPELINE TEST\")\n",
        "    \n",
        "    try:\n",
        "        # Test integration of all components\n",
        "        from ultralytics import YOLO\n",
        "        import cv2\n",
        "        import supervision as sv\n",
        "        \n",
        "        print(\"Basketball Detection Pipeline Components:\")\n",
        "        print(f\"  ✅ YOLO: Available\")\n",
        "        print(f\"  ✅ OpenCV: {cv2.__version__}\")\n",
        "        print(f\"  ✅ Supervision: {sv.__version__}\")\n",
        "        \n",
        "        # Simulate basketball court detection\n",
        "        print(\"\\nBasketball Court Detection Configuration:\")\n",
        "        court_model = os.environ.get('BASKETBALL_COURT_MODEL', 'basketball-court-detection-2-mlopt')\n",
        "        player_model = os.environ.get('PLAYER_DETECTION_MODEL', 'yolov8n.pt') \n",
        "        ball_model = os.environ.get('BALL_DETECTION_MODEL', 'basketball-ball-detection')\n",
        "        \n",
        "        print(f\"  Court Detection: {court_model}\")\n",
        "        print(f\"  Player Detection: {player_model}\")\n",
        "        print(f\"  Ball Detection: {ball_model}\")\n",
        "        \n",
        "        # Test confidence thresholds\n",
        "        court_conf = float(os.environ.get('COURT_DETECTION_CONFIDENCE', '0.7'))\n",
        "        player_conf = float(os.environ.get('PLAYER_DETECTION_CONFIDENCE', '0.5'))\n",
        "        ball_conf = float(os.environ.get('BALL_DETECTION_CONFIDENCE', '0.4'))\n",
        "        \n",
        "        print(f\"\\nConfidence Thresholds:\")\n",
        "        print(f\"  Court: {court_conf}\")\n",
        "        print(f\"  Players: {player_conf}\")\n",
        "        print(f\"  Ball: {ball_conf}\")\n",
        "        \n",
        "        # Check model directories\n",
        "        models_dir = Path('/app/models')\n",
        "        weights_dir = Path('/app/weights')\n",
        "        \n",
        "        print(f\"\\nModel Storage:\")\n",
        "        print(f\"  Models directory: {models_dir} ({'✅' if models_dir.exists() else '❌'})\")\n",
        "        print(f\"  Weights directory: {weights_dir} ({'✅' if weights_dir.exists() else '❌'})\")\n",
        "        \n",
        "        if models_dir.exists():\n",
        "            model_files = list(models_dir.glob('*.pt')) + list(models_dir.glob('*.onnx'))\n",
        "            print(f\"  Found {len(model_files)} model files\")\n",
        "            \n",
        "        if weights_dir.exists():\n",
        "            weight_files = list(weights_dir.glob('*.pt')) + list(weights_dir.glob('*.weights'))\n",
        "            print(f\"  Found {len(weight_files)} weight files\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Basketball pipeline test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_gpu_integration() -> bool:\n",
        "    \"\"\"Test GPU integration across PyTorch, JAX, and OpenCV.\"\"\"\n",
        "    print_section(\"GPU INTEGRATION TEST\")\n",
        "    \n",
        "    try:\n",
        "        # Test PyTorch GPU\n",
        "        import torch\n",
        "        pytorch_gpu = torch.cuda.is_available()\n",
        "        print(f\"PyTorch CUDA: {'✅' if pytorch_gpu else '❌'}\")\n",
        "        \n",
        "        if pytorch_gpu:\n",
        "            print(f\"PyTorch GPU devices: {torch.cuda.device_count()}\")\n",
        "            print(f\"Current GPU: {torch.cuda.get_device_name()}\")\n",
        "        \n",
        "        # Test JAX GPU\n",
        "        import jax\n",
        "        jax_devices = jax.devices()\n",
        "        jax_gpus = [d for d in jax_devices if 'gpu' in str(d).lower()]\n",
        "        print(f\"JAX GPU devices: {len(jax_gpus)} ({'✅' if jax_gpus else '❌'})\")\n",
        "        \n",
        "        # Test OpenCV CUDA (if available)\n",
        "        try:\n",
        "            import cv2\n",
        "            opencv_cuda = cv2.cuda.getCudaEnabledDeviceCount() > 0\n",
        "            print(f\"OpenCV CUDA: {'✅' if opencv_cuda else '❌'}\")\n",
        "        except:\n",
        "            print(f\"OpenCV CUDA: ❌ (CPU only)\")\n",
        "        \n",
        "        # Test YOLO GPU\n",
        "        from ultralytics import YOLO\n",
        "        model = YOLO('yolov8n.pt')\n",
        "        yolo_gpu = 'cuda' in str(model.device)\n",
        "        print(f\"YOLO GPU: {'✅' if yolo_gpu else '❌'}\")\n",
        "        \n",
        "        return pytorch_gpu and len(jax_gpus) > 0\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"GPU integration test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def main() -> int:\n",
        "    \"\"\"Run comprehensive computer vision tests.\"\"\"\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(description=\"Test Computer Vision Integration\")\n",
        "    parser.add_argument('--quick', action='store_true', help='Run quick tests only')\n",
        "    parser.add_argument('--verbose', action='store_true', help='Verbose output')\n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    print(\"Computer Vision Integration Test Suite\")\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "    \n",
        "    if args.verbose:\n",
        "        test_environment_setup()\n",
        "    \n",
        "    # Core tests\n",
        "    directory_ok = test_directories()\n",
        "    opencv_ok = test_opencv()\n",
        "    yolo_ok = test_ultralytics_yolo()\n",
        "    \n",
        "    if args.quick:\n",
        "        print_section(\"QUICK TEST SUMMARY\")\n",
        "        results = {\n",
        "            \"Directories\": directory_ok,\n",
        "            \"OpenCV\": opencv_ok,\n",
        "            \"YOLO\": yolo_ok\n",
        "        }\n",
        "        \n",
        "        for component, status in results.items():\n",
        "            print(f\"{component}: {'✅' if status else '❌'}\")\n",
        "        \n",
        "        return 0 if all(results.values()) else 1\n",
        "    \n",
        "    # Full test suite\n",
        "    roboflow_ok = test_roboflow_integration()\n",
        "    supervision_ok = test_supervision_tracking()\n",
        "    video_ok = test_video_processing()\n",
        "    basketball_ok = test_basketball_pipeline()\n",
        "    gpu_ok = test_gpu_integration()\n",
        "    \n",
        "    print_section(\"COMPREHENSIVE TEST SUMMARY\")\n",
        "    results = {\n",
        "        \"Directories\": directory_ok,\n",
        "        \"OpenCV\": opencv_ok,\n",
        "        \"YOLO/Ultralytics\": yolo_ok,\n",
        "        \"Roboflow\": roboflow_ok,\n",
        "        \"Supervision\": supervision_ok,\n",
        "        \"Video Processing\": video_ok,\n",
        "        \"Basketball Pipeline\": basketball_ok,\n",
        "        \"GPU Integration\": gpu_ok\n",
        "    }\n",
        "    \n",
        "    for component, status in results.items():\n",
        "        status_symbol = \"✅\" if status else \"❌\"\n",
        "        print(f\"{component}: {status_symbol}\")\n",
        "    \n",
        "    all_ok = all(results.values())\n",
        "    \n",
        "    if not all_ok:\n",
        "        print(\"\\n⚠️  Some components failed. Common fixes:\")\n",
        "        print(\"  - Set ROBOFLOW_API_KEY for Roboflow integration\")\n",
        "        print(\"  - Ensure GPU drivers are properly installed\")\n",
        "        print(\"  - Check that all required directories exist\")\n",
        "        print(\"  - Verify ffmpeg installation for video processing\")\n",
        "    else:\n",
        "        print(\"\\n🎉 All computer vision components are working correctly!\")\n",
        "        print(\"Basketball detection pipeline is ready for use!\")\n",
        "    \n",
        "    return 0 if all_ok else 1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../../.devcontainer/tests/test_summary.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../../.devcontainer/tests/test_summary.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"Aggregated checks for the devcontainer layout and GPU readiness.\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "\n",
        "def section(t):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(t)\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def test_structure() -> bool:\n",
        "    section(\"STRUCTURE\")\n",
        "    expected = [\n",
        "        '/workspace/.devcontainer/docker-compose.yml',  # MOVED FROM ROOT\n",
        "        '/workspace/pyproject.toml',\n",
        "        '/workspace/.devcontainer/devcontainer.json',\n",
        "        '/workspace/.devcontainer/Dockerfile',\n",
        "        '/workspace/.devcontainer/.env.template',\n",
        "        '/workspace/.devcontainer/.dockerignore',\n",
        "        '/app/validate_gpu.py',\n",
        "        '/app/tests/'\n",
        "    ]\n",
        "    ok = True\n",
        "    for p in expected:\n",
        "        if os.path.exists(p):\n",
        "            print(\"ok:\", p)\n",
        "        else:\n",
        "            print(\"missing:\", p)\n",
        "            ok = False\n",
        "    return ok\n",
        "\n",
        "\n",
        "def test_uv() -> bool:\n",
        "    section(\"UV\")\n",
        "    try:\n",
        "        r = subprocess.run(['uv', '--version'], capture_output=True, text=True)\n",
        "        print(r.stdout.strip() or r.stderr.strip())\n",
        "        return r.returncode == 0\n",
        "    except FileNotFoundError:\n",
        "        print('uv not in PATH')\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_pytorch() -> bool:\n",
        "    section(\"PYTORCH\")\n",
        "    try:\n",
        "        import torch\n",
        "        print(\"version:\", torch.__version__)\n",
        "        print(\"cuda:\", torch.cuda.is_available())\n",
        "        if torch.cuda.is_available():\n",
        "            d = torch.device('cuda:0')\n",
        "            x = torch.ones(512, 512, device=d)\n",
        "            y = torch.sum(x)\n",
        "            print(\"sum:\", y.item())\n",
        "            return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(\"error:\", e)\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_jax() -> bool:\n",
        "    section(\"JAX\")\n",
        "    try:\n",
        "        import jax, jax.numpy as jnp\n",
        "\n",
        "        # Show all devices for visibility\n",
        "        devs = jax.devices()\n",
        "        print(\"devices:\", devs)\n",
        "\n",
        "        # Prefer the supported filtered query\n",
        "        gpus = jax.devices(\"gpu\")\n",
        "\n",
        "        # Fallback for older/newer renderings (e.g., \"CudaDevice(id=0)\")\n",
        "        if not gpus:\n",
        "            gpus = [\n",
        "                d for d in devs\n",
        "                if getattr(d, \"platform\", \"\").lower() in {\"gpu\", \"cuda\"} or \"cuda\" in str(d).lower()\n",
        "            ]\n",
        "\n",
        "        if not gpus:\n",
        "            print(\"no gpu devices detected by jax\")\n",
        "            return False\n",
        "\n",
        "        # Tiny compute on the first GPU to ensure execution\n",
        "        x = jnp.ones((512, 512), dtype=jnp.float32)\n",
        "        x = jax.device_put(x, gpus[0])\n",
        "        s = jnp.sum(x).block_until_ready()\n",
        "        print(\"sum:\", float(s))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"error:\", e)\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "def main() -> int:\n",
        "    s_ok = test_structure()\n",
        "    uv_ok = test_uv()\n",
        "    pt_ok = test_pytorch()\n",
        "    j_ok = test_jax()\n",
        "\n",
        "    section(\"SUMMARY\")\n",
        "    print(\"structure:\", s_ok, \"uv:\", uv_ok, \"pytorch:\", pt_ok, \"jax:\", j_ok)\n",
        "    return 0 if all([s_ok, uv_ok, pt_ok, j_ok]) else 1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "docker-dev-template",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

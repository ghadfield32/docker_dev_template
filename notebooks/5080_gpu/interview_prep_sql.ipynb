{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7105b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id name  manager_id  salary\n",
      "  1  Ann         NaN     100\n",
      "  2  Bob         1.0     120\n",
      "  3  Cai         1.0      90\n",
      "  4  Dia         2.0     130\n",
      "employee manager  emp_sal  mgr_sal\n",
      "     Bob     Ann      120      100\n",
      "     Dia     Bob      130      120\n",
      "emp dept  salary\n",
      "Ann    A     100\n",
      "Bob    A     120\n",
      "Cai    A     120\n",
      "Dia    B     130\n",
      "Eli    B     130\n",
      "Flo    B     110\n",
      "dept emp  salary\n",
      "   A Bob     120\n",
      "   B Dia     130\n",
      " id visit_date  people\n",
      "  1 2023-01-01      10\n",
      "  2 2023-01-02     120\n",
      "  3 2023-01-03     130\n",
      "  4 2023-01-04     140\n",
      "  5 2023-01-05      50\n",
      "  6 2023-01-06     160\n",
      "  7 2023-01-07     170\n",
      " id visit_date  people\n",
      "  2 2023-01-02     120\n",
      "  3 2023-01-03     130\n",
      "  4 2023-01-04     140\n",
      "       day  cancellation_rate\n",
      "2013-10-01                0.5\n",
      "2013-10-02                0.0\n",
      "2013-10-03                1.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "median == windowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 161\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m m1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mequals(m2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m6\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian == quantile_cont\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m merged_13 \u001b[38;5;241m=\u001b[39m m1\u001b[38;5;241m.\u001b[39mmerge(m3, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany\u001b[39m\u001b[38;5;124m\"\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_3\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (merged_13[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmed_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m6\u001b[39m) \u001b[38;5;241m==\u001b[39m merged_13[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmed_3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m6\u001b[39m))\u001b[38;5;241m.\u001b[39mall(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian == windowed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# %% 6) Pure-Pandas mirror\u001b[39;00m\n\u001b[1;32m    164\u001b[0m dept[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    165\u001b[0m   dept\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdept\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m\"\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;28;01mFalse\u001b[39;00m])\n\u001b[1;32m    166\u001b[0m       \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdept\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcumcount()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    167\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: median == windowed"
     ]
    }
   ],
   "source": [
    "# %% 0) Setup (minimal)\n",
    "import duckdb, pandas as pd\n",
    "def show(df, n=10): print(df.head(n).to_string(index=False))\n",
    "\n",
    "# %% 1) Self-join (LC-181)\n",
    "emp = pd.DataFrame({\n",
    "  \"id\":[1,2,3,4], \"name\":[\"Ann\",\"Bob\",\"Cai\",\"Dia\"],\n",
    "  \"manager_id\":[None,1,1,2], \"salary\":[100,120,90,130]\n",
    "})\n",
    "show(emp)\n",
    "\n",
    "res_181 = duckdb.sql(\"\"\"\n",
    "SELECT w.name AS employee, m.name AS manager, w.salary AS emp_sal, m.salary AS mgr_sal\n",
    "FROM emp w\n",
    "JOIN emp m ON w.manager_id = m.id\n",
    "WHERE w.salary > m.salary\n",
    "\"\"\").df()\n",
    "show(res_181)\n",
    "\n",
    "# Quick checks\n",
    "assert duckdb.sql(\"\"\"\n",
    "SELECT COUNT(*) FROM emp WHERE manager_id IS NOT NULL AND id = manager_id\n",
    "\"\"\").fetchone()[0] == 0, \"No one should manage themselves\"\n",
    "assert (res_181[\"emp_sal\"] > res_181[\"mgr_sal\"]).all(), \"All rows must have emp_sal > mgr_sal\"\n",
    "\n",
    "# %% 2) Top-N per group (LC-184 — ROW_NUMBER())\n",
    "dept = pd.DataFrame({\n",
    "  \"emp\":[\"Ann\",\"Bob\",\"Cai\",\"Dia\",\"Eli\",\"Flo\"],\n",
    "  \"dept\":[\"A\",\"A\",\"A\",\"B\",\"B\",\"B\"],\n",
    "  \"salary\":[100,120,120,130,130,110]\n",
    "})\n",
    "show(dept)\n",
    "\n",
    "top_per_dept = duckdb.sql(\"\"\"\n",
    "WITH ranked AS (\n",
    "  SELECT *, ROW_NUMBER() OVER (PARTITION BY dept ORDER BY salary DESC, emp) rn\n",
    "  FROM dept\n",
    ")\n",
    "SELECT dept, emp, salary FROM ranked WHERE rn=1 ORDER BY dept\n",
    "\"\"\").df()\n",
    "show(top_per_dept)\n",
    "\n",
    "# Check vs MAX(salary) per dept (pure Pandas, no temp view)\n",
    "mx = dept.groupby(\"dept\", as_index=False)[\"salary\"].max().rename(columns={\"salary\":\"m\"})\n",
    "assert top_per_dept.merge(mx, on=\"dept\").eval(\"salary==m\").all(), \"Top row must match per-dept MAX salary\"\n",
    "\n",
    "# %% 3) Gaps & Islands (≥3 consecutive hot days) — no lateral join\n",
    "stadium = pd.DataFrame({\n",
    " \"id\":[1,2,3,4,5,6,7],\n",
    " \"visit_date\":pd.to_datetime([\"2023-01-01\",\"2023-01-02\",\"2023-01-03\",\n",
    "                              \"2023-01-04\",\"2023-01-05\",\"2023-01-06\",\"2023-01-07\"]),\n",
    " \"people\":[10,120,130,140,50,160,170]\n",
    "})\n",
    "show(stadium)\n",
    "\n",
    "streak3 = duckdb.sql(\"\"\"\n",
    "WITH mark AS (\n",
    "  SELECT id, visit_date, people, (people>=100) AS hot\n",
    "  FROM stadium\n",
    "),\n",
    "hot_rows AS (\n",
    "  SELECT *,\n",
    "         id - ROW_NUMBER() OVER (ORDER BY id) AS grp   -- same constant within a run\n",
    "  FROM mark\n",
    "  WHERE hot\n",
    "),\n",
    "kept AS (\n",
    "  SELECT grp\n",
    "  FROM hot_rows\n",
    "  GROUP BY grp\n",
    "  HAVING COUNT(*) >= 3\n",
    ")\n",
    "SELECT s.*\n",
    "FROM hot_rows h\n",
    "JOIN kept k USING (grp)\n",
    "JOIN stadium s ON s.id = h.id\n",
    "ORDER BY s.id\n",
    "\"\"\").df()\n",
    "show(streak3)\n",
    "\n",
    "# Check every included hot island has length >= 3\n",
    "bad_groups = duckdb.sql(\"\"\"\n",
    "WITH mark AS (SELECT id, (people>=100) AS hot FROM stadium),\n",
    "hot_rows AS (\n",
    "  SELECT *, id - ROW_NUMBER() OVER (ORDER BY id) AS grp\n",
    "  FROM mark WHERE hot\n",
    "),\n",
    "kept AS (\n",
    "  SELECT grp FROM hot_rows GROUP BY grp HAVING COUNT(*) >= 3\n",
    "),\n",
    "lens AS (SELECT grp, COUNT(*) AS n FROM hot_rows GROUP BY grp)\n",
    "SELECT COUNT(*) \n",
    "FROM lens\n",
    "JOIN kept USING (grp)\n",
    "WHERE n < 3\n",
    "\"\"\").fetchone()[0]\n",
    "assert bad_groups == 0, \"All included hot runs must be length ≥ 3\"\n",
    "\n",
    "\n",
    "\n",
    "# %% 4) Conditional aggregation + multi-join (LC-262)\n",
    "trips = pd.DataFrame({\n",
    " \"id\":[1,2,3,4],\n",
    " \"client_id\":[10,11,10,12],\n",
    " \"driver_id\":[20,21,22,21],\n",
    " \"status\":[\"completed\",\"cancelled_by_client\",\"completed\",\"cancelled_by_driver\"],\n",
    " \"request_at\":pd.to_datetime([\"2013-10-01\",\"2013-10-01\",\"2013-10-02\",\"2013-10-03\"])\n",
    "})\n",
    "users = pd.DataFrame({\n",
    " \"users_id\":[10,11,12,20,21,22],\n",
    " \"role\":[\"client\",\"client\",\"client\",\"driver\",\"driver\",\"driver\"],\n",
    " \"banned\":[\"No\",\"No\",\"No\",\"No\",\"No\",\"No\"]\n",
    "})\n",
    "\n",
    "cancel_rates = duckdb.sql(\"\"\"\n",
    "WITH j AS (\n",
    "  SELECT DATE_TRUNC('day', t.request_at)::DATE AS day, t.status\n",
    "  FROM trips t\n",
    "  JOIN users c ON t.client_id=c.users_id AND c.role='client' AND c.banned='No'\n",
    "  JOIN users d ON t.driver_id=d.users_id AND d.role='driver' AND d.banned='No'\n",
    ")\n",
    "SELECT day,\n",
    "       ROUND( SUM((status!='completed')::INT)::DOUBLE / COUNT(*), 2) AS cancellation_rate\n",
    "FROM j\n",
    "GROUP BY day ORDER BY day\n",
    "\"\"\").df()\n",
    "show(cancel_rates)\n",
    "\n",
    "# Checks\n",
    "assert ((cancel_rates[\"cancellation_rate\"]>=0) & (cancel_rates[\"cancellation_rate\"]<=1)).all(), \"Rates must be in [0,1]\"\n",
    "assert duckdb.sql(\"\"\"\n",
    "SELECT COUNT(*) FROM trips t\n",
    "JOIN users c ON t.client_id=c.users_id\n",
    "WHERE c.role='client' AND c.banned<>'No'\n",
    "\"\"\").fetchone()[0] == 0, \"No banned clients included\"\n",
    "\n",
    "# %% 5) Group median three ways (LC-569)\n",
    "pay = pd.DataFrame({\n",
    " \"company\":[\"A\",\"A\",\"A\",\"B\",\"B\",\"C\"],\n",
    " \"salary\":[451,513,700,234,1154,2645]\n",
    "})\n",
    "\n",
    "m1 = duckdb.sql(\"SELECT company, median(salary) AS med FROM pay GROUP BY company ORDER BY company\").df()\n",
    "m2 = duckdb.sql(\"SELECT company, quantile_cont(salary,0.5) AS med FROM pay GROUP BY company ORDER BY company\").df()\n",
    "m3 = duckdb.sql(\"\"\"\n",
    "WITH r AS (\n",
    "  SELECT *, COUNT(*) OVER (PARTITION BY company) n,\n",
    "         ROW_NUMBER() OVER (PARTITION BY company ORDER BY salary) rn\n",
    "  FROM pay\n",
    ")\n",
    "SELECT company, AVG(salary) AS med\n",
    "FROM r\n",
    "WHERE rn IN ((n+1)/2, (n+2)/2)\n",
    "GROUP BY company\n",
    "ORDER BY company\n",
    "\"\"\").df()\n",
    "\n",
    "# Float-safe equality checks\n",
    "assert m1[\"med\"].round(6).equals(m2[\"med\"].round(6)), \"median == quantile_cont\"\n",
    "merged_13 = m1.merge(m3, on=\"company\", suffixes=(\"_1\",\"_3\"))\n",
    "assert (merged_13[\"med_1\"].round(6) == merged_13[\"med_3\"].round(6)).all(), \"median == windowed\"\n",
    "\n",
    "# %% 6) Pure-Pandas mirror\n",
    "dept[\"rn\"] = (\n",
    "  dept.sort_values([\"dept\",\"salary\"], ascending=[True,False])\n",
    "      .groupby(\"dept\").cumcount()+1\n",
    ")\n",
    "top_pd = dept.query(\"rn==1\")[[\"dept\",\"emp\",\"salary\"]].sort_values(\"dept\")\n",
    "show(top_pd)\n",
    "\n",
    "maxs = dept.groupby(\"dept\", as_index=False)[\"salary\"].max().rename(columns={\"salary\":\"m\"})\n",
    "pd_check = top_pd.merge(maxs, on=\"dept\")\n",
    "assert (pd_check[\"salary\"] == pd_check[\"m\"]).all(), \"Pandas top-1 matches group MAX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d59b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure no other containers are running for dev container, if they are stop and remove them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .gitattributes\n",
    "# Enforce LF endings in all scripts & Docker artifacts\n",
    "*.sh       text eol=lf\n",
    "*.bash     text eol=lf\n",
    "Dockerfile text eol=lf\n",
    "*.py       text eol=lf\n",
    "*.env      text eol=lf\n",
    "*.yml      text eol=lf\n",
    "*.yaml     text eol=lf\n",
    "*.json     text eol=lf\n",
    "*.md       text eol=lf\n",
    "*.txt      text eol=lf\n",
    "*.lock     text eol=lf\n",
    "*.toml     text eol=lf\n",
    "*.cfg      text eol=lf\n",
    "*.ini      text eol=lf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .gitignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .gitignore\n",
    ".env\n",
    "dev.env\n",
    ".devcontainer/.env.runtime\n",
    "\n",
    "# Railway CLI (never commit tokens)\n",
    ".railway/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/.dockerignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/.dockerignore\n",
    "**/.git\n",
    "**/.vscode\n",
    "**/.idea\n",
    "**/__pycache__\n",
    "**/*.pyc\n",
    "**/*.pyo\n",
    "**/*.pyd\n",
    "**/*.swp\n",
    "**/venv\n",
    "**/env\n",
    ".env\n",
    "*.code-workspace\n",
    "data/\n",
    "notebooks/**/*.ipynb_checkpoints\n",
    "*.log\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "\n",
    "# --- NEW: keep build context tiny & readable ---\n",
    "mlruns/          # MLflow runs & artifacts (often huge, root-owned)\n",
    "mlruns/**        # ensure nested paths are ignored\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .dockerignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .dockerignore\n",
    "**/.git\n",
    "**/.vscode\n",
    "**/.idea\n",
    "**/__pycache__\n",
    "**/*.pyc\n",
    "**/*.pyo\n",
    "**/*.pyd\n",
    "**/*.swp\n",
    "**/venv\n",
    "**/env\n",
    ".env\n",
    "*.code-workspace\n",
    "data/\n",
    "notebooks/**/*.ipynb_checkpoints\n",
    "*.log\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "\n",
    "# --- NEW: keep build context tiny & readable ---\n",
    "mlruns/          # MLflow runs & artifacts (often huge, root-owned)\n",
    "mlruns/**        # ensure nested paths are ignored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env.template\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env.template \n",
    "ENV_NAME=docker_dev_template\n",
    "CUDA_TAG=12.8.0\n",
    "DOCKER_BUILDKIT=1\n",
    "HOST_JUPYTER_PORT=8890\n",
    "HOST_TENSORBOARD_PORT=6008\n",
    "HOST_EXPLAINER_PORT=8050\n",
    "HOST_STREAMLIT_PORT=8501\n",
    "HOST_MLFLOW_PORT=5000\n",
    "PYTHON_VER=3.10\n",
    "JAX_PLATFORM_NAME=gpu\n",
    "XLA_PYTHON_CLIENT_PREALLOCATE=true\n",
    "XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "XLA_PYTHON_CLIENT_MEM_FRACTION=0.95\n",
    "XLA_FLAGS=--xla_force_host_platform_device_count=1\n",
    "JAX_DISABLE_JIT=false\n",
    "JAX_ENABLE_X64=false\n",
    "TF_FORCE_GPU_ALLOW_GROWTH=false\n",
    "JAX_PREALLOCATION_SIZE_LIMIT_BYTES=8589934592\n",
    "\n",
    "RAILWAY_TOKEN=f1c333f4-ff09-480b-abcf-3bf81500ec7a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .vscode/settings.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile .vscode/settings.json\n",
    "{\n",
    "    \"http.proxySupport\": \"off\",\n",
    "    \"update.mode\": \"manual\",\n",
    "    \"extensions.autoUpdate\": false,\n",
    "    \"extensions.autoCheckUpdates\": false,\n",
    "    \"python.defaultInterpreterPath\": \"/app/.venv/bin/python\",\n",
    "    \"jupyter.interactiveWindow.textEditor.executeSelection\": true,\n",
    "    \"jupyter.widgetScriptSources\": [\"jsdelivr.com\", \"unpkg.com\"],\n",
    "    \"jupyter.experiments.enabled\": false,\n",
    "    \"jupyter.telemetry.enabled\": false,\n",
    "    \"python.telemetry.enabled\": false,\n",
    "    \"telemetry.telemetryLevel\": \"off\"\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/devcontainer.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/devcontainer.json\n",
    "{\n",
    "  \"name\": \"docker_dev_template_uv\",\n",
    "  \"dockerComposeFile\": [\"../docker-compose.yml\"],\n",
    "  \"service\": \"datascience\",\n",
    "  \"workspaceFolder\": \"/workspace\",\n",
    "  \"shutdownAction\": \"stopCompose\",\n",
    "  \"initializeCommand\": \".devcontainer/generate-project-name.sh\",\n",
    "  \"runArgs\": [\n",
    "    \"--gpus\", \"all\",\n",
    "    \"--env-file\", \"${localWorkspaceFolder}/.devcontainer/.env.runtime\"\n",
    "  ],\n",
    "  \"customizations\": {\n",
    "    \"vscode\": {\n",
    "      \"extensions\": [\n",
    "        \"ms-python.python\",\n",
    "        \"ms-python.vscode-pylance\",\n",
    "        \"ms-toolsai.jupyter\",\n",
    "        \"ms-toolsai.jupyter-renderers\"\n",
    "      ],\n",
    "      \"settings\": {\n",
    "        // 1. COMPREHENSIVE TELEMETRY SETTINGS\n",
    "        \"telemetry.telemetryLevel\": \"off\",\n",
    "        \"python.telemetry.enabled\": false,\n",
    "        \"jupyter.telemetry.enabled\": false,\n",
    "        \"jupyter.experiments.enabled\": false,\n",
    "        \"update.mode\": \"manual\",\n",
    "        \"extensions.autoUpdate\": false,\n",
    "        \"extensions.autoCheckUpdates\": false,\n",
    "\n",
    "        // 2. MOVE HEAVY EXTENSIONS TO LOCAL UI HOST\n",
    "        \"remote.extensionKind\": {\n",
    "          \"ms-python.python\": [\"ui\"],\n",
    "          \"ms-python.vscode-pylance\": [\"ui\"],\n",
    "          \"ms-toolsai.jupyter\": [\"ui\"],\n",
    "          \"ms-toolsai.jupyter-renderers\": [\"ui\"]\n",
    "        },\n",
    "\n",
    "        // 3. PYTHON AND JUPYTER SETTINGS\n",
    "        \"python.defaultInterpreterPath\": \"/workspace/.venv/bin/python\",\n",
    "        \"jupyter.interactiveWindow.textEditor.executeSelection\": true,\n",
    "        \"jupyter.widgetScriptSources\": [\"jsdelivr.com\", \"unpkg.com\"]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"remoteEnv\": {\n",
    "    \"JUPYTER_ENABLE_LAB\": \"true\"\n",
    "  },\n",
    "\n",
    "  // After container creation, set up env, check UV, Python, and key libs\n",
    "  \"postCreateCommand\": [\n",
    "    \"/bin/sh\",\n",
    "    \"-c\",\n",
    "    \".devcontainer/setup_env.sh && \\\\\\necho '## uv diagnostics ##' && uv --version && \\\\\\necho '## python ##' && which python && python -V && \\\\\\nexec .devcontainer/verify_env.py\"\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/Dockerfile\n",
    "# .devcontainer/Dockerfile — uv‑based replacement for the previous Conda image\n",
    "# -----------------------------------------------------------------------------\n",
    "# CUDA + cuDNN base with drivers already installed --------------------------------\n",
    "ARG CUDA_TAG=12.8.0              # <── single source of truth\n",
    "FROM nvidia/cuda:${CUDA_TAG}-cudnn-devel-ubuntu22.04\n",
    "\n",
    "# ---------- build-time ARGs ---------------------------------------------------\n",
    "ARG PYTHON_VER=3.10\n",
    "ARG ENV_NAME=docker_dev_template\n",
    "ARG JAX_PREALLOCATE=true\n",
    "ARG JAX_MEM_FRAC=0.95\n",
    "ARG JAX_ALLOCATOR=platform\n",
    "ARG JAX_PREALLOC_LIMIT=8589934592\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) Core OS deps, build tools, & Python (system) -----------------------------\n",
    "RUN --mount=type=cache,target=/var/cache/apt \\\n",
    "    --mount=type=cache,target=/var/lib/apt \\\n",
    "    apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        bash curl ca-certificates git procps htop util-linux build-essential \\\n",
    "        python3 python3-venv python3-pip python3-dev \\\n",
    "        autoconf automake libtool m4 cmake pkg-config \\\n",
    "        jags iproute2 net-tools lsof \\\n",
    "        && pkg-config --modversion jags \\\n",
    "        && apt-get clean && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install Node.js for VS Code remote extension host\n",
    "RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash - && \\\n",
    "    apt-get update && apt-get install -y nodejs && \\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install Railway CLI\n",
    "RUN npm install -g @railway/cli\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2) Copy a *pinned* uv & uvx binary pair from the official distroless image --\n",
    "COPY --from=ghcr.io/astral-sh/uv:0.7.12 /uv /uvx /bin/\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) Create project dir & copy only the lock/manifest for best layer‑caching --\n",
    "WORKDIR /app\n",
    "COPY pyproject.toml uv.lock* ./\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4) Create an in-project venv, install deps, then symlink into /workspace\n",
    "RUN --mount=type=cache,target=/root/.cache/uv \\\n",
    "    mkdir -p /workspace && \\\n",
    "    uv venv .venv --python \"${PYTHON_VER}\" --prompt \"${ENV_NAME}\" && \\\n",
    "    (uv sync --locked || (echo \"⚠️  Lock drift detected – regenerating\" \\\n",
    "        && uv lock --upgrade --quiet && uv sync)) && \\\n",
    "    ln -s /app/.venv /workspace/.venv\n",
    "\n",
    "# Promote venv for all later layers ------------------------------------------------\n",
    "ENV VIRTUAL_ENV=/app/.venv\n",
    "ENV PATH=\"/app/.venv/bin:${PATH}\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5) ---------- CUDA wheels -------------------------------------------------------\n",
    "RUN --mount=type=cache,target=/root/.cache/uv \\\n",
    "    uv pip install --pre --no-cache-dir \\\n",
    "        torch torchvision torchaudio \\\n",
    "        --index-url https://download.pytorch.org/whl/nightly/cu128 && \\\n",
    "    uv pip install --no-cache-dir \\\n",
    "        \"jax[cuda12]==0.6.0\" \\\n",
    "        -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "\n",
    "# --- CUDA toolkit sanity check (robust for runtime *and* devel images) ------\n",
    "RUN set -e; \\\n",
    "    # 1️⃣ First try: any cuda-<ver> folder?\n",
    "    CUDA_REAL=\"$(ls -d /usr/local/cuda-* 2>/dev/null | sort -V | tail -n1 || true)\"; \\\n",
    "    # 2️⃣ Fallback: flat layout shipped by some runtime images\n",
    "    if [ -z \"$CUDA_REAL\" ] && [ -d /usr/local/cuda ]; then \\\n",
    "        CUDA_REAL=\"/usr/local/cuda\"; \\\n",
    "    fi; \\\n",
    "    # 3️⃣ Bail if still empty\n",
    "    if [ -z \"$CUDA_REAL\" ]; then \\\n",
    "        echo '❌  No CUDA toolkit folder found — aborting.' >&2; exit 1; \\\n",
    "    fi; \\\n",
    "    # 4️⃣ Refresh the canonical symlink only when needed\n",
    "    if [ \"$CUDA_REAL\" != \"/usr/local/cuda\" ]; then \\\n",
    "        echo \"🔧  Linking /usr/local/cuda -> $CUDA_REAL\"; \\\n",
    "        ln -sfn \"$CUDA_REAL\" /usr/local/cuda; \\\n",
    "    fi; \\\n",
    "    echo \"🟢  CUDA toolkit detected at $CUDA_REAL\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6) Install PyJAGS with the cstdint header work‑around -----------------------\n",
    "RUN CPPFLAGS=\"-include cstdint\" uv pip install --no-build-isolation pyjags==1.3.8\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7) Copy *rest* of the project after deps → fast rebuild when code changes ---\n",
    "COPY . /app\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7.1) Convert Windows line endings to Unix (CR-LF → LF) ---------------------\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends dos2unix && \\\n",
    "    find /app/.devcontainer -type f -name \"*.sh\" -exec dos2unix {} + && \\\n",
    "    find /app -type f -name \"*.py\" -perm -u=x -exec dos2unix {} + && \\\n",
    "    apt-get purge -y dos2unix && apt-get autoremove -y && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 8) GPU‑tuning env vars (carried forward from Conda‑based image) -------------\n",
    "ENV XLA_PYTHON_CLIENT_PREALLOCATE=${JAX_PREALLOCATE}\n",
    "ENV XLA_PYTHON_CLIENT_MEM_FRACTION=${JAX_MEM_FRAC}\n",
    "ENV XLA_PYTHON_CLIENT_ALLOCATOR=${JAX_ALLOCATOR}\n",
    "ENV JAX_PLATFORM_NAME=gpu\n",
    "ENV XLA_FLAGS=\"--xla_force_host_platform_device_count=1\"\n",
    "ENV JAX_DISABLE_JIT=false\n",
    "ENV JAX_ENABLE_X64=false\n",
    "ENV TF_FORCE_GPU_ALLOW_GROWTH=false\n",
    "ENV JAX_PREALLOCATION_SIZE_LIMIT_BYTES=${JAX_PREALLOC_LIMIT}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 9) Library path so PyJAGS & CUDA libs resolve correctly ---------------------\n",
    "ENV LD_LIBRARY_PATH=\"/app/.venv/lib:${LD_LIBRARY_PATH}\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 10) Final working directory & default command ------------------------------\n",
    "WORKDIR /workspace\n",
    "CMD [\"bash\"]\n",
    "\n",
    "# 11) Force login shells & VS Code terminals to land in /workspace\n",
    "RUN echo 'cd /workspace' > /etc/profile.d/99-workspace-cd.sh\n",
    "\n",
    "# 12) Force every IPython / Jupyter kernel to start in /workspace\n",
    "RUN mkdir -p /root/.ipython/profile_default/startup && \\\n",
    "    printf \"import os, sys\\nos.chdir('/workspace')\\nsys.path.append('/workspace')\\n\" \\\n",
    "      > /root/.ipython/profile_default/startup/00-cd-workspace.py\n",
    "\n",
    "# 13) Auto-activate uv venv in every login shell\n",
    "RUN echo '. /app/.venv/bin/activate' > /etc/profile.d/10-uv-activate.sh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/verify_env.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/verify_env.py\n",
    "#!/usr/bin/env python3\n",
    "import encodings, jupyterlab, torch, jax, sys, os, subprocess\n",
    "import pathlib\n",
    "\n",
    "print(\"## Python & library diagnostics ##\")\n",
    "print(\"Python:\", sys.executable, sys.version.split()[0])\n",
    "print(\"🟢 encodings OK\")\n",
    "print(\"🟢 jupyterlab OK\")\n",
    "print(\"🟢 torch\", torch.__version__, \"CUDA:\", torch.cuda.is_available())\n",
    "print(\"🟢 jax\", jax.__version__, \"devices:\", jax.devices())\n",
    "\n",
    "# Check Railway CLI\n",
    "try:\n",
    "    railway_version = subprocess.check_output([\"railway\", \"--version\"], stderr=subprocess.STDOUT).decode().strip()\n",
    "    print(\"🛤️  railway\", railway_version)\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"⚠️  railway CLI not found\")\n",
    "\n",
    "# Check for CRLF line endings in scripts\n",
    "print(\"\\n## Line ending checks ##\")\n",
    "devcontainer_dir = pathlib.Path(\"/workspace/.devcontainer\")\n",
    "crlf_files = []\n",
    "\n",
    "if devcontainer_dir.exists():\n",
    "    for script_file in devcontainer_dir.glob(\"*.sh\"):\n",
    "        try:\n",
    "            with open(script_file, 'rb') as f:\n",
    "                content = f.read()\n",
    "                if b'\\r\\n' in content:\n",
    "                    crlf_files.append(script_file.name)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Could not check {script_file}: {e}\")\n",
    "\n",
    "if crlf_files:\n",
    "    print(\"❌ CRLF line endings found in:\", \", \".join(crlf_files))\n",
    "    print(\"   This will cause '/usr/bin/env: sh\\\\r: No such file' errors!\")\n",
    "else:\n",
    "    print(\"🟢 All shell scripts have proper LF line endings\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/setup_env.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/setup_env.sh\n",
    "#!/usr/bin/env sh\n",
    "set -eu\n",
    "\n",
    "# Copy template only once so secrets are preserved\n",
    "if [ ! -f /workspace/.env ]; then\n",
    "  echo \"📝  Generating default .env from template\"\n",
    "  cp /workspace/.env.template /workspace/.env\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/gpu_verify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/gpu_verify.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Verify that the GPU is accessible and JAX is correctly configured.\n",
    "This script is used during container startup.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "def check_gpu():\n",
    "    print(\"Checking GPU availability...\")\n",
    "    try:\n",
    "        import jax\n",
    "        jax.config.update('jax_platform_name', 'gpu')\n",
    "        \n",
    "        # Get device count and details\n",
    "        devices = jax.devices()\n",
    "        device_count = len(devices)\n",
    "        print(f\"JAX version: {jax.__version__}\")\n",
    "        print(f\"Available devices: {device_count}\")\n",
    "        \n",
    "        for i, device in enumerate(devices):\n",
    "            print(f\"Device {i}: {device}\")\n",
    "        \n",
    "        if device_count == 0 or 'gpu' not in str(devices[0]).lower():\n",
    "            print(\"WARNING: No GPU devices found by JAX!\")\n",
    "            return False\n",
    "        \n",
    "        # Check CUDA configuration\n",
    "        import jax.tools.jax_jit\n",
    "        jit_info = jax.tools.jax_jit.get_jax_jit_flags()\n",
    "        print(f\"JIT configuration: {jit_info}\")\n",
    "        \n",
    "        # Run a simple GPU computation\n",
    "        print(\"Running a test computation on GPU...\")\n",
    "        import numpy as np\n",
    "        x = np.ones((1000, 1000))\n",
    "        result = jax.numpy.sum(x, axis=0)\n",
    "        print(f\"Test computation result shape: {result.shape}\")\n",
    "        \n",
    "        print(\"JAX GPU verification completed successfully!\")\n",
    "        return True\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"JAX not found! Make sure JAX is installed with GPU support.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPU verification: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = check_gpu()\n",
    "    if not success:\n",
    "        print(\"WARNING: GPU verification failed!\")\n",
    "        # Not exiting with error to allow container to start anyway\n",
    "        # sys.exit(1)\n",
    "    else:\n",
    "        sys.exit(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/jags_verify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/jags_verify.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Verify that PyJAGS is correctly installed and working.\n",
    "This script is used by the Docker container health check.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "try:\n",
    "    import pyjags\n",
    "    print(f\"PyJAGS version: {pyjags.__version__}\")\n",
    "    \n",
    "    # Create a simple model to verify that PyJAGS works\n",
    "    code = \"\"\"\n",
    "    model {\n",
    "        # Likelihood\n",
    "        y ~ dnorm(mu, 1/sigma^2)\n",
    "        \n",
    "        # Priors\n",
    "        mu ~ dnorm(0, 0.001)\n",
    "        sigma ~ dunif(0, 100)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample data\n",
    "    data = {'y': 0.5}\n",
    "    \n",
    "    # Initialize model with data\n",
    "    model = pyjags.Model(code, data=data, chains=1, adapt=100)\n",
    "    print(\"JAGS model initialized successfully!\")\n",
    "    \n",
    "    # Sample from the model\n",
    "    samples = model.sample(200, vars=['mu', 'sigma'])\n",
    "    print(\"JAGS sampling completed successfully!\")\n",
    "    \n",
    "    # Verify the samples\n",
    "    mu_samples = samples['mu']\n",
    "    sigma_samples = samples['sigma']\n",
    "    print(f\"mu mean: {mu_samples.mean():.4f}\")\n",
    "    print(f\"sigma mean: {sigma_samples.mean():.4f}\")\n",
    "    \n",
    "    print(\"PyJAGS verification completed successfully!\")\n",
    "    sys.exit(0)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyJAGS not found!\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error during PyJAGS verification: {e}\")\n",
    "    sys.exit(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/pyjags_patch.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/pyjags_patch.py\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def patch_pyjags_sources():\n",
    "    print(\"Downloading and patching PyJAGS source...\")\n",
    "    os.system(\"pip download --no-binary :all: pyjags==1.3.8\")\n",
    "    os.system(\"tar -xzf pyjags-1.3.8.tar.gz\")\n",
    "    os.chdir(\"pyjags-1.3.8\")\n",
    "    \n",
    "    # Add cstdint include to all cpp files\n",
    "    for root, dirs, files in os.walk(\"src\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".cpp\") or file.endswith(\".h\"):\n",
    "                filepath = os.path.join(root, file)\n",
    "                with open(filepath, 'r') as f:\n",
    "                    content = f.read()\n",
    "                if \"#include <cstdint>\" not in content:\n",
    "                    with open(filepath, 'w') as f:\n",
    "                        f.write(\"#include <cstdint>\\n\" + content)\n",
    "                    print(f\"Patched {filepath}\")\n",
    "    \n",
    "    # Build and install\n",
    "    os.system(\"pip install --no-build-isolation .\")\n",
    "    print(\"PyJAGS installation complete!\")\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(patch_pyjags_sources()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .pre-commit-config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile .pre-commit-config.yaml\n",
    "\n",
    "repos:\n",
    "  - repo: https://github.com/astral-sh/uv-pre-commit\n",
    "    rev: 0.5.7  # Use the ref you want to point at\n",
    "    hooks:\n",
    "      - id: uv-lock      # keep uv.lock in sync\n",
    "      - id: uv-export    \n",
    "        args: [--extra=dev, --output-file=requirements-dev.txt]\n",
    "  - repo: https://github.com/pre-commit/pre-commit-hooks\n",
    "    rev: v4.6.0\n",
    "    hooks:\n",
    "      - id: trailing-whitespace\n",
    "      - id: end-of-file-fixer\n",
    "      - id: check-yaml\n",
    "      - id: check-added-large-files\n",
    "  - repo: https://github.com/detailyang/pre-commit-dos2unix\n",
    "    rev: v1.1.0\n",
    "    hooks:\n",
    "      - id: dos2unix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docker-compose.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker-compose.yml\n",
    "# docker-compose.yml\n",
    "name: ${ENV_NAME:-docker_dev_template}\n",
    "\n",
    "services:\n",
    "  datascience:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: .devcontainer/Dockerfile\n",
    "      args:\n",
    "        PYTHON_VER: ${PYTHON_VER:-3.10}\n",
    "        ENV_NAME: ${ENV_NAME:-docker_dev_template}\n",
    "        JAX_PREALLOCATE: ${XLA_PYTHON_CLIENT_PREALLOCATE:-true}\n",
    "        JAX_MEM_FRAC: ${XLA_PYTHON_CLIENT_MEM_FRACTION:-0.95}\n",
    "        JAX_ALLOCATOR: ${XLA_PYTHON_CLIENT_ALLOCATOR:-platform}\n",
    "        JAX_PREALLOC_LIMIT: ${JAX_PREALLOCATION_SIZE_LIMIT_BYTES:-8589934592}\n",
    "\n",
    "    # (Removed explicit container_name to avoid \"already in use\" conflicts.)\n",
    "\n",
    "    # Enhanced restart policy to handle port conflicts\n",
    "    restart: unless-stopped\n",
    "\n",
    "    depends_on:\n",
    "      mlflow:\n",
    "        condition: service_healthy\n",
    "\n",
    "    gpus: all\n",
    "\n",
    "    environment:\n",
    "      - PYTHON_VER=${PYTHON_VER}\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics,display\n",
    "      - JAX_PLATFORM_NAME=${JAX_PLATFORM_NAME}\n",
    "      - XLA_PYTHON_CLIENT_PREALLOCATE=${XLA_PYTHON_CLIENT_PREALLOCATE}\n",
    "      - XLA_PYTHON_CLIENT_ALLOCATOR=${XLA_PYTHON_CLIENT_ALLOCATOR}\n",
    "      - XLA_PYTHON_CLIENT_MEM_FRACTION=${XLA_PYTHON_CLIENT_MEM_FRACTION}\n",
    "      - XLA_FLAGS=${XLA_FLAGS}\n",
    "      - JAX_DISABLE_JIT=${JAX_DISABLE_JIT}\n",
    "      - JAX_ENABLE_X64=${JAX_ENABLE_X64}\n",
    "      - TF_FORCE_GPU_ALLOW_GROWTH=${TF_FORCE_GPU_ALLOW_GROWTH}\n",
    "      - JAX_PREALLOCATION_SIZE_LIMIT_BYTES=${JAX_PREALLOCATION_SIZE_LIMIT_BYTES}\n",
    "      - RAILWAY_TOKEN=${RAILWAY_TOKEN}\n",
    "\n",
    "    volumes:\n",
    "      - .:/workspace\n",
    "      - ./mlruns:/workspace/mlruns        # new\n",
    "\n",
    "    ports:\n",
    "      # Enhanced port configuration with fallback options\n",
    "      - \"${HOST_JUPYTER_PORT:-8890}:8888\"\n",
    "      - \"${HOST_TENSORBOARD_PORT:-}:6008\"\n",
    "      - \"${HOST_EXPLAINER_PORT:-8050}:8050\"\n",
    "      - \"${HOST_STREAMLIT_PORT:-}:8501\"\n",
    "      - \"${HOST_FRONTEND_DEV_PORT:-5173}:5173\"  # Frontend development server\n",
    "      - \"${HOST_BACKEND_DEV_PORT:-5002}:5000\"   # Backend development server (host:5002 -> container:5000)\n",
    "\n",
    "    command: >\n",
    "      jupyter lab\n",
    "        --ip=0.0.0.0\n",
    "        --port=8888\n",
    "        --allow-root\n",
    "        --NotebookApp.token=\"${JUPYTER_TOKEN:-jupyter}\"\n",
    "        --NotebookApp.allow_origin='*'\n",
    "\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"bash --version && uv --help || exit 1\"]\n",
    "      interval: 30s\n",
    "      timeout: 5s\n",
    "      retries: 3\n",
    "\n",
    "    # Enhanced labels for better debugging\n",
    "    labels:\n",
    "      - \"com.docker.compose.project=${ENV_NAME:-docker_dev_template}\"\n",
    "      - \"com.docker.compose.service=datascience\"\n",
    "      - \"description=AI/ML Development Environment with GPU Support\"\n",
    "\n",
    "  # NFL Kicker Assessment App (Production Build Testing)\n",
    "  app:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"${HOST_APP_PORT:-5000}:5000\"\n",
    "    restart: unless-stopped\n",
    "    environment:\n",
    "      - NODE_ENV=production\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"wget --no-verbose --tries=1 --spider http://localhost:5000/api/ping || exit 1\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "      start_period: 30s\n",
    "    labels:\n",
    "      - \"description=NFL Kicker Assessment Application\"\n",
    "\n",
    "  mlflow:\n",
    "    image: ghcr.io/mlflow/mlflow:latest\n",
    "    command: >\n",
    "      mlflow server\n",
    "      --host 0.0.0.0\n",
    "      --port 5000\n",
    "      --backend-store-uri sqlite:///mlflow.db\n",
    "      --default-artifact-root /mlflow_artifacts\n",
    "    environment:\n",
    "      MLFLOW_EXPERIMENTS_DEFAULT_ARTIFACT_LOCATION: /mlflow_artifacts\n",
    "    volumes:\n",
    "      - ./mlruns:/mlflow_artifacts    # artifacts + run metadata\n",
    "      - ./mlflow_db:/mlflow_db        # SQLite backend store\n",
    "    ports:\n",
    "      - \"${HOST_MLFLOW_PORT:-5001}:5000\"  # Changed to avoid conflict with app\n",
    "    restart: unless-stopped\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\",\n",
    "             \"python - <<'PY'\\nimport requests,sys; requests.get('http://localhost:5000/health').raise_for_status()\\nPY\"]\n",
    "      interval: 10s\n",
    "      timeout: 3s\n",
    "      retries: 5\n",
    "      start_period: 30s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "%%writefile pyproject.toml\n",
    "[project]\n",
    "name = \"docker_dev_template\"\n",
    "version = \"0.1.0\"\n",
    "description = \"Pytorch and Jax GPU docker container\"\n",
    "authors = [\n",
    "  { name = \"Geoffrey Hadfield\" },\n",
    "]\n",
    "license = \"MIT\"\n",
    "readme = \"README.md\"\n",
    "\n",
    "# ─── Restrict to Python 3.10–3.12 ──────────────────────────────\n",
    "requires-python = \">=3.10,<3.13\"\n",
    "\n",
    "dependencies = [\n",
    "  \"pandas>=1.2.0\",\n",
    "  \"numpy>=1.20.0\",\n",
    "  \"matplotlib>=3.4.0\",\n",
    "  \"mlflow>=2.10.2\",\n",
    "  \"mlflow-skinny>=2.10.2\",\n",
    "  \"scikit-learn>=1.4.2\",\n",
    "  \"pymc>=5.0.0\",\n",
    "  \"arviz>=0.14.0\",\n",
    "  \"statsmodels>=0.13.0\",\n",
    "  \"jupyterlab>=3.0.0\",\n",
    "  \"seaborn>=0.11.0\",\n",
    "  \"tabulate>=0.9.0\",\n",
    "  \"shap>=0.40.0\",\n",
    "  \"xgboost>=1.5.0\",\n",
    "  \"lightgbm>=3.3.0\",\n",
    "  \"catboost>=1.2.8,<1.3.0\",\n",
    "  \"scipy>=1.7.0\",\n",
    "  \"shapash[report]>=2.3.0\",\n",
    "  \"shapiq>=0.1.0\",\n",
    "  \"explainerdashboard==0.5.1\",\n",
    "  \"ipywidgets>=8.0.0\",\n",
    "  \"nutpie>=0.7.1\",   # new: nutpie backend for PyMC\n",
    "  \"numpyro>=0.18.0,<1.0.0\",\n",
    "  \"jax==0.6.0\",\n",
    "  \"jaxlib==0.6.0\",\n",
    "  \"pytensor>=2.18.3\",  # explicit version for CUDA support\n",
    "  \"aesara>=2.9.4\",     # alternative backend option\n",
    "  \"tqdm>=4.67.0\",\n",
    "  \"pyarrow>=12.0.0\",\n",
    "  \"optuna>=3.0.0\",\n",
    "  \"optuna-integration[mlflow]>=0.2.0\",\n",
    "  \"omegaconf>=2.3.0,<2.4.0\",\n",
    "  \"hydra-core>=1.3.2,<1.4.0\",\n",
    "]\n",
    "\n",
    "[project.optional-dependencies]\n",
    "dev = [\n",
    "  \"pytest>=7.0.0\",\n",
    "  \"black>=23.0.0\",\n",
    "  \"isort>=5.0.0\",\n",
    "  \"flake8>=5.0.0\",\n",
    "  \"mypy>=1.0.0\",\n",
    "  \"invoke>=2.2\",\n",
    "]\n",
    "\n",
    "cuda = [\n",
    "  \"cupy-cuda12x>=12.0.0\",  # For CUDA 12.x\n",
    "]\n",
    "\n",
    "[tool.pytensor]\n",
    "# Default configuration for PyTensor\n",
    "device = \"cuda\"          # Use CUDA by default if available\n",
    "floatX = \"float32\"       # Use float32 by default for better CUDA performance\n",
    "allow_gc = true          # Allow garbage collection\n",
    "optimizer = \"fast_run\"   # Fast run optimization by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tasks.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tasks.py\n",
    "# tasks.py  ── invoke ≥2.2\n",
    "from invoke import task, Context  # type: ignore\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import tempfile\n",
    "import datetime as _dt\n",
    "import atexit\n",
    "import socket\n",
    "import contextlib\n",
    "import errno\n",
    "\n",
    "\n",
    "BASE_ENV = pathlib.Path(__file__).parent\n",
    "\n",
    "\n",
    "# Track temporary env files for cleanup\n",
    "_saved_env_files: List[str] = []\n",
    "\n",
    "\n",
    "def _parse_port(port: Union[str, int, None]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Parse and validate a port number.\n",
    "    \n",
    "    Args:\n",
    "        port: Port number as string or int, or None\n",
    "        \n",
    "    Returns:\n",
    "        Validated port number as int, or None if input was None\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If port is invalid or out of range\n",
    "    \"\"\"\n",
    "    if port is None:\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        port_int = int(port)\n",
    "        if not (0 < port_int < 65536):\n",
    "            raise ValueError(f\"Port {port_int} out of valid range (1-65535)\")\n",
    "        return port_int\n",
    "    except (TypeError, ValueError) as e:\n",
    "        raise ValueError(f\"Invalid port value: {port}\") from e\n",
    "\n",
    "\n",
    "def _first_free_port(start: int = 5200) -> int:\n",
    "    \"\"\"Return the first TCP port >= *start* that is unused on localhost.\"\"\"\n",
    "    print(f\"DEBUG: Searching for free port starting at {start}\")  # Debug\n",
    "    import socket\n",
    "    import contextlib\n",
    "    for port in range(start, 65535):\n",
    "        with contextlib.closing(socket.socket()) as s:\n",
    "            if s.connect_ex((\"127.0.0.1\", port)):\n",
    "                print(f\"DEBUG: Found free port {port}\")  # Debug\n",
    "                return port\n",
    "    raise RuntimeError(\"No free port found\")\n",
    "\n",
    "\n",
    "def _free_port(start=5200) -> int:\n",
    "    \"\"\"Find a free port by letting the OS assign one.\"\"\"\n",
    "    print(f\"DEBUG: Finding free port starting at {start}\")  # Debug\n",
    "    import socket\n",
    "    import contextlib\n",
    "    with contextlib.closing(\n",
    "        socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    ) as s:\n",
    "        s.bind(('', 0))\n",
    "        port = s.getsockname()[1]\n",
    "        print(f\"DEBUG: Found free port {port}\")  # Debug\n",
    "        return port\n",
    "\n",
    "\n",
    "def _port_free(host: str, port: int, timeout: float = 0.1) -> bool:\n",
    "    \"\"\"\n",
    "    Return True iff *host:port* is NOT in use.\n",
    "\n",
    "    Uses a non-blocking TCP connect – works on Linux, macOS, Windows,\n",
    "    inside or outside WSL – and does **not** rely on lsof / netstat.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Checking if port {port} is free on {host}\")  # Debug\n",
    "    try:\n",
    "        with contextlib.closing(\n",
    "            socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        ) as s:\n",
    "            s.settimeout(timeout)\n",
    "            s.connect((host, port))\n",
    "            print(f\"DEBUG: Port {port} is in use\")  # Debug\n",
    "            return False      # connection succeeded ⇒ something listening\n",
    "    except (OSError, socket.timeout):\n",
    "        print(f\"DEBUG: Port {port} is free\")  # Debug\n",
    "        return True           # connection failed ⇒ port is free\n",
    "\n",
    "\n",
    "def _find_port(preferred: int, start: int = 5200) -> int:\n",
    "    \"\"\"\n",
    "    Try to use preferred port, fall back to finding first available port.\n",
    "    \n",
    "    Args:\n",
    "        preferred: The preferred port number to try first\n",
    "        start: Where to start searching if preferred port is taken\n",
    "        \n",
    "    Returns:\n",
    "        An available port number\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Trying preferred port {preferred}\")  # Debug\n",
    "    if _port_free(\"127.0.0.1\", preferred):\n",
    "        return preferred\n",
    "    return _first_free_port(start)\n",
    "\n",
    "\n",
    "def _write_envfile(name: str, \n",
    "                   ports: Optional[dict[str, int]] = None) -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    Create a throw-away .env file for the current `invoke up` run.\n",
    "    \n",
    "    Docker-compose will use this to see the chosen host-ports. We include all\n",
    "    services we know about; anything unset falls back to .env.template defaults.\n",
    "    \"\"\"\n",
    "    env_lines = [f\"ENV_NAME={name}\"]\n",
    "    mapping = {\n",
    "        \"jupyter\": \"HOST_JUPYTER_PORT\",\n",
    "        \"tensorboard\": \"HOST_TENSORBOARD_PORT\",\n",
    "        \"explainer\": \"HOST_EXPLAINER_PORT\",\n",
    "        \"streamlit\": \"HOST_STREAMLIT_PORT\",\n",
    "        \"mlflow\": \"HOST_MLFLOW_PORT\",\n",
    "        \"app\": \"HOST_APP_PORT\",            # NFL Kicker App (production)\n",
    "        \"frontend_dev\": \"HOST_FRONTEND_DEV_PORT\",  # Frontend development server\n",
    "        \"backend_dev\": \"HOST_BACKEND_DEV_PORT\",    # Backend development server\n",
    "    }\n",
    "    for svc, var in mapping.items():\n",
    "        if ports and svc in ports:\n",
    "            env_lines.append(f\"{var}={ports[svc]}\")\n",
    "    env_lines.append(f\"# generated {_dt.datetime.now().isoformat()}\")\n",
    "    tmp = tempfile.NamedTemporaryFile(\n",
    "        \"w\", \n",
    "        delete=False, \n",
    "        prefix=\".env.\",\n",
    "        dir=BASE_ENV\n",
    "    )\n",
    "    tmp.write(\"\\n\".join(env_lines))\n",
    "    tmp.close()\n",
    "    _saved_env_files.append(tmp.name)\n",
    "    return pathlib.Path(tmp.name)\n",
    "\n",
    "\n",
    "# Register cleanup function\n",
    "def _cleanup_env_files() -> None:\n",
    "    \"\"\"Remove all temporary env files.\"\"\"\n",
    "    for path in _saved_env_files:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "\n",
    "atexit.register(_cleanup_env_files)\n",
    "\n",
    "\n",
    "def _load_env_file(env_file: pathlib.Path) -> dict[str, str]:\n",
    "    \"\"\"Load environment variables from a file.\"\"\"\n",
    "    env_vars = {}\n",
    "    if env_file.exists():\n",
    "        with open(env_file, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#') and '=' in line:\n",
    "                    key, value = line.split('=', 1)\n",
    "                    env_vars[key] = value\n",
    "    return env_vars\n",
    "\n",
    "\n",
    "def _compose(\n",
    "    c: Context,\n",
    "    cmd: str,\n",
    "    name: str,\n",
    "    rebuild: bool = False,\n",
    "    force_pty: bool = False,\n",
    "    ports: Optional[dict[str, int]] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Wrapper around `docker compose` that also sanity-checks host ports.\n",
    "    \"\"\"\n",
    "    # ---------- NEW pre-flight check --------------------------------------\n",
    "    if ports:\n",
    "        for svc, port in ports.items():\n",
    "            if port is None:\n",
    "                continue\n",
    "            if not _port_free(\"127.0.0.1\", int(port)):\n",
    "                print(f\"❌  Host port {port} already bound – \"\n",
    "                      f\"{svc} cannot start. Choose another port (invoke up \"\n",
    "                      f\"--{svc}-port XXXXX) or free it first.\")\n",
    "                sys.exit(1)\n",
    "\n",
    "    env = {**os.environ, \"ENV_NAME\": name, \"COMPOSE_PROJECT_NAME\": name}\n",
    "    \n",
    "    # Load from .env.runtime if it exists (for VS Code dev containers)\n",
    "    env_file = BASE_ENV / \".devcontainer\" / \".env.runtime\"\n",
    "    if env_file.exists():\n",
    "        runtime_env = _load_env_file(env_file)\n",
    "        env.update(runtime_env)\n",
    "        print(f\"🔧  Loaded runtime environment from {env_file}\")\n",
    "    \n",
    "    # Add port overrides if provided\n",
    "    if ports:\n",
    "        port_mapping = {\n",
    "            \"jupyter\": \"HOST_JUPYTER_PORT\",\n",
    "            \"tensorboard\": \"HOST_TENSORBOARD_PORT\", \n",
    "            \"explainer\": \"HOST_EXPLAINER_PORT\",\n",
    "            \"streamlit\": \"HOST_STREAMLIT_PORT\",\n",
    "            \"mlflow\": \"HOST_MLFLOW_PORT\",\n",
    "            \"app\": \"HOST_APP_PORT\",\n",
    "            \"frontend_dev\": \"HOST_FRONTEND_DEV_PORT\",\n",
    "            \"backend_dev\": \"HOST_BACKEND_DEV_PORT\",\n",
    "        }\n",
    "        for service, port in ports.items():\n",
    "            if service in port_mapping:\n",
    "                env[port_mapping[service]] = str(port)\n",
    "    \n",
    "    use_pty = force_pty or (os.name != \"nt\" and sys.stdin.isatty())\n",
    "\n",
    "    if not use_pty and not getattr(_compose, \"_warned\", False):\n",
    "        print(\"ℹ️  PTY not supported – running without TTY.\")\n",
    "        _compose._warned = True  # type: ignore[attr-defined]\n",
    "\n",
    "    if rebuild:\n",
    "        full_cmd = f\"docker compose -p {name} {cmd} --build\"\n",
    "    else:\n",
    "        full_cmd = f\"docker compose -p {name} {cmd}\"\n",
    "    c.run(full_cmd, env=env, pty=use_pty)\n",
    "\n",
    "\n",
    "@task(\n",
    "    help={\n",
    "        \"name\": \"Project/venv name (defaults to folder name)\",\n",
    "        \"use_pty\": \"Force PTY even on non-POSIX hosts\",\n",
    "        \"jupyter_port\": \"Jupyter Lab port (default: 8890)\",\n",
    "        \"tensorboard_port\": \"TensorBoard port (default: auto-assigned)\",\n",
    "        \"explainer_port\": \"Explainer Dashboard port (default: auto-assigned)\", \n",
    "        \"streamlit_port\": \"Streamlit port (default: auto-assigned)\",\n",
    "        \"mlflow_port\": \"MLflow UI port (default: 5001, auto-assigns if busy)\",\n",
    "        \"app_port\": \"NFL Kicker App port (default: 5000)\",\n",
    "        \"frontend_dev_port\": \"Frontend dev server port (default: 5173)\",\n",
    "        \"backend_dev_port\": \"Backend dev server port (default: 5002)\",\n",
    "    }\n",
    ")\n",
    "def up(\n",
    "    c,\n",
    "    name: Optional[str] = None,\n",
    "    rebuild: bool = False,\n",
    "    detach: bool = True,\n",
    "    use_pty: bool = False,\n",
    "    jupyter_port: Union[str, int, None] = None,\n",
    "    tensorboard_port: Union[str, int, None] = None,\n",
    "    explainer_port: Union[str, int, None] = None,\n",
    "    streamlit_port: Union[str, int, None] = None,\n",
    "    mlflow_port: Union[str, int, None] = None,\n",
    "    app_port: Union[str, int, None] = None,\n",
    "    frontend_dev_port: Union[str, int, None] = None,\n",
    "    backend_dev_port: Union[str, int, None] = None,\n",
    ") -> None:\n",
    "    \"\"\"Build (optionally --rebuild) & start the container with custom ports.\"\"\"\n",
    "    name = name or BASE_ENV.name\n",
    "\n",
    "    # ---------- Parse and validate all ports -----------------\n",
    "    try:\n",
    "        jupyter_port = _parse_port(jupyter_port)\n",
    "        tensorboard_port = _parse_port(tensorboard_port)\n",
    "        explainer_port = _parse_port(explainer_port)\n",
    "        streamlit_port = _parse_port(streamlit_port)\n",
    "        mlflow_port = _parse_port(mlflow_port)\n",
    "        app_port = _parse_port(app_port)\n",
    "        frontend_dev_port = _parse_port(frontend_dev_port)\n",
    "        backend_dev_port = _parse_port(backend_dev_port)\n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Port validation failed: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # ---------- build dynamic port map -----------------\n",
    "    ports = {}\n",
    "    if jupyter_port is not None:\n",
    "        ports[\"jupyter\"] = jupyter_port\n",
    "    if tensorboard_port is not None:\n",
    "        ports[\"tensorboard\"] = tensorboard_port\n",
    "    if explainer_port is not None:\n",
    "        ports[\"explainer\"] = explainer_port\n",
    "    if streamlit_port is not None:\n",
    "        ports[\"streamlit\"] = streamlit_port\n",
    "\n",
    "    # ---------- Explainer auto-assign (NEW) ------------\n",
    "    print(\"DEBUG: Starting explainer port assignment\")  # Debug\n",
    "    try:\n",
    "        # Try to use the explainer's version first\n",
    "        from src.mlops.explainer import _first_free_port  # type: ignore\n",
    "        print(\"DEBUG: Successfully imported _first_free_port from explainer\")  # Debug\n",
    "    except ModuleNotFoundError:\n",
    "        print(\"DEBUG: Failed to import _first_free_port, using local implementation\")  # Debug\n",
    "        # We'll use our local _first_free_port implementation\n",
    "        pass\n",
    "\n",
    "    if explainer_port is None:\n",
    "        print(\"DEBUG: No explainer port specified, finding one\")  # Debug\n",
    "        explainer_port = _find_port(8050, 5200)\n",
    "    elif not _port_free(\"127.0.0.1\", explainer_port):\n",
    "        print(f\"DEBUG: Specified explainer port {explainer_port} is in use\")  # Debug\n",
    "        sys.exit(1)\n",
    "    ports[\"explainer\"] = explainer_port\n",
    "    print(f\"🔌 Explainer host-port → {explainer_port}\")\n",
    "\n",
    "    # ----- MLflow auto-assign (default 5001) -----------\n",
    "    print(\"DEBUG: Starting MLflow port assignment\")  # Debug\n",
    "    if mlflow_port is None:\n",
    "        print(\"DEBUG: No MLflow port specified, finding one\")  # Debug\n",
    "        mlflow_port = _find_port(5001, 5200)  # Changed default to 5001\n",
    "    elif not _port_free(\"127.0.0.1\", mlflow_port):\n",
    "        print(f\"DEBUG: Specified MLflow port {mlflow_port} is in use\")  # Debug\n",
    "        sys.exit(1)\n",
    "    ports[\"mlflow\"] = mlflow_port\n",
    "    print(f\"🔌 MLflow host-port → {mlflow_port}\")\n",
    "\n",
    "    # ----- NFL Kicker App auto-assign (default 5000) ----\n",
    "    print(\"DEBUG: Starting NFL Kicker App port assignment\")  # Debug  \n",
    "    if app_port is None:\n",
    "        print(\"DEBUG: No app port specified, finding one\")  # Debug\n",
    "        app_port = _find_port(5000, 5200)  # Prefer port 5000 for the app\n",
    "    elif not _port_free(\"127.0.0.1\", app_port):\n",
    "        print(f\"DEBUG: Specified app port {app_port} is in use\")  # Debug\n",
    "        sys.exit(1)\n",
    "    ports[\"app\"] = app_port\n",
    "    print(f\"🔌 NFL Kicker App host-port → {app_port}\")\n",
    "\n",
    "    # ----- Frontend Dev Server auto-assign (default 5173) ----\n",
    "    print(\"DEBUG: Starting Frontend Dev Server port assignment\")  # Debug  \n",
    "    if frontend_dev_port is None:\n",
    "        print(\"DEBUG: No frontend dev port specified, finding one\")  # Debug\n",
    "        frontend_dev_port = _find_port(5173, 5200)  # Prefer port 5173 for frontend dev\n",
    "    elif not _port_free(\"127.0.0.1\", frontend_dev_port):\n",
    "        print(f\"DEBUG: Specified frontend dev port {frontend_dev_port} is in use\")  # Debug\n",
    "        sys.exit(1)\n",
    "    ports[\"frontend_dev\"] = frontend_dev_port\n",
    "    print(f\"🔌 Frontend Dev Server host-port → {frontend_dev_port}\")\n",
    "\n",
    "    # ----- Backend Dev Server auto-assign (default 5002) ----\n",
    "    print(\"DEBUG: Starting Backend Dev Server port assignment\")  # Debug  \n",
    "    if backend_dev_port is None:\n",
    "        print(\"DEBUG: No backend dev port specified, finding one\")  # Debug\n",
    "        backend_dev_port = _find_port(5002, 5200)  # Use 5002 to avoid conflict with app port 5000\n",
    "    elif not _port_free(\"127.0.0.1\", backend_dev_port):\n",
    "        print(f\"DEBUG: Specified backend dev port {backend_dev_port} is in use\")  # Debug\n",
    "        sys.exit(1)\n",
    "    ports[\"backend_dev\"] = backend_dev_port\n",
    "    print(f\"🔌 Backend Dev Server host-port → {backend_dev_port}\")\n",
    "\n",
    "    # Generate environment file\n",
    "    env_path = _write_envfile(name, ports)\n",
    "    compose_cmd = \"up -d\" if detach else \"up\"\n",
    "\n",
    "    _compose(\n",
    "        c,\n",
    "        f\"--env-file {env_path} {compose_cmd}\",\n",
    "        name,\n",
    "        rebuild=rebuild,\n",
    "        force_pty=use_pty,\n",
    "        ports=ports,\n",
    "    )\n",
    "\n",
    "\n",
    "@task(\n",
    "    help={\n",
    "        \"name\": \"Project/venv name (defaults to folder name)\",\n",
    "    }\n",
    ")\n",
    "def stop(c, name: Optional[str] = None) -> None:\n",
    "    \"\"\"Stop and remove dev container (keeps volumes).\"\"\"\n",
    "    name = name or BASE_ENV.name\n",
    "    cmd = f\"docker compose -p {name} down\"\n",
    "    try:\n",
    "        c.run(cmd)\n",
    "        print(f\"\\n🛑 Stopped and removed project '{name}'\")\n",
    "    except Exception:\n",
    "        print(f\"❌ No running containers found for project '{name}'\")\n",
    "\n",
    "\n",
    "@task\n",
    "def shell(c, name: str | None = None) -> None:\n",
    "    \"\"\"Open an interactive shell inside the running container.\"\"\"\n",
    "    name = name or BASE_ENV.name\n",
    "    cmd = f\"docker compose -p {name} ps -q datascience\"\n",
    "    cid = c.run(cmd, hide=True).stdout.strip()\n",
    "    c.run(f\"docker exec -it {cid} bash\", env={\"ENV_NAME\": name}, pty=False)\n",
    "\n",
    "\n",
    "@task\n",
    "def clean(c) -> None:\n",
    "    \"\"\"Prune stopped containers + dangling images.\"\"\"\n",
    "    c.run(\"docker system prune -f\")\n",
    "\n",
    "\n",
    "@task\n",
    "def ports(c, name: str | None = None) -> None:\n",
    "    \"\"\"Show current port mappings for the named project.\"\"\"\n",
    "    name = name or BASE_ENV.name\n",
    "    cmd = f\"docker compose -p {name} ps --format table\"\n",
    "    try:\n",
    "        c.run(cmd, hide=False)\n",
    "        print(f\"\\n📊 Port mappings for project '{name}':\")\n",
    "        print(\"=\" * 50)\n",
    "    except Exception:\n",
    "        print(f\"❌ No running containers found for project '{name}'\")\n",
    "        print(\"\\n💡 Usage examples:\")\n",
    "        print(\"  invoke up --name myproject --jupyter-port 8891\")\n",
    "        print(\"  invoke up --name myproject --jupyter-port 8892 \\\\\")\n",
    "        print(\"    --tensorboard-port 6009\")\n",
    "\n",
    "\n",
    "# --- utilities ---------------------------------------------------------------\n",
    "def _norm(path: str | pathlib.Path) -> str:\n",
    "    \"\"\"Return a lower-case, forward-slash, no-trailing-slash version of *path*.\"\"\"\n",
    "    p = str(path).replace(\"\\\\\", \"/\").rstrip(\"/\").lower()\n",
    "    return p\n",
    "\n",
    "def _docker_projects_from_this_repo() -> set[str]:\n",
    "    \"\"\"\n",
    "    Discover every Compose *project name* whose working_dir label ends with\n",
    "    the current repo path.\n",
    "\n",
    "    Works across Windows ↔ WSL ↔ macOS because we do suffix-match on a\n",
    "    normalised path.\n",
    "    \"\"\"\n",
    "    here_tail = _norm(pathlib.Path(__file__).parent.resolve())\n",
    "    cmd = (\n",
    "        \"docker container ls -a \"\n",
    "        \"--format '{{.Label \\\"com.docker.compose.project\\\"}} \"\n",
    "        \"{{.Label \\\"com.docker.compose.project.working_dir\\\"}}' \"\n",
    "        \"--filter label=com.docker.compose.project\"\n",
    "    )\n",
    "    projects: set[str] = set()\n",
    "    for line in os.popen(cmd).read().strip().splitlines():\n",
    "        try:\n",
    "            proj, wd = line.split(maxsplit=1)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if _norm(wd).endswith(here_tail):\n",
    "            projects.add(proj)\n",
    "    return projects\n",
    "\n",
    "# --- task --------------------------------------------------------------------\n",
    "@task(\n",
    "    help={\n",
    "        \"name\": \"Project name (defaults to folder). Ignored with --all.\",\n",
    "        \"all\":  \"Remove *all* projects launched from this repo.\",\n",
    "        \"rmi\":  \"Image-removal policy: all | local | none (default: local).\",\n",
    "    }\n",
    ")\n",
    "def down(c, name: str | None = None, all: bool = False, rmi: str = \"local\"):\n",
    "    \"\"\"\n",
    "    Stop containers **and** fully delete every artefact so next `invoke up`\n",
    "    starts from a clean slate.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    invoke down                  # nuke current-folder project\n",
    "    invoke down --name ml_project --rmi all   # wipe everything for ml_project\n",
    "    invoke down --all            # tear down every project from this repo\n",
    "    \"\"\"\n",
    "    if rmi not in {\"all\", \"local\", \"none\"}:\n",
    "        raise ValueError(\"--rmi must be all | local | none\")\n",
    "\n",
    "    targets = _docker_projects_from_this_repo() if all else {name or BASE_ENV.name}\n",
    "    flags = \"-v --remove-orphans\"\n",
    "    if rmi != \"none\":\n",
    "        flags += f\" --rmi {rmi}\"\n",
    "\n",
    "    for proj in targets:\n",
    "        try:\n",
    "            c.run(f\"docker compose -p {proj} down {flags}\")\n",
    "            print(f\"🗑️  Removed project '{proj}'\")\n",
    "        except Exception:\n",
    "            print(f\"⚠️  Nothing to remove for '{proj}'\")\n",
    "\n",
    "\n",
    "@task(\n",
    "    help={\n",
    "        \"yaml\": \"Path to dashboard.yaml file\",\n",
    "        \"port\": \"Port to serve on (default: 8150)\",\n",
    "        \"host\": \"Host to bind to (default: 0.0.0.0)\",\n",
    "    }\n",
    ")\n",
    "def dashboard(c, yaml: str, port: int = 8150, host: str = \"0.0.0.0\") -> None:\n",
    "    \"\"\"\n",
    "    Serve a saved ExplainerDashboard from a YAML configuration file.\n",
    "    \n",
    "    This task allows you to re-serve dashboards that were previously saved\n",
    "    with build_and_log_dashboard(save_yaml=True).\n",
    "    \n",
    "    Examples:\n",
    "        invoke dashboard --yaml dashboard.yaml\n",
    "        invoke dashboard --yaml dashboard.yaml --port 8200\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    from src.mlops.explainer import load_dashboard_yaml\n",
    "    \n",
    "    yaml_path = Path(yaml)\n",
    "    if not yaml_path.exists():\n",
    "        print(f\"❌ Dashboard YAML file not found: {yaml_path}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Check if port is available\n",
    "    if not _port_free(host, port):\n",
    "        print(f\"❌ Port {port} is already in use on {host}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    try:\n",
    "        print(f\"🔄 Loading dashboard from {yaml_path}\")\n",
    "        dashboard_obj = load_dashboard_yaml(yaml_path)\n",
    "        \n",
    "        print(f\"🌐 Serving ExplainerDashboard on {host}:{port}\")\n",
    "        dashboard_obj.run(port=port, host=host, use_waitress=True, open_browser=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load or serve dashboard: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "@task\n",
    "def railway(c, cmd=\"--help\", name=None):\n",
    "    \"\"\"\n",
    "    Run Railway CLI commands inside the dev container.\n",
    "    \n",
    "    Examples:\n",
    "        invoke railway \"login --browserless\"\n",
    "        invoke railway \"link\"\n",
    "        invoke railway \"variables pull --env production --force\"\n",
    "        invoke railway \"run 'npm start'\"\n",
    "        invoke railway \"dev\"\n",
    "        invoke railway \"logs -f\"\n",
    "        invoke railway \"--version\" --name my_project\n",
    "    \"\"\"\n",
    "    project_name = name or BASE_ENV.name\n",
    "    container_id = c.run(f\"docker compose -p {project_name} ps -q datascience\", hide=True).stdout.strip()\n",
    "    \n",
    "    if not container_id:\n",
    "        print(f\"❌ No running container found for project '{project_name}'\")\n",
    "        print(\"💡 Run 'invoke up --name {project_name}' first to start the dev container\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    c.run(f\"docker exec {container_id} railway {cmd}\", pty=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/diagnose_devcontainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tests/diagnose_devcontainer.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Comprehensive diagnostic script for dev container issues.\n",
    "Run this inside the container to diagnose Python environment and remote extension problems.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def run_command(cmd, description):\n",
    "    \"\"\"Run a command and return its output.\"\"\"\n",
    "    print(f\"\\n🔍 {description}\")\n",
    "    print(\"=\" * 60)\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"✅ {result.stdout.strip()}\")\n",
    "        else:\n",
    "            print(f\"❌ Error (code {result.returncode}): {result.stderr.strip()}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_paths_and_environment():\n",
    "    \"\"\"Check Python paths and environment variables.\"\"\"\n",
    "    print(\"\\n🐍 PYTHON ENVIRONMENT DIAGNOSTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Python executable and version\n",
    "    print(f\"Python executable: {sys.executable}\")\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    print(f\"Python path: {sys.path[:3]}...\")  # First few paths\n",
    "    \n",
    "    # Environment variables\n",
    "    print(f\"\\nVIRTUAL_ENV: {os.environ.get('VIRTUAL_ENV', 'Not set')}\")\n",
    "    print(f\"PATH (first 3): {':'.join(os.environ.get('PATH', '').split(':')[:3])}\")\n",
    "    \n",
    "    # Virtual environment validation\n",
    "    venv_path = Path('/app/.venv')\n",
    "    if venv_path.exists():\n",
    "        print(f\"✅ Virtual environment exists at {venv_path}\")\n",
    "        print(f\"   - bin directory: {list(venv_path.glob('bin/python*'))}\")\n",
    "        print(f\"   - site-packages: {(venv_path / 'lib/python3.10/site-packages').exists()}\")\n",
    "    else:\n",
    "        print(f\"❌ Virtual environment NOT found at {venv_path}\")\n",
    "\n",
    "\n",
    "def check_key_packages():\n",
    "    \"\"\"Check if key packages are importable.\"\"\"\n",
    "    print(\"\\n📦 PACKAGE IMPORT TESTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    packages = [\n",
    "        'jax', 'torch', 'numpy', 'pandas', 'matplotlib', \n",
    "        'jupyterlab', 'streamlit', 'sklearn'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            if package == 'sklearn':\n",
    "                import sklearn\n",
    "                version = sklearn.__version__\n",
    "            else:\n",
    "                module = __import__(package)\n",
    "                version = getattr(module, '__version__', 'unknown')\n",
    "            print(f\"✅ {package}: {version}\")\n",
    "        except ImportError as e:\n",
    "            print(f\"❌ {package}: Import failed - {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  {package}: {e}\")\n",
    "\n",
    "\n",
    "def check_gpu_environment():\n",
    "    \"\"\"Check GPU-related environment variables.\"\"\"\n",
    "    print(\"\\n🎮 GPU ENVIRONMENT VARIABLES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    gpu_env_vars = [\n",
    "        'XLA_PYTHON_CLIENT_PREALLOCATE',\n",
    "        'XLA_PYTHON_CLIENT_ALLOCATOR', \n",
    "        'XLA_PYTHON_CLIENT_MEM_FRACTION',\n",
    "        'JAX_PLATFORM_NAME',\n",
    "        'XLA_FLAGS',\n",
    "        'JAX_DISABLE_JIT',\n",
    "        'JAX_ENABLE_X64',\n",
    "        'JAX_PREALLOCATION_SIZE_LIMIT_BYTES',\n",
    "        'TF_FORCE_GPU_ALLOW_GROWTH',\n",
    "        'NVIDIA_VISIBLE_DEVICES',\n",
    "        'NVIDIA_DRIVER_CAPABILITIES'\n",
    "    ]\n",
    "    \n",
    "    for var in gpu_env_vars:\n",
    "        value = os.environ.get(var, 'Not set')\n",
    "        print(f\"   {var}: {value}\")\n",
    "\n",
    "\n",
    "def check_gpu_support():\n",
    "    \"\"\"Check GPU support for JAX and PyTorch with enhanced diagnostics.\"\"\"\n",
    "    print(\"\\n🎮 ENHANCED GPU SUPPORT CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # JAX GPU check with detailed info\n",
    "    try:\n",
    "        import jax\n",
    "        print(f\"JAX version: {jax.__version__}\")\n",
    "        \n",
    "        devices = jax.devices()\n",
    "        print(f\"JAX devices: {devices}\")\n",
    "        \n",
    "        if devices:\n",
    "            for i, device in enumerate(devices):\n",
    "                print(f\"   Device {i}: {device}\")\n",
    "                \n",
    "        if any('gpu' in str(device).lower() or 'cuda' in str(device).lower() for device in devices):\n",
    "            print(\"✅ JAX GPU/CUDA support detected!\")\n",
    "            \n",
    "            # Test a simple computation\n",
    "            try:\n",
    "                import jax.numpy as jnp\n",
    "                x = jnp.ones((1000, 1000))\n",
    "                result = jnp.sum(x)\n",
    "                print(f\"   ✅ JAX GPU computation test passed: sum = {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️  JAX GPU computation test failed: {e}\")\n",
    "        else:\n",
    "            print(\"⚠️  JAX GPU support not detected\")\n",
    "            print(\"   This might be due to GPU architecture compatibility\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ JAX GPU check failed: {e}\")\n",
    "    \n",
    "    # PyTorch GPU check with enhanced info\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "        print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            device_count = torch.cuda.device_count()\n",
    "            print(f\"✅ PyTorch CUDA device count: {device_count}\")\n",
    "            \n",
    "            for i in range(device_count):\n",
    "                try:\n",
    "                    device_name = torch.cuda.get_device_name(i)\n",
    "                    memory_total = torch.cuda.get_device_properties(i).total_memory\n",
    "                    print(f\"   Device {i}: {device_name}\")\n",
    "                    print(f\"     Total memory: {memory_total / (1024**3):.1f} GB\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   Device {i}: Error getting info - {e}\")\n",
    "            \n",
    "            # Test a simple computation\n",
    "            try:\n",
    "                device = torch.device('cuda:0')\n",
    "                x = torch.ones(1000, 1000, device=device)\n",
    "                result = torch.sum(x)\n",
    "                print(f\"   ✅ PyTorch GPU computation test passed: sum = {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️  PyTorch GPU computation test failed: {e}\")\n",
    "        else:\n",
    "            print(\"⚠️  PyTorch CUDA not available\")\n",
    "            print(\"   Check CUDA installation and GPU compatibility\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ PyTorch GPU check failed: {e}\")\n",
    "\n",
    "\n",
    "def check_workspace_mount():\n",
    "    \"\"\"Check if workspace is properly mounted.\"\"\"\n",
    "    print(\"\\n📁 WORKSPACE MOUNT CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    workspace_path = Path('/workspace')\n",
    "    if workspace_path.exists():\n",
    "        print(f\"✅ /workspace directory exists\")\n",
    "        try:\n",
    "            contents = list(workspace_path.iterdir())[:10]  # First 10 items\n",
    "            print(f\"   Contents (first 10): {[p.name for p in contents]}\")\n",
    "            \n",
    "            # Check for specific expected files\n",
    "            expected_files = ['.devcontainer', 'pyproject.toml', 'docker-compose.yml']\n",
    "            for file in expected_files:\n",
    "                if (workspace_path / file).exists():\n",
    "                    print(f\"   ✅ Found: {file}\")\n",
    "                else:\n",
    "                    print(f\"   ❌ Missing: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error reading workspace: {e}\")\n",
    "    else:\n",
    "        print(f\"❌ /workspace directory does not exist\")\n",
    "\n",
    "\n",
    "def check_dev_container_config():\n",
    "    \"\"\"Check dev container configuration.\"\"\"\n",
    "    print(\"\\n⚙️  DEV CONTAINER CONFIG CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    config_path = Path('/workspace/.devcontainer/devcontainer.json')\n",
    "    if config_path.exists():\n",
    "        print(\"✅ devcontainer.json found\")\n",
    "        try:\n",
    "            with open(config_path) as f:\n",
    "                config = json.load(f)\n",
    "            print(f\"   Name: {config.get('name', 'Not specified')}\")\n",
    "            print(f\"   Python path: {config.get('customizations', {}).get('vscode', {}).get('settings', {}).get('python.defaultInterpreterPath', 'Not specified')}\")\n",
    "            print(f\"   Workspace folder: {config.get('workspaceFolder', 'Not specified')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error reading config: {e}\")\n",
    "    else:\n",
    "        print(\"❌ devcontainer.json not found\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run all diagnostic checks.\"\"\"\n",
    "    print(\"🔍 DEV CONTAINER COMPREHENSIVE DIAGNOSTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Running from: {os.getcwd()}\")\n",
    "    print(f\"User: {os.getenv('USER', 'unknown')}\")\n",
    "    print(f\"Container hostname: {os.getenv('HOSTNAME', 'unknown')}\")\n",
    "    \n",
    "    # System commands\n",
    "    run_command(\"uv --version\", \"UV Version\")\n",
    "    run_command(\"which python\", \"Python Location\")\n",
    "    run_command(\"ls -la /app/.venv/\", \"Virtual Environment Contents\")\n",
    "    run_command(\"mount | grep workspace\", \"Workspace Mount Status\")\n",
    "    run_command(\"nvidia-smi\", \"NVIDIA GPU Status\")\n",
    "    \n",
    "    # Python-based checks\n",
    "    check_paths_and_environment()\n",
    "    check_gpu_environment()\n",
    "    check_key_packages()\n",
    "    check_gpu_support()\n",
    "    check_workspace_mount()\n",
    "    check_dev_container_config()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"🎯 SUMMARY & RECOMMENDATIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"If you see issues:\")\n",
    "    print(\"1. ❌ Virtual env missing → Check Dockerfile uv sync step\")\n",
    "    print(\"2. ❌ Workspace not mounted → Check devcontainer.json mounts config\")\n",
    "    print(\"3. ❌ Packages missing → Check uv.lock and pip install steps\")\n",
    "    print(\"4. ⚠️  GPU not detected → Check docker-compose.yml gpu settings\")\n",
    "    print(\"5. 🔧 For VS Code issues → Check python.defaultInterpreterPath setting\")\n",
    "    print(\"6. 🎮 For GPU issues → Check NVIDIA drivers and CUDA compatibility\")\n",
    "    print(\"\\n✅ All checks passed = ready for development!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tests/test_pytorch_jax_gpu.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tests/test_pytorch_jax_gpu.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Test script to verify that PyTorch and JAX can access the GPU,\n",
    "and that PyJAGS is working correctly.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "def test_pytorch_gpu():\n",
    "    \"\"\"Test PyTorch GPU availability and basic operations.\"\"\"\n",
    "    print(\"\\n=== Testing PyTorch GPU ===\")\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        \n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"❌ PyTorch CUDA not available!\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "        \n",
    "        # Run a simple test computation\n",
    "        x = torch.rand(1000, 1000).cuda()\n",
    "        y = torch.rand(1000, 1000).cuda()\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "        start.record()\n",
    "        z = torch.matmul(x, y)\n",
    "        end.record()\n",
    "        \n",
    "        # Wait for GPU computation to finish\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Matrix multiplication time: {start.elapsed_time(end):.2f} ms\")\n",
    "        print(f\"Result shape: {z.shape}\")\n",
    "        print(\"✅ PyTorch GPU test passed!\")\n",
    "        return True\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"❌ PyTorch not found!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during PyTorch GPU test: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_jax_gpu():\n",
    "    \"\"\"Test JAX GPU availability and basic operations.\"\"\"\n",
    "    print(\"\\n=== Testing JAX GPU ===\")\n",
    "    try:\n",
    "        import jax\n",
    "        import jax.numpy as jnp\n",
    "        \n",
    "        print(f\"JAX version: {jax.__version__}\")\n",
    "        \n",
    "        # Force GPU platform\n",
    "        jax.config.update('jax_platform_name', 'gpu')\n",
    "        \n",
    "        # Get device count and details\n",
    "        devices = jax.devices()\n",
    "        device_count = len(devices)\n",
    "        print(f\"Available devices: {device_count}\")\n",
    "        \n",
    "        for i, device in enumerate(devices):\n",
    "            print(f\"Device {i}: {device}\")\n",
    "        \n",
    "        if device_count == 0 or 'cuda' not in str(devices[0]).lower():\n",
    "            print(\"❌ No GPU devices found by JAX!\")\n",
    "            return False\n",
    "        \n",
    "        # Check CUDA configuration\n",
    "        jit_info = jax.config.values\n",
    "        print(f\"JAX configuration: {jit_info}\")\n",
    "        \n",
    "        # Run a simple GPU computation\n",
    "        print(\"Running a test computation on GPU...\")\n",
    "        try:\n",
    "            x = jnp.ones((1000, 1000))\n",
    "            y = jnp.ones((1000, 1000))\n",
    "            \n",
    "            # Use JIT compilation for better performance\n",
    "            @jax.jit\n",
    "            def matmul(a, b):\n",
    "                return jnp.matmul(a, b)\n",
    "            \n",
    "            result = matmul(x, y)\n",
    "            print(f\"Result shape: {result.shape}\")\n",
    "            \n",
    "            print(\"✅ JAX GPU test passed!\")\n",
    "            return True\n",
    "        except RuntimeError as e:\n",
    "            if \"ptxas too old\" in str(e):\n",
    "                print(f\"⚠️ JAX GPU detected but CUDA compatibility issue: {e}\")\n",
    "                print(\"⚠️ JAX can see the GPU but there's a CUDA version compatibility issue.\")\n",
    "                print(\"⚠️ This is considered a partial success since the GPU is detected.\")\n",
    "                return True\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"❌ JAX not found!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during JAX GPU test: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_pyjags():\n",
    "    \"\"\"Test PyJAGS installation and basic functionality.\"\"\"\n",
    "    print(\"\\n=== Testing PyJAGS ===\")\n",
    "    try:\n",
    "        import pyjags\n",
    "        print(f\"PyJAGS version: {pyjags.__version__}\")\n",
    "        \n",
    "        # Create a simple model to verify that PyJAGS works\n",
    "        code = \"\"\"\n",
    "        model {\n",
    "            # Likelihood\n",
    "            y ~ dnorm(mu, 1/sigma^2)\n",
    "            \n",
    "            # Priors\n",
    "            mu ~ dnorm(0, 0.001)\n",
    "            sigma ~ dunif(0, 100)\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sample data\n",
    "        data = {'y': 0.5}\n",
    "        \n",
    "        # Initialize model with data\n",
    "        model = pyjags.Model(code, data=data, chains=1, adapt=100)\n",
    "        print(\"JAGS model initialized successfully!\")\n",
    "        \n",
    "        # Sample from the model\n",
    "        samples = model.sample(200, vars=['mu', 'sigma'])\n",
    "        print(\"JAGS sampling completed successfully!\")\n",
    "        \n",
    "        # Verify the samples\n",
    "        mu_samples = samples['mu']\n",
    "        sigma_samples = samples['sigma']\n",
    "        print(f\"mu mean: {mu_samples.mean():.4f}\")\n",
    "        print(f\"sigma mean: {sigma_samples.mean():.4f}\")\n",
    "        \n",
    "        print(\"✅ PyJAGS test passed!\")\n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"❌ PyJAGS not found!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during PyJAGS test: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running GPU and PyJAGS verification tests...\")\n",
    "    \n",
    "    pytorch_success = test_pytorch_gpu()\n",
    "    jax_success = test_jax_gpu()\n",
    "    pyjags_success = test_pyjags()\n",
    "    \n",
    "    print(\"\\n=== Test Summary ===\")\n",
    "    print(f\"PyTorch GPU: {'✅ PASS' if pytorch_success else '❌ FAIL'}\")\n",
    "    print(f\"JAX GPU: {'✅ PASS' if jax_success else '❌ FAIL'}\")\n",
    "    print(f\"PyJAGS: {'✅ PASS' if pyjags_success else '❌ FAIL'}\")\n",
    "    \n",
    "    if pytorch_success and jax_success and pyjags_success:\n",
    "        print(\"\\n🎉 All tests passed! The container is working correctly.\")\n",
    "        sys.exit(0)\n",
    "    else:\n",
    "        print(\"\\n❌ Some tests failed. Please check the output for details.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%writefile scripts/dev-frontend.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# Development script to run the React frontend\n",
    "set -e\n",
    "\n",
    "echo \"🚀 Starting NFL Kicker Assessment Development Servers\"\n",
    "echo \"==================================================\"\n",
    "\n",
    "# Change to the workspace directory\n",
    "cd /workspace\n",
    "\n",
    "# Check if we're in the container\n",
    "if [ ! -d \"/workspace/frontend\" ] || [ ! -d \"/workspace/backend\" ]; then\n",
    "    echo \"❌ Error: frontend/ and backend/ directories not found\"\n",
    "    echo \"   Make sure you're running this from within the dev container\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Function to cleanup background processes\n",
    "cleanup() {\n",
    "    echo \"🛑 Shutting down development servers...\"\n",
    "    kill $(jobs -p) 2>/dev/null || true\n",
    "    exit 0\n",
    "}\n",
    "trap cleanup SIGINT SIGTERM\n",
    "\n",
    "# Install frontend dependencies if needed\n",
    "echo \"📦 Checking frontend dependencies...\"\n",
    "cd /workspace/frontend\n",
    "if [ ! -d \"node_modules\" ]; then\n",
    "    echo \"   Installing frontend dependencies...\"\n",
    "    npm install\n",
    "fi\n",
    "\n",
    "# Install backend dependencies if needed\n",
    "echo \"📦 Checking backend dependencies...\"\n",
    "cd /workspace/backend\n",
    "if [ ! -d \"node_modules\" ]; then\n",
    "    echo \"   Installing backend dependencies...\"\n",
    "    npm install\n",
    "fi\n",
    "\n",
    "# Start backend development server\n",
    "echo \"🔧 Starting backend development server on port 5000...\"\n",
    "cd /workspace/backend\n",
    "npm run dev &\n",
    "BACKEND_PID=$!\n",
    "\n",
    "# Wait a moment for backend to start\n",
    "sleep 3\n",
    "\n",
    "# Start frontend development server\n",
    "echo \"🎨 Starting frontend development server on port 5173...\"\n",
    "cd /workspace/frontend\n",
    "npm run dev &\n",
    "FRONTEND_PID=$!\n",
    "\n",
    "echo \"\"\n",
    "echo \"✅ Development servers started!\"\n",
    "echo \"📊 Frontend: http://localhost:5173\"\n",
    "echo \"🔧 Backend API: http://localhost:5002 (proxied from frontend)\"\n",
    "echo \"🏥 Health check: http://localhost:5002/api/ping\"\n",
    "echo \"\"\n",
    "echo \"Press Ctrl+C to stop both servers\"\n",
    "\n",
    "# Wait for both processes\n",
    "wait $BACKEND_PID $FRONTEND_PID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "# Multi-stage Dockerfile for React + Express deployment\n",
    "# Stage 1: Build the React frontend\n",
    "FROM node:18-alpine AS client-build\n",
    "WORKDIR /client\n",
    "COPY frontend/package*.json ./\n",
    "RUN npm ci\n",
    "COPY frontend/. .\n",
    "RUN npm run build                   # output will be /client/dist\n",
    "\n",
    "# Stage 2: Setup Express backend and serve static files\n",
    "FROM node:18-alpine\n",
    "\n",
    "# Create non-root user for security\n",
    "RUN addgroup -g 1001 -S nodejs && \\\n",
    "    adduser -S nextjs -u 1001\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy backend package files and install (prod only)\n",
    "COPY backend/package*.json ./\n",
    "RUN npm ci --omit=dev\n",
    "\n",
    "# Copy backend source code\n",
    "COPY backend/. .\n",
    "\n",
    "# Copy frontend build artifacts into backend's public/ folder\n",
    "COPY --from=client-build /client/dist ./public\n",
    "\n",
    "# Set proper ownership for non-root user\n",
    "RUN chown -R nextjs:nodejs /app\n",
    "USER nextjs\n",
    "\n",
    "# Set environment and port - Railway injects PORT at runtime\n",
    "ENV NODE_ENV=production\n",
    "ENV PORT=${PORT:-5000}\n",
    "EXPOSE $PORT\n",
    "\n",
    "# Add health check for Railway deployment health monitoring\n",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n",
    "  CMD node -e \"require('http').get('http://localhost:' + process.env.PORT + '/api/ping', (res) => { process.exit(res.statusCode === 200 ? 0 : 1) }).on('error', () => process.exit(1))\"\n",
    "\n",
    "# Launch the Express server (which serves static files from /app/public)\n",
    "CMD [\"node\", \"server.js\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting backend/server.js\n"
     ]
    }
   ],
   "source": [
    "%%writefile backend/server.js\n",
    "import express from 'express';\n",
    "import cors from 'cors';\n",
    "import multer from 'multer';\n",
    "import csv from 'csv-parser';\n",
    "import fs from 'fs';\n",
    "import path from 'path';\n",
    "import { fileURLToPath } from 'url';\n",
    "\n",
    "const __filename = fileURLToPath(import.meta.url);\n",
    "const __dirname = path.dirname(__filename);\n",
    "\n",
    "const app = express();\n",
    "\n",
    "// Middleware\n",
    "app.use(cors({\n",
    "  origin: process.env.CORS_ORIGIN \n",
    "    ? process.env.CORS_ORIGIN.split(',').map(origin => origin.trim())\n",
    "    : process.env.NODE_ENV === 'production' \n",
    "      ? ['https://your-railway-domain.com'] // Will be replaced with actual Railway domain\n",
    "      : ['http://localhost:5173', 'http://localhost:3000'],\n",
    "  credentials: true\n",
    "}));\n",
    "\n",
    "app.use(express.json());\n",
    "app.use(express.urlencoded({ extended: true }));\n",
    "\n",
    "// In production, serve static files from the public directory\n",
    "if (process.env.NODE_ENV === 'production') {\n",
    "  const publicPath = path.join(__dirname, 'public');\n",
    "  app.use(express.static(publicPath));\n",
    "  \n",
    "  // Serve index.html for any non-API routes (SPA fallback)\n",
    "  app.get('*', (req, res, next) => {\n",
    "    if (req.path.startsWith('/api/')) {\n",
    "      return next();\n",
    "    }\n",
    "    res.sendFile(path.join(publicPath, 'index.html'));\n",
    "  });\n",
    "}\n",
    "\n",
    "// Configure multer for file uploads\n",
    "const storage = multer.diskStorage({\n",
    "  destination: (req, file, cb) => {\n",
    "    const uploadDir = 'uploads/';\n",
    "    // Ensure uploads directory exists (Railway volume mount point)\n",
    "    if (!fs.existsSync(uploadDir)) {\n",
    "      fs.mkdirSync(uploadDir, { recursive: true });\n",
    "    }\n",
    "    cb(null, uploadDir);\n",
    "  },\n",
    "  filename: (req, file, cb) => {\n",
    "    // Add timestamp to prevent filename conflicts\n",
    "    const timestamp = Date.now();\n",
    "    const originalName = file.originalname;\n",
    "    cb(null, `${timestamp}-${originalName}`);\n",
    "  }\n",
    "});\n",
    "\n",
    "const upload = multer({ \n",
    "  storage,\n",
    "  limits: {\n",
    "    fileSize: 10 * 1024 * 1024, // 10MB limit\n",
    "    files: 1\n",
    "  },\n",
    "  fileFilter: (req, file, cb) => {\n",
    "    // Only allow CSV files\n",
    "    if (file.mimetype === 'text/csv' || file.originalname.endsWith('.csv')) {\n",
    "      cb(null, true);\n",
    "    } else {\n",
    "      cb(new Error('Only CSV files are allowed'), false);\n",
    "    }\n",
    "  }\n",
    "});\n",
    "\n",
    "// API Routes\n",
    "\n",
    "// Health check endpoint\n",
    "app.get('/api/ping', (req, res) => {\n",
    "  res.json({ \n",
    "    pong: true, \n",
    "    timestamp: new Date().toISOString(),\n",
    "    environment: process.env.NODE_ENV || 'development'\n",
    "  });\n",
    "});\n",
    "\n",
    "// CSV upload and processing endpoint\n",
    "app.post('/api/upload', upload.single('file'), (req, res) => {\n",
    "  if (!req.file) {\n",
    "    return res.status(400).json({ error: 'No file uploaded' });\n",
    "  }\n",
    "\n",
    "  const results = [];\n",
    "  const filePath = req.file.path;\n",
    "\n",
    "  console.log(`Processing uploaded file: ${req.file.originalname}`);\n",
    "\n",
    "  // Stream parse the CSV file\n",
    "  fs.createReadStream(filePath)\n",
    "    .pipe(csv())\n",
    "    .on('data', (data) => {\n",
    "      // Clean and validate data\n",
    "      const cleanData = {};\n",
    "      Object.keys(data).forEach(key => {\n",
    "        const cleanKey = key.trim();\n",
    "        const value = data[key]?.toString().trim();\n",
    "        \n",
    "        // Convert numeric fields\n",
    "        if (['player_id', 'distance', 'made', 'week', 'year'].includes(cleanKey)) {\n",
    "          cleanData[cleanKey] = isNaN(value) ? value : Number(value);\n",
    "        } else {\n",
    "          cleanData[cleanKey] = value;\n",
    "        }\n",
    "      });\n",
    "      \n",
    "      // Basic validation - ensure required fields are present\n",
    "      if (cleanData.player_id && cleanData.player_name && \n",
    "          cleanData.distance !== undefined && cleanData.made !== undefined) {\n",
    "        results.push(cleanData);\n",
    "      }\n",
    "    })\n",
    "    .on('end', () => {\n",
    "      // Clean up the uploaded file\n",
    "      fs.unlink(filePath, (err) => {\n",
    "        if (err) console.error('Error deleting uploaded file:', err);\n",
    "      });\n",
    "\n",
    "      console.log(`Processed ${results.length} records from ${req.file.originalname}`);\n",
    "      \n",
    "      res.json({ \n",
    "        success: true,\n",
    "        data: results,\n",
    "        rowCount: results.length,\n",
    "        filename: req.file.originalname\n",
    "      });\n",
    "    })\n",
    "    .on('error', (error) => {\n",
    "      console.error('Error processing CSV:', error);\n",
    "      \n",
    "      // Clean up the uploaded file on error\n",
    "      fs.unlink(filePath, (err) => {\n",
    "        if (err) console.error('Error deleting uploaded file:', err);\n",
    "      });\n",
    "      \n",
    "      res.status(500).json({ \n",
    "        error: 'Error processing CSV file',\n",
    "        details: error.message\n",
    "      });\n",
    "    });\n",
    "});\n",
    "\n",
    "// Get processed leaderboard data (if we want to store it server-side)\n",
    "app.get('/api/leaderboard', (req, res) => {\n",
    "  // This could be enhanced to return cached/processed leaderboard data\n",
    "  res.json({ \n",
    "    message: 'Leaderboard endpoint - not implemented yet',\n",
    "    timestamp: new Date().toISOString()\n",
    "  });\n",
    "});\n",
    "\n",
    "// Error handling middleware\n",
    "app.use((error, req, res, next) => {\n",
    "  console.error('Server error:', error);\n",
    "  \n",
    "  if (error instanceof multer.MulterError) {\n",
    "    if (error.code === 'LIMIT_FILE_SIZE') {\n",
    "      return res.status(400).json({ error: 'File too large (max 10MB)' });\n",
    "    }\n",
    "    if (error.code === 'LIMIT_UNEXPECTED_FILE') {\n",
    "      return res.status(400).json({ error: 'Too many files uploaded' });\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  res.status(500).json({ \n",
    "    error: 'Internal server error',\n",
    "    details: process.env.NODE_ENV === 'development' ? error.message : undefined\n",
    "  });\n",
    "});\n",
    "\n",
    "// 404 handler for API routes\n",
    "app.use('/api/*', (req, res) => {\n",
    "  res.status(404).json({ error: 'API endpoint not found' });\n",
    "});\n",
    "\n",
    "// Start server\n",
    "const PORT = process.env.PORT || 5000;\n",
    "const HOST = process.env.HOST || '0.0.0.0';\n",
    "\n",
    "app.listen(PORT, HOST, () => {\n",
    "  console.log(`🚀 NFL Kicker API server running on http://${HOST}:${PORT}`);\n",
    "  console.log(`📁 Environment: ${process.env.NODE_ENV || 'development'}`);\n",
    "  console.log(`🔧 CORS enabled for: ${process.env.CORS_ORIGIN || (process.env.NODE_ENV === 'production' ? 'production domains' : 'development (localhost:5173, localhost:3000)')}`);\n",
    "  console.log(`📊 Health check: http://${HOST}:${PORT}/api/ping`);\n",
    "  \n",
    "  // Railway deployment info\n",
    "  if (process.env.RAILWAY_ENVIRONMENT) {\n",
    "    console.log(`🚂 Railway Environment: ${process.env.RAILWAY_ENVIRONMENT}`);\n",
    "    console.log(`🌍 Railway Service: ${process.env.RAILWAY_SERVICE_NAME || 'Unknown'}`);\n",
    "  }\n",
    "});\n",
    "\n",
    "// Graceful shutdown\n",
    "process.on('SIGTERM', () => {\n",
    "  console.log('SIGTERM received, shutting down gracefully');\n",
    "  process.exit(0);\n",
    "});\n",
    "\n",
    "process.on('SIGINT', () => {\n",
    "  console.log('SIGINT received, shutting down gracefully');\n",
    "  process.exit(0);\n",
    "}); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting backend/package.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile backend/package.json\n",
    "{\n",
    "  \"name\": \"nfl-kicker-backend\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"description\": \"Express backend for NFL Kicker Assessment\",\n",
    "  \"main\": \"server.js\",\n",
    "  \"type\": \"module\",\n",
    "  \"scripts\": {\n",
    "    \"start\": \"node server.js\",\n",
    "    \"dev\": \"nodemon server.js\"\n",
    "  },\n",
    "  \"dependencies\": {\n",
    "    \"express\": \"^4.18.2\",\n",
    "    \"cors\": \"^2.8.5\",\n",
    "    \"multer\": \"^1.4.5-lts.1\",\n",
    "    \"csv-parser\": \"^3.0.0\"\n",
    "  },\n",
    "  \"devDependencies\": {\n",
    "    \"nodemon\": \"^3.0.2\"\n",
    "  },\n",
    "  \"keywords\": [\"nfl\", \"kicker\", \"assessment\", \"api\"],\n",
    "  \"author\": \"\",\n",
    "  \"license\": \"MIT\"\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frontend/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile frontend/index.html\n",
    "<!doctype html>\n",
    "<html lang=\"en\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <link rel=\"icon\" type=\"image/svg+xml\" href=\"/vite.svg\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>NFL Kicker Assessment</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div id=\"root\"></div>\n",
    "    <script type=\"module\" src=\"/src/main.jsx\"></script>\n",
    "  </body>\n",
    "</html> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frontend/postcss.config.js\n"
     ]
    }
   ],
   "source": [
    "%%writefile frontend/postcss.config.js\n",
    "export default {\n",
    "  plugins: {\n",
    "    tailwindcss: {},\n",
    "    autoprefixer: {},\n",
    "  },\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frontend/tailwind.config.js\n"
     ]
    }
   ],
   "source": [
    "%%writefile frontend/tailwind.config.js\n",
    "/** @type {import('tailwindcss').Config} */\n",
    "export default {\n",
    "  content: [\n",
    "    \"./index.html\",\n",
    "    \"./src/**/*.{js,ts,jsx,tsx}\",\n",
    "  ],\n",
    "  theme: {\n",
    "    extend: {},\n",
    "  },\n",
    "  plugins: [],\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frontend/vite.config.js\n"
     ]
    }
   ],
   "source": [
    "%%writefile frontend/vite.config.js\n",
    "import { defineConfig } from 'vite'\n",
    "import react from '@vitejs/plugin-react'\n",
    "\n",
    "// https://vitejs.dev/config/\n",
    "export default defineConfig({\n",
    "  plugins: [react()],\n",
    "  server: {\n",
    "    host: '0.0.0.0',\n",
    "    port: 5173,\n",
    "    proxy: {\n",
    "      '/api': {\n",
    "        target: 'http://localhost:5000',\n",
    "        changeOrigin: true,\n",
    "        secure: false,\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frontend/package.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile frontend/package.json\n",
    "{\n",
    "  \"name\": \"nfl-kicker-frontend\",\n",
    "  \"private\": true,\n",
    "  \"version\": \"0.0.0\",\n",
    "  \"type\": \"module\",\n",
    "  \"scripts\": {\n",
    "    \"dev\": \"vite\",\n",
    "    \"build\": \"vite build\",\n",
    "    \"start\": \"serve -s dist -l $PORT\",\n",
    "    \"lint\": \"eslint . --ext js,jsx --report-unused-disable-directives --max-warnings 0\",\n",
    "    \"preview\": \"vite preview\"\n",
    "  },\n",
    "  \"dependencies\": {\n",
    "    \"react\": \"^18.2.0\",\n",
    "    \"react-dom\": \"^18.2.0\",\n",
    "    \"recharts\": \"^2.12.7\",\n",
    "    \"lucide-react\": \"^0.436.0\"\n",
    "  },\n",
    "  \"devDependencies\": {\n",
    "    \"@types/react\": \"^18.2.43\",\n",
    "    \"@types/react-dom\": \"^18.2.17\",\n",
    "    \"@vitejs/plugin-react\": \"^4.2.1\",\n",
    "    \"autoprefixer\": \"^10.4.16\",\n",
    "    \"eslint\": \"^8.55.0\",\n",
    "    \"eslint-plugin-react\": \"^7.33.2\",\n",
    "    \"eslint-plugin-react-hooks\": \"^4.6.0\",\n",
    "    \"eslint-plugin-react-refresh\": \"^0.4.5\",\n",
    "    \"postcss\": \"^8.4.32\",\n",
    "    \"tailwindcss\": \"^3.3.6\",\n",
    "    \"vite\": \"^5.0.8\"\n",
    "  }\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frontend/src/index.css\n"
     ]
    }
   ],
   "source": [
    "%%writefile frontend/src/index.css\n",
    "@tailwind base;\n",
    "@tailwind components;\n",
    "@tailwind utilities; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frontend/src/main.jsx\n"
     ]
    }
   ],
   "source": [
    "%%writefile frontend/src/main.jsx\n",
    "import React from 'react'\n",
    "import ReactDOM from 'react-dom/client'\n",
    "import App from './App.jsx'\n",
    "import './index.css'\n",
    "\n",
    "ReactDOM.createRoot(document.getElementById('root')).render(\n",
    "  <React.StrictMode>\n",
    "    <App />\n",
    "  </React.StrictMode>,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frontend/src/App.jsx\n"
     ]
    }
   ],
   "source": [
    "%%writefile frontend/src/App.jsx\n",
    "\n",
    "import React, { useState, useEffect } from 'react';\n",
    "import { Upload, Download, BarChart3, Users, Target, TrendingUp, FileText, Calculator } from 'lucide-react';\n",
    "import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend, ScatterChart, Scatter, ResponsiveContainer, BarChart, Bar } from 'recharts';\n",
    "\n",
    "const NFLKickerAssessment = () => {\n",
    "  const [data, setData] = useState(null);\n",
    "  const [processedData, setProcessedData] = useState(null);\n",
    "  const [leaderboard, setLeaderboard] = useState([]);\n",
    "  const [activeTab, setActiveTab] = useState('upload');\n",
    "  const [loading, setLoading] = useState(false);\n",
    "  const [error, setError] = useState(null);\n",
    "  const [modelParams, setModelParams] = useState({\n",
    "    minAttempts: 10,\n",
    "    weightRecency: 0.3,\n",
    "    weightDistance: 0.4,\n",
    "    weightAccuracy: 0.3\n",
    "  });\n",
    "\n",
    "  const calculateKickerRating = (kickerData) => {\n",
    "    if (!kickerData || kickerData.length === 0) return 0;\n",
    "    \n",
    "    // Calculate basic statistics\n",
    "    const totalAttempts = kickerData.length;\n",
    "    const totalMakes = kickerData.filter(kick => kick.made === 1).length;\n",
    "    const accuracy = totalMakes / totalAttempts;\n",
    "    \n",
    "    // Distance-weighted accuracy\n",
    "    const distanceWeightedScore = kickerData.reduce((sum, kick) => {\n",
    "      const distanceWeight = Math.max(0, (kick.distance - 20) / 40); // Normalize distance\n",
    "      return sum + (kick.made * (1 + distanceWeight));\n",
    "    }, 0) / totalAttempts;\n",
    "    \n",
    "    // Recency weight (more recent kicks weighted higher)\n",
    "    const maxWeek = Math.max(...kickerData.map(k => k.week));\n",
    "    const recencyScore = kickerData.reduce((sum, kick) => {\n",
    "      const recencyWeight = kick.week / maxWeek;\n",
    "      return sum + (kick.made * recencyWeight);\n",
    "    }, 0) / totalAttempts;\n",
    "    \n",
    "    // Composite rating\n",
    "    const rating = (\n",
    "      modelParams.weightAccuracy * accuracy +\n",
    "      modelParams.weightDistance * distanceWeightedScore +\n",
    "      modelParams.weightRecency * recencyScore\n",
    "    ) * 100;\n",
    "    \n",
    "    return Math.round(rating * 100) / 100;\n",
    "  };\n",
    "\n",
    "  const processData = () => {\n",
    "    if (!data) return;\n",
    "    \n",
    "    setLoading(true);\n",
    "    try {\n",
    "      // Group by player\n",
    "      const playerGroups = {};\n",
    "      data.forEach(row => {\n",
    "        if (!playerGroups[row.player_id]) {\n",
    "          playerGroups[row.player_id] = {\n",
    "            player_id: row.player_id,\n",
    "            player_name: row.player_name,\n",
    "            attempts: []\n",
    "          };\n",
    "        }\n",
    "        playerGroups[row.player_id].attempts.push(row);\n",
    "      });\n",
    "      \n",
    "      // Calculate ratings and create leaderboard\n",
    "      const leaderboardData = Object.values(playerGroups)\n",
    "        .filter(player => player.attempts.length >= modelParams.minAttempts)\n",
    "        .map(player => ({\n",
    "          player_id: player.player_id,\n",
    "          player_name: player.player_name,\n",
    "          rating: calculateKickerRating(player.attempts),\n",
    "          attempts: player.attempts.length,\n",
    "          accuracy: player.attempts.filter(a => a.made === 1).length / player.attempts.length\n",
    "        }))\n",
    "        .sort((a, b) => b.rating - a.rating)\n",
    "        .map((player, index) => ({ ...player, rank: index + 1 }));\n",
    "      \n",
    "      setLeaderboard(leaderboardData);\n",
    "      setProcessedData(playerGroups);\n",
    "    } catch (err) {\n",
    "      setError('Error processing data: ' + err.message);\n",
    "    } finally {\n",
    "      setLoading(false);\n",
    "    }\n",
    "  };\n",
    "\n",
    "  const handleFileUpload = async (event) => {\n",
    "    const file = event.target.files[0];\n",
    "    if (!file) return;\n",
    "\n",
    "    if (file.type !== 'text/csv') {\n",
    "      setError('Please upload a CSV file');\n",
    "      return;\n",
    "    }\n",
    "\n",
    "    setLoading(true);\n",
    "    setError(null);\n",
    "\n",
    "    try {\n",
    "      // Try backend API first\n",
    "      const formData = new FormData();\n",
    "      formData.append('file', file);\n",
    "      \n",
    "      const response = await fetch('/api/upload', {\n",
    "        method: 'POST',\n",
    "        body: formData,\n",
    "      });\n",
    "\n",
    "      if (response.ok) {\n",
    "        const result = await response.json();\n",
    "        setData(result.data);\n",
    "      } else {\n",
    "        throw new Error('Backend API not available');\n",
    "      }\n",
    "      \n",
    "    } catch (err) {\n",
    "      // Fallback to client-side processing\n",
    "      console.log('Using client-side processing:', err.message);\n",
    "      \n",
    "      const reader = new FileReader();\n",
    "      reader.onload = (e) => {\n",
    "        try {\n",
    "          const text = e.target.result;\n",
    "          const rows = text.split('\\n').filter(row => row.trim());\n",
    "          const headers = rows[0].split(',').map(h => h.trim());\n",
    "          const parsedData = rows.slice(1).map(row => {\n",
    "            const values = row.split(',');\n",
    "            const obj = {};\n",
    "            headers.forEach((header, index) => {\n",
    "              const value = values[index]?.trim();\n",
    "              obj[header] = isNaN(value) ? value : Number(value);\n",
    "            });\n",
    "            return obj;\n",
    "          });\n",
    "          setData(parsedData);\n",
    "          setError(null);\n",
    "        } catch (parseErr) {\n",
    "          setError('Error parsing CSV file: ' + parseErr.message);\n",
    "        }\n",
    "      };\n",
    "      reader.readAsText(file);\n",
    "    } finally {\n",
    "      setLoading(false);\n",
    "    }\n",
    "  };\n",
    "\n",
    "  const downloadLeaderboard = () => {\n",
    "    const csv = [\n",
    "      'player_id,player_name,rating,rank',\n",
    "      ...leaderboard.map(row => `${row.player_id},${row.player_name},${row.rating},${row.rank}`)\n",
    "    ].join('\\n');\n",
    "    \n",
    "    const blob = new Blob([csv], { type: 'text/csv' });\n",
    "    const url = window.URL.createObjectURL(blob);\n",
    "    const a = document.createElement('a');\n",
    "    a.style.display = 'none';\n",
    "    a.href = url;\n",
    "    a.download = 'leaderboard.csv';\n",
    "    document.body.appendChild(a);\n",
    "    a.click();\n",
    "    window.URL.revokeObjectURL(url);\n",
    "  };\n",
    "\n",
    "  const generateReport = () => {\n",
    "    const report = `# NFL Kicker Rating Model - Technical Assessment\n",
    "\n",
    "## Model Overview\n",
    "This rating system evaluates NFL kickers based on:\n",
    "- **Accuracy**: Base field goal percentage\n",
    "- **Distance Performance**: Weighted by kick difficulty (distance)\n",
    "- **Recency**: More recent performance weighted higher\n",
    "\n",
    "## Model Parameters\n",
    "- Minimum Attempts: ${modelParams.minAttempts}\n",
    "- Accuracy Weight: ${modelParams.weightAccuracy}\n",
    "- Distance Weight: ${modelParams.weightDistance}\n",
    "- Recency Weight: ${modelParams.weightRecency}\n",
    "\n",
    "## Top 10 Kickers (Week 6, 2018)\n",
    "${leaderboard.slice(0, 10).map((k, i) => \n",
    "  `${i + 1}. ${k.player_name} - Rating: ${k.rating} (${k.attempts} attempts, ${(k.accuracy * 100).toFixed(1)}% accuracy)`\n",
    ").join('\\n')}\n",
    "\n",
    "## Model Interpretation\n",
    "- Rating Scale: 0-100 (higher is better)\n",
    "- Considers both volume and efficiency\n",
    "- Adjusts for kick difficulty and timing\n",
    "\n",
    "## Potential Improvements\n",
    "1. Incorporate situational factors (weather, pressure)\n",
    "2. Add opponent strength adjustments\n",
    "3. Include career trajectory analysis\n",
    "4. Implement Bayesian updating for new kickers\n",
    "\n",
    "## Next Steps\n",
    "1. Validate model with out-of-sample data\n",
    "2. Compare against Vegas odds or expert rankings\n",
    "3. Implement confidence intervals\n",
    "4. Add visualization for decision-makers\n",
    "    `;\n",
    "    \n",
    "    const blob = new Blob([report], { type: 'text/markdown' });\n",
    "    const url = window.URL.createObjectURL(blob);\n",
    "    const a = document.createElement('a');\n",
    "    a.style.display = 'none';\n",
    "    a.href = url;\n",
    "    a.download = 'kicker_analysis_report.md';\n",
    "    document.body.appendChild(a);\n",
    "    a.click();\n",
    "    window.URL.revokeObjectURL(url);\n",
    "  };\n",
    "\n",
    "  useEffect(() => {\n",
    "    if (data) {\n",
    "      processData();\n",
    "    }\n",
    "  }, [data, modelParams]);\n",
    "\n",
    "  const TabButton = ({ id, label, icon: Icon, active }) => (\n",
    "    <button\n",
    "      onClick={() => setActiveTab(id)}\n",
    "      className={`flex items-center px-4 py-2 rounded-lg transition-colors ${\n",
    "        active \n",
    "          ? 'bg-orange-600 text-white' \n",
    "          : 'bg-gray-100 text-gray-700 hover:bg-gray-200'\n",
    "      }`}\n",
    "    >\n",
    "      <Icon className=\"w-4 h-4 mr-2\" />\n",
    "      {label}\n",
    "    </button>\n",
    "  );\n",
    "\n",
    "  return (\n",
    "    <div className=\"min-h-screen bg-gradient-to-br from-orange-50 to-blue-50 p-6\">\n",
    "      <div className=\"max-w-7xl mx-auto\">\n",
    "        <div className=\"bg-white rounded-xl shadow-lg overflow-hidden\">\n",
    "          {/* Header */}\n",
    "          <div className=\"bg-gradient-to-r from-orange-600 to-blue-600 text-white p-6\">\n",
    "            <h1 className=\"text-3xl font-bold flex items-center\">\n",
    "              <Target className=\"w-8 h-8 mr-3\" />\n",
    "              NFL Kicker Assessment Framework\n",
    "            </h1>\n",
    "            <p className=\"text-orange-100 mt-2\">Denver Broncos Technical Assessment Tool</p>\n",
    "          </div>\n",
    "\n",
    "          {/* Navigation */}\n",
    "          <div className=\"border-b border-gray-200 p-4\">\n",
    "            <div className=\"flex flex-wrap gap-2\">\n",
    "              <TabButton id=\"upload\" label=\"Data Upload\" icon={Upload} active={activeTab === 'upload'} />\n",
    "              <TabButton id=\"model\" label=\"Model Config\" icon={Calculator} active={activeTab === 'model'} />\n",
    "              <TabButton id=\"leaderboard\" label=\"Leaderboard\" icon={Users} active={activeTab === 'leaderboard'} />\n",
    "              <TabButton id=\"analysis\" label=\"Analysis\" icon={BarChart3} active={activeTab === 'analysis'} />\n",
    "              <TabButton id=\"export\" label=\"Export\" icon={Download} active={activeTab === 'export'} />\n",
    "            </div>\n",
    "          </div>\n",
    "\n",
    "          {/* Content */}\n",
    "          <div className=\"p-6\">\n",
    "            {/* Error Display */}\n",
    "            {error && (\n",
    "              <div className=\"bg-red-50 border border-red-200 rounded-lg p-4 mb-6\">\n",
    "                <h4 className=\"font-semibold text-red-800\">Error</h4>\n",
    "                <p className=\"text-red-700\">{error}</p>\n",
    "              </div>\n",
    "            )}\n",
    "\n",
    "            {activeTab === 'upload' && (\n",
    "              <div className=\"space-y-6\">\n",
    "                <div className=\"border-2 border-dashed border-gray-300 rounded-lg p-8 text-center\">\n",
    "                  <Upload className=\"w-12 h-12 mx-auto text-gray-400 mb-4\" />\n",
    "                  <h3 className=\"text-lg font-semibold mb-2\">Upload NFL Field Goal Data</h3>\n",
    "                  <p className=\"text-gray-600 mb-4\">Upload the CSV file with field goal data</p>\n",
    "                  <input\n",
    "                    type=\"file\"\n",
    "                    accept=\".csv\"\n",
    "                    onChange={handleFileUpload}\n",
    "                    disabled={loading}\n",
    "                    className=\"block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-orange-50 file:text-orange-700 hover:file:bg-orange-100 disabled:opacity-50\"\n",
    "                  />\n",
    "                  {loading && (\n",
    "                    <div className=\"mt-4\">\n",
    "                      <div className=\"animate-spin rounded-full h-8 w-8 border-b-2 border-orange-600 mx-auto\"></div>\n",
    "                      <p className=\"text-gray-600 mt-2\">Processing file...</p>\n",
    "                    </div>\n",
    "                  )}\n",
    "                </div>\n",
    "                \n",
    "                {data && (\n",
    "                  <div className=\"bg-green-50 border border-green-200 rounded-lg p-4\">\n",
    "                    <h4 className=\"font-semibold text-green-800\">Data Loaded Successfully!</h4>\n",
    "                    <p className=\"text-green-700\">Loaded {data.length} field goal attempts</p>\n",
    "                    <div className=\"mt-2 text-sm\">\n",
    "                      <strong>Sample data structure:</strong>\n",
    "                      <pre className=\"bg-white p-2 rounded mt-1 text-xs overflow-x-auto\">\n",
    "                        {JSON.stringify(data[0], null, 2)}\n",
    "                      </pre>\n",
    "                    </div>\n",
    "                  </div>\n",
    "                )}\n",
    "              </div>\n",
    "            )}\n",
    "\n",
    "            {activeTab === 'model' && (\n",
    "              <div className=\"space-y-6\">\n",
    "                <h3 className=\"text-xl font-bold\">Model Configuration</h3>\n",
    "                \n",
    "                <div className=\"grid grid-cols-1 md:grid-cols-2 gap-6\">\n",
    "                  <div className=\"space-y-4\">\n",
    "                    <div>\n",
    "                      <label className=\"block text-sm font-medium mb-2\">Minimum Attempts</label>\n",
    "                      <input\n",
    "                        type=\"number\"\n",
    "                        value={modelParams.minAttempts}\n",
    "                        onChange={(e) => setModelParams({...modelParams, minAttempts: parseInt(e.target.value)})}\n",
    "                        className=\"w-full px-3 py-2 border rounded-lg focus:ring-2 focus:ring-orange-500 focus:border-transparent\"\n",
    "                      />\n",
    "                    </div>\n",
    "                    \n",
    "                    <div>\n",
    "                      <label className=\"block text-sm font-medium mb-2\">Accuracy Weight</label>\n",
    "                      <input\n",
    "                        type=\"range\"\n",
    "                        min=\"0\"\n",
    "                        max=\"1\"\n",
    "                        step=\"0.1\"\n",
    "                        value={modelParams.weightAccuracy}\n",
    "                        onChange={(e) => setModelParams({...modelParams, weightAccuracy: parseFloat(e.target.value)})}\n",
    "                        className=\"w-full\"\n",
    "                      />\n",
    "                      <span className=\"text-sm text-gray-600\">{modelParams.weightAccuracy}</span>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div>\n",
    "                      <label className=\"block text-sm font-medium mb-2\">Distance Weight</label>\n",
    "                      <input\n",
    "                        type=\"range\"\n",
    "                        min=\"0\"\n",
    "                        max=\"1\"\n",
    "                        step=\"0.1\"\n",
    "                        value={modelParams.weightDistance}\n",
    "                        onChange={(e) => setModelParams({...modelParams, weightDistance: parseFloat(e.target.value)})}\n",
    "                        className=\"w-full\"\n",
    "                      />\n",
    "                      <span className=\"text-sm text-gray-600\">{modelParams.weightDistance}</span>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div>\n",
    "                      <label className=\"block text-sm font-medium mb-2\">Recency Weight</label>\n",
    "                      <input\n",
    "                        type=\"range\"\n",
    "                        min=\"0\"\n",
    "                        max=\"1\"\n",
    "                        step=\"0.1\"\n",
    "                        value={modelParams.weightRecency}\n",
    "                        onChange={(e) => setModelParams({...modelParams, weightRecency: parseFloat(e.target.value)})}\n",
    "                        className=\"w-full\"\n",
    "                      />\n",
    "                      <span className=\"text-sm text-gray-600\">{modelParams.weightRecency}</span>\n",
    "                    </div>\n",
    "                  </div>\n",
    "                  \n",
    "                  <div className=\"bg-gray-50 p-4 rounded-lg\">\n",
    "                    <h4 className=\"font-semibold mb-3\">Model Explanation</h4>\n",
    "                    <div className=\"space-y-2 text-sm\">\n",
    "                      <p><strong>Accuracy:</strong> Base field goal percentage</p>\n",
    "                      <p><strong>Distance:</strong> Rewards longer successful kicks</p>\n",
    "                      <p><strong>Recency:</strong> Weights recent performance higher</p>\n",
    "                      <p className=\"text-gray-600 text-xs mt-3\">\n",
    "                        The final rating is a weighted combination of these factors, \n",
    "                        scaled to 0-100 where higher is better.\n",
    "                      </p>\n",
    "                    </div>\n",
    "                  </div>\n",
    "                </div>\n",
    "              </div>\n",
    "            )}\n",
    "\n",
    "            {activeTab === 'leaderboard' && (\n",
    "              <div className=\"space-y-6\">\n",
    "                <div className=\"flex justify-between items-center\">\n",
    "                  <h3 className=\"text-xl font-bold\">Kicker Leaderboard</h3>\n",
    "                  {leaderboard.length > 0 && (\n",
    "                    <button\n",
    "                      onClick={downloadLeaderboard}\n",
    "                      className=\"bg-orange-600 text-white px-4 py-2 rounded-lg hover:bg-orange-700 flex items-center transition-colors\"\n",
    "                    >\n",
    "                      <Download className=\"w-4 h-4 mr-2\" />\n",
    "                      Download CSV\n",
    "                    </button>\n",
    "                  )}\n",
    "                </div>\n",
    "                \n",
    "                {leaderboard.length > 0 ? (\n",
    "                  <div className=\"overflow-x-auto\">\n",
    "                    <table className=\"w-full border-collapse border border-gray-300\">\n",
    "                      <thead className=\"bg-gray-50\">\n",
    "                        <tr>\n",
    "                          <th className=\"border border-gray-300 px-4 py-2 text-left\">Rank</th>\n",
    "                          <th className=\"border border-gray-300 px-4 py-2 text-left\">Player Name</th>\n",
    "                          <th className=\"border border-gray-300 px-4 py-2 text-left\">Rating</th>\n",
    "                          <th className=\"border border-gray-300 px-4 py-2 text-left\">Attempts</th>\n",
    "                          <th className=\"border border-gray-300 px-4 py-2 text-left\">Accuracy</th>\n",
    "                        </tr>\n",
    "                      </thead>\n",
    "                      <tbody>\n",
    "                        {leaderboard.map(kicker => (\n",
    "                          <tr key={kicker.player_id} className=\"hover:bg-gray-50\">\n",
    "                            <td className=\"border border-gray-300 px-4 py-2\">{kicker.rank}</td>\n",
    "                            <td className=\"border border-gray-300 px-4 py-2 font-medium\">{kicker.player_name}</td>\n",
    "                            <td className=\"border border-gray-300 px-4 py-2\">{kicker.rating}</td>\n",
    "                            <td className=\"border border-gray-300 px-4 py-2\">{kicker.attempts}</td>\n",
    "                            <td className=\"border border-gray-300 px-4 py-2\">{(kicker.accuracy * 100).toFixed(1)}%</td>\n",
    "                          </tr>\n",
    "                        ))}\n",
    "                      </tbody>\n",
    "                    </table>\n",
    "                  </div>\n",
    "                ) : (\n",
    "                  <div className=\"text-center py-12 text-gray-500\">\n",
    "                    Upload data and configure the model to see the leaderboard\n",
    "                  </div>\n",
    "                )}\n",
    "              </div>\n",
    "            )}\n",
    "\n",
    "            {activeTab === 'analysis' && (\n",
    "              <div className=\"space-y-6\">\n",
    "                <h3 className=\"text-xl font-bold\">Data Analysis</h3>\n",
    "                \n",
    "                {leaderboard.length > 0 ? (\n",
    "                  <div className=\"grid grid-cols-1 lg:grid-cols-2 gap-6\">\n",
    "                    <div className=\"bg-white border rounded-lg p-4\">\n",
    "                      <h4 className=\"font-semibold mb-3\">Rating Distribution</h4>\n",
    "                      <ResponsiveContainer width=\"100%\" height={300}>\n",
    "                        <BarChart data={leaderboard.slice(0, 10)}>\n",
    "                          <CartesianGrid strokeDasharray=\"3 3\" />\n",
    "                          <XAxis \n",
    "                            dataKey=\"player_name\" \n",
    "                            angle={-45}\n",
    "                            textAnchor=\"end\"\n",
    "                            height={100}\n",
    "                          />\n",
    "                          <YAxis />\n",
    "                          <Tooltip />\n",
    "                          <Bar dataKey=\"rating\" fill=\"#ea580c\" />\n",
    "                        </BarChart>\n",
    "                      </ResponsiveContainer>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div className=\"bg-white border rounded-lg p-4\">\n",
    "                      <h4 className=\"font-semibold mb-3\">Rating vs Accuracy</h4>\n",
    "                      <ResponsiveContainer width=\"100%\" height={300}>\n",
    "                        <ScatterChart data={leaderboard}>\n",
    "                          <CartesianGrid strokeDasharray=\"3 3\" />\n",
    "                          <XAxis dataKey=\"accuracy\" domain={[0, 1]} />\n",
    "                          <YAxis dataKey=\"rating\" />\n",
    "                          <Tooltip \n",
    "                            formatter={(value, name) => [\n",
    "                              name === 'accuracy' ? `${(value * 100).toFixed(1)}%` : value,\n",
    "                              name === 'accuracy' ? 'Accuracy' : 'Rating'\n",
    "                            ]}\n",
    "                          />\n",
    "                          <Scatter dataKey=\"rating\" fill=\"#2563eb\" />\n",
    "                        </ScatterChart>\n",
    "                      </ResponsiveContainer>\n",
    "                    </div>\n",
    "                  </div>\n",
    "                ) : (\n",
    "                  <div className=\"text-center py-12 text-gray-500\">\n",
    "                    Upload data to see analysis charts\n",
    "                  </div>\n",
    "                )}\n",
    "              </div>\n",
    "            )}\n",
    "\n",
    "            {activeTab === 'export' && (\n",
    "              <div className=\"space-y-6\">\n",
    "                <h3 className=\"text-xl font-bold\">Export Deliverables</h3>\n",
    "                \n",
    "                <div className=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n",
    "                  <div className=\"bg-blue-50 border border-blue-200 rounded-lg p-6\">\n",
    "                    <FileText className=\"w-8 h-8 text-blue-600 mb-3\" />\n",
    "                    <h4 className=\"font-semibold mb-2\">Leaderboard CSV</h4>\n",
    "                    <p className=\"text-sm text-gray-600 mb-4\">Required format with player_id, player_name, rating, rank</p>\n",
    "                    <button\n",
    "                      onClick={downloadLeaderboard}\n",
    "                      disabled={leaderboard.length === 0}\n",
    "                      className=\"w-full bg-blue-600 text-white px-4 py-2 rounded hover:bg-blue-700 disabled:bg-gray-300 transition-colors\"\n",
    "                    >\n",
    "                      Download CSV\n",
    "                    </button>\n",
    "                  </div>\n",
    "                  \n",
    "                  <div className=\"bg-green-50 border border-green-200 rounded-lg p-6\">\n",
    "                    <TrendingUp className=\"w-8 h-8 text-green-600 mb-3\" />\n",
    "                    <h4 className=\"font-semibold mb-2\">Analysis Report</h4>\n",
    "                    <p className=\"text-sm text-gray-600 mb-4\">Model explanation and critique document</p>\n",
    "                    <button\n",
    "                      onClick={generateReport}\n",
    "                      disabled={leaderboard.length === 0}\n",
    "                      className=\"w-full bg-green-600 text-white px-4 py-2 rounded hover:bg-green-700 disabled:bg-gray-300 transition-colors\"\n",
    "                    >\n",
    "                      Generate Report\n",
    "                    </button>\n",
    "                  </div>\n",
    "                  \n",
    "                  <div className=\"bg-orange-50 border border-orange-200 rounded-lg p-6\">\n",
    "                    <Calculator className=\"w-8 h-8 text-orange-600 mb-3\" />\n",
    "                    <h4 className=\"font-semibold mb-2\">Python Script</h4>\n",
    "                    <p className=\"text-sm text-gray-600 mb-4\">Documented code for model implementation</p>\n",
    "                    <button\n",
    "                      onClick={() => alert('Generate Python script based on your model configuration')}\n",
    "                      className=\"w-full bg-orange-600 text-white px-4 py-2 rounded hover:bg-orange-700 transition-colors\"\n",
    "                    >\n",
    "                      View Script\n",
    "                    </button>\n",
    "                  </div>\n",
    "                </div>\n",
    "                \n",
    "                <div className=\"bg-gray-50 rounded-lg p-6\">\n",
    "                  <h4 className=\"font-semibold mb-3\">Submission Checklist</h4>\n",
    "                  <div className=\"space-y-2\">\n",
    "                    <label className=\"flex items-center\">\n",
    "                      <input type=\"checkbox\" className=\"mr-2\" />\n",
    "                      <span className=\"text-sm\">leaderboard.csv with required columns</span>\n",
    "                    </label>\n",
    "                    <label className=\"flex items-center\">\n",
    "                      <input type=\"checkbox\" className=\"mr-2\" />\n",
    "                      <span className=\"text-sm\">Well-documented Python/R script</span>\n",
    "                    </label>\n",
    "                    <label className=\"flex items-center\">\n",
    "                      <input type=\"checkbox\" className=\"mr-2\" />\n",
    "                      <span className=\"text-sm\">Model critique and improvement suggestions</span>\n",
    "                    </label>\n",
    "                    <label className=\"flex items-center\">\n",
    "                      <input type=\"checkbox\" className=\"mr-2\" />\n",
    "                      <span className=\"text-sm\">Email to footballresearch.technology@broncos.nfl.net</span>\n",
    "                    </label>\n",
    "                  </div>\n",
    "                </div>\n",
    "              </div>\n",
    "            )}\n",
    "          </div>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "  );\n",
    "};\n",
    "\n",
    "export default NFLKickerAssessment; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting railway.toml\n"
     ]
    }
   ],
   "source": [
    "%%writefile railway.toml\n",
    "[build]\n",
    "# Railway automatically detects a Dockerfile, but we name the image for clarity\n",
    "builder = \"dockerfile\"\n",
    "dockerfilePath = \"Dockerfile\"\n",
    "\n",
    "[deploy]\n",
    "startCommand = \"node server.js\"\n",
    "healthcheckPath = \"/api/ping\"\n",
    "restartPolicyType = \"on_failure\"\n",
    "\n",
    "[service]\n",
    "# Expose your unified API + static bundle\n",
    "ports = [\"$PORT\"]\n",
    "\n",
    "[volumes]\n",
    "# Persist model artifacts & uploads across deploys\n",
    "\"/app/uploads\" = \"kicker-uploads\"\n",
    "\"/workspace/mlruns\" = \"mlflow-artifacts\"\n",
    "\"/mlflow_db\" = \"mlflow-database\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .devcontainer/generate-project-name.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile .devcontainer/generate-project-name.sh\n",
    "#!/usr/bin/env bash\n",
    "set -euo pipefail\n",
    "\n",
    "ENV_FILE=\".devcontainer/.env.runtime\"\n",
    "\n",
    "# Only generate once per local checkout\n",
    "if [[ ! -f \"${ENV_FILE}\" ]]; then\n",
    "  # workspaceFolderBasename → \"docker-dev-template\", devcontainerId → random but stable\n",
    "  RAND=\"${devcontainerId:-$(date +%s | tail -c 6 | tr -d '\\n')}\"\n",
    "  BASENAME=\"${localWorkspaceFolderBasename:-$(basename \"$PWD\")}\"\n",
    "  \n",
    "  # Clean up basename to be docker-compose friendly\n",
    "  BASENAME=$(echo \"$BASENAME\" | sed 's/[^a-zA-Z0-9_-]/-/g' | tr '[:upper:]' '[:lower:]')\n",
    "  \n",
    "  PROJECT_NAME=\"${BASENAME}-${RAND}\"\n",
    "  \n",
    "  echo \"COMPOSE_PROJECT_NAME=${PROJECT_NAME}\" > \"${ENV_FILE}\"\n",
    "  echo \"ENV_NAME=${PROJECT_NAME}\"           >> \"${ENV_FILE}\"\n",
    "  echo \"🔧  Generated unique project name: ${PROJECT_NAME}\"\n",
    "  echo \"🔧  Wrote ${ENV_FILE}: $(cat ${ENV_FILE})\"\n",
    "fi "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
